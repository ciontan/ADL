{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae84885b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\GitHub repos\\ADL\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import (\n",
    "    MaxAbsScaler,\n",
    "    MinMaxScaler,\n",
    "    Normalizer,\n",
    "    PowerTransformer,\n",
    "    QuantileTransformer,\n",
    "    RobustScaler,\n",
    "    StandardScaler,\n",
    "    minmax_scale,\n",
    ")\n",
    "from sklearn.metrics import recall_score, accuracy_score,f1_score, precision_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from imblearn.pipeline import Pipeline\n",
    "import warnings\n",
    "import optuna\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed72646e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "randomState = 42\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "raw_dataset = pd.read_csv(\"./data/processed_data.csv\") #data has X and Y\n",
    "X = raw_dataset.drop(columns=[\"DR\"])\n",
    "Y = pd.DataFrame(raw_dataset[\"DR\"])\n",
    "\n",
    "#* 90/10 split for training and final test\n",
    "X_FOR_FOLDS, X_FINAL_TEST, Y_FOR_FOLDS, Y_FINAL_TEST = train_test_split(X, Y, test_size=0.1, random_state=randomState, stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "63312d8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.82758621e-01, 1.00000000e+00, 4.41355996e-03, 3.52019713e-04,\n",
       "        5.50173480e-05, 1.54148472e-01, 1.16646416e-02, 1.81195280e-01,\n",
       "        4.56057007e-01, 2.63565891e-01, 4.79452055e-02, 2.69058296e-01,\n",
       "        1.61538462e-01, 2.77777778e-01, 7.54716981e-01, 5.11363636e-02,\n",
       "        3.79865031e-02, 6.96048632e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00],\n",
       "       [6.89655172e-01, 0.00000000e+00, 2.03775002e-02, 5.05192291e-01,\n",
       "        1.95487173e-04, 1.44104803e-01, 5.46780073e-03, 3.52874001e-01,\n",
       "        4.70308789e-01, 2.94573643e-01, 6.16438356e-02, 1.92825112e-01,\n",
       "        1.00000000e-01, 3.51851852e-01, 8.11320755e-01, 5.49242424e-02,\n",
       "        3.38270871e-02, 9.72644377e-02, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [6.37931034e-01, 1.00000000e+00, 6.76119823e-03, 3.95582153e-01,\n",
       "        8.31113130e-05, 1.75109170e-01, 1.71324423e-02, 1.33231823e-01,\n",
       "        4.84560570e-01, 2.40310078e-01, 6.33561644e-02, 1.88340807e-01,\n",
       "        6.92307692e-02, 2.77777778e-01, 7.07547170e-01, 5.49242424e-02,\n",
       "        4.80030559e-02, 7.90273556e-02, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [5.51724138e-01, 0.00000000e+00, 3.09888252e-03, 3.52019713e-04,\n",
       "        3.86292018e-05, 1.22270742e-01, 9.96354800e-03, 1.81956604e-01,\n",
       "        3.33729216e-01, 2.75193798e-01, 8.21917808e-02, 2.28699552e-01,\n",
       "        1.88461538e-01, 2.87037037e-01, 7.73584906e-01, 4.16666667e-02,\n",
       "        2.75879632e-02, 2.34042553e-01, 1.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [3.44827586e-02, 0.00000000e+00, 1.98140670e-02, 4.84027106e-04,\n",
       "        1.96657755e-04, 1.63755459e-01, 4.44714459e-02, 3.84468976e-02,\n",
       "        2.95724466e-01, 1.78294574e-01, 4.28082192e-02, 1.92825112e-01,\n",
       "        3.80769231e-01, 7.22222222e-01, 8.67924528e-01, 9.84848485e-02,\n",
       "        5.94626714e-02, 6.68693009e-02, 0.00000000e+00, 1.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'startswith'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[48]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m display(test_norm[:\u001b[32m5\u001b[39m])\n\u001b[32m      6\u001b[39m test_norm = pd.DataFrame(test_norm)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m community_cols = \u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtest_norm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstartswith\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mCommunity\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m \n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mCommunity columns:\u001b[39m\u001b[33m\"\u001b[39m, community_cols)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[48]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m      5\u001b[39m display(test_norm[:\u001b[32m5\u001b[39m])\n\u001b[32m      6\u001b[39m test_norm = pd.DataFrame(test_norm)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m community_cols = [col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m test_norm.columns \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcol\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstartswith\u001b[49m(\u001b[33m'\u001b[39m\u001b[33mCommunity\u001b[39m\u001b[33m'\u001b[39m)] \n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mCommunity columns:\u001b[39m\u001b[33m\"\u001b[39m, community_cols)\n",
      "\u001b[31mAttributeError\u001b[39m: 'int' object has no attribute 'startswith'"
     ]
    }
   ],
   "source": [
    "# display(raw_dataset.head())\n",
    "display\n",
    "Norm_function = MinMaxScaler() # Normalization function\n",
    "test_norm = Norm_function.fit_transform(X_FOR_FOLDS)\n",
    "display(test_norm[:5])\n",
    "test_norm = pd.DataFrame(test_norm)\n",
    "community_cols = [col for col in test_norm.columns if col.startswith('Community')] \n",
    "print(\"Community columns:\", community_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6d3b2506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary columns:  [1, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27]\n"
     ]
    }
   ],
   "source": [
    "binary_cols = [col for col in test_norm if set(test_norm[col].unique()).issubset({0.0, 1.0})]\n",
    "print(\"Binary columns: \", binary_cols)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2be4dc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FOLDS_GENERATOR(X, Y, normalisation_method=MinMaxScaler(), n_splits=5, random_state=None, oversampler=None):\n",
    "    \"\"\"\n",
    "    Generates stratified folds with specified normalization and oversampling.\n",
    "    \"\"\"\n",
    "    kF = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    kFolds_list = []\n",
    "    \n",
    "    for fold, (train_idx, test_idx) in enumerate(kF.split(X, Y)):\n",
    "        # Split the data into training and testing sets for this fold\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        Y_train, Y_test = Y.iloc[train_idx], Y.iloc[test_idx]\n",
    "        \n",
    "        # IsolationForest for outlier removal (optional)\n",
    "        iso_forest = IsolationForest(contamination=0.05, random_state=random_state)\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\", UserWarning)\n",
    "            outliers = iso_forest.fit_predict(X_train)    \n",
    "        X_train = X_train[outliers == 1]\n",
    "        Y_train = Y_train[outliers == 1]\n",
    "        \n",
    "        # Scale the entire data (binary and continuous together)\n",
    "        X_train_scaled = normalisation_method.fit_transform(X_train)\n",
    "        X_test_scaled = normalisation_method.transform(X_test)\n",
    "\n",
    "        # Handle oversampling if needed\n",
    "        if oversampler:\n",
    "            # Apply oversampling to both features and target\n",
    "            X_train_scaled, Y_train = oversampler.fit_resample(X_train_scaled, Y_train)\n",
    "\n",
    "        # Convert scaled data back to DataFrame with the correct column names\n",
    "        X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "        X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n",
    "        \n",
    "        # Handle community columns\n",
    "        community_cols = [col for col in X_train_scaled.columns if col.startswith('Community')] \n",
    "\n",
    "        # Check for rows where multiple communities are flagged\n",
    "        for idx, row in X_train_scaled[community_cols].iterrows():\n",
    "            if set(np.unique(row)) != {0, 1}:  # If the unique values aren't just 0 or 1\n",
    "                # Fix row by ensuring only one community is marked\n",
    "                X_train_scaled.loc[idx, community_cols] = 0  # Set all community columns to 0\n",
    "                max_col = row.idxmax()  # Find the column with the maximum value\n",
    "                X_train_scaled.at[idx, max_col] = 1  # Set the column with the max value to 1\n",
    "\n",
    "        # Ensure 'gender' is still binary (0 or 1)\n",
    "        if 'Gender' in X_train_scaled.columns:\n",
    "            X_train_scaled['Gender'] = (X_train_scaled['Gender'] > 0.5).astype(int)\n",
    "            X_test_scaled['Gender'] = (X_test_scaled['Gender'] > 0.5).astype(int)\n",
    "        \n",
    "        # Append the processed fold to the list\n",
    "        kFolds_list.append((X_train_scaled, X_test_scaled, Y_train, Y_test))\n",
    "        \n",
    "        print(f\"Fold: {fold+1}, Train: {kFolds_list[fold][0].shape}, Test: {kFolds_list[fold][1].shape}\")\n",
    "    \n",
    "    return kFolds_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "78bf0bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1, Train: (7981, 28), Test: (1149, 28)\n",
      "Fold: 2, Train: (7859, 28), Test: (1149, 28)\n",
      "Fold: 3, Train: (7906, 28), Test: (1148, 28)\n",
      "Fold: 4, Train: (7942, 28), Test: (1148, 28)\n",
      "Fold: 5, Train: (7958, 28), Test: (1148, 28)\n"
     ]
    }
   ],
   "source": [
    "oversampler = ADASYN(sampling_strategy='minority', n_neighbors=5, random_state=5)\n",
    "normalisation_method = MinMaxScaler() # Normalization function\n",
    "\n",
    "Folds = FOLDS_GENERATOR(X_FOR_FOLDS, Y_FOR_FOLDS, \n",
    "                         normalisation_method = normalisation_method, \n",
    "                         n_splits=5, \n",
    "\n",
    "                         oversampler = oversampler, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f292dc71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1, Train: (4363, 28), Test: (1149, 28)\n",
      "Fold: 2, Train: (4363, 28), Test: (1149, 28)\n",
      "Fold: 3, Train: (4364, 28), Test: (1148, 28)\n",
      "Fold: 4, Train: (4364, 28), Test: (1148, 28)\n",
      "Fold: 5, Train: (4364, 28), Test: (1148, 28)\n"
     ]
    }
   ],
   "source": [
    "Folds = FOLDS_GENERATOR(X_FOR_FOLDS, Y_FOR_FOLDS, \n",
    "                         normalisation_method = normalisation_method, \n",
    "                         n_splits=5, \n",
    "\n",
    "                         oversampler = None, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94964e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
