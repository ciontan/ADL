{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b6cacd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\GitHub repos\\ADL\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import (\n",
    "    MaxAbsScaler,\n",
    "    MinMaxScaler,\n",
    "    Normalizer,\n",
    "    PowerTransformer,\n",
    "    QuantileTransformer,\n",
    "    RobustScaler,\n",
    "    StandardScaler,\n",
    "    minmax_scale,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import optuna\n",
    "import pandas as pd\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0c6603c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'device' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfold_to_dataloader_tensor\u001b[39m(train_x, test_x, train_y, test_y, batch_size=\u001b[32m64\u001b[39m, device=\u001b[43mdevice\u001b[49m):\n\u001b[32m      2\u001b[39m     train_dataset = TensorDataset(\n\u001b[32m      3\u001b[39m         torch.tensor(train_x.values,dtype=torch.float32).to(device), \n\u001b[32m      4\u001b[39m         torch.tensor(train_y.values,dtype=torch.float32).to(device))\n\u001b[32m      5\u001b[39m     val_dataset = TensorDataset(\n\u001b[32m      6\u001b[39m         torch.tensor(test_x.values,dtype=torch.float32).to(device), \n\u001b[32m      7\u001b[39m         torch.tensor(test_y.values,dtype=torch.float32).to(device))\n",
      "\u001b[31mNameError\u001b[39m: name 'device' is not defined"
     ]
    }
   ],
   "source": [
    "def fold_to_dataloader_tensor(train_x, test_x, train_y, test_y, batch_size=64, device=device):\n",
    "    train_dataset = TensorDataset(\n",
    "        torch.tensor(train_x.values,dtype=torch.float32).to(device), \n",
    "        torch.tensor(train_y.values,dtype=torch.float32).to(device))\n",
    "    val_dataset = TensorDataset(\n",
    "        torch.tensor(test_x.values,dtype=torch.float32).to(device), \n",
    "        torch.tensor(test_y.values,dtype=torch.float32).to(device))\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=len(val_dataset), shuffle=True, drop_last=True)\n",
    "    return train_loader, val_loader \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d7ffa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42 #! ABSOLUTELY DO NOT CHANGE THIS VALUE AS IT WILL CHANGE THE TEST/HOLDOUT SET\n",
    "raw_dataset = pd.read_csv(\"./data/processed_data_OHE.csv\") #data has X and Y\n",
    "X = raw_dataset.drop(columns=[\"DR\"])\n",
    "Y = pd.DataFrame(raw_dataset[\"DR\"])\n",
    "# Slice your data\n",
    "\n",
    "\n",
    "X_FOR_FOLDS, X_FINAL_TEST, Y_FOR_FOLDS, Y_FINAL_TEST = train_test_split(X, Y, test_size=0.1, random_state=random_state, stratify=Y)\n",
    "HOLDOUT_DATA = pd.concat([X_FINAL_TEST, Y_FINAL_TEST], axis=1)\n",
    "FOLDS_DATA = pd.concat([X_FOR_FOLDS, Y_FOR_FOLDS], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf1cbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FOLDS_GENERATOR(dataset, n_splits=5, random_state=None, oversampler=None, noise=None,\n",
    "                     OD_majority=None, OD_minority=None, scaler=None):\n",
    "    kF = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    kFolds_list = []\n",
    "\n",
    "    # Convert column names to strings to ensure compatibility\n",
    "    df = dataset.copy()\n",
    "    X = df.drop(columns=[\"DR\"])\n",
    "    Y = pd.DataFrame(df[\"DR\"])\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(kF.split(X, Y)):\n",
    "        # Split the data into training and testing sets for this fold\n",
    "        train = pd.concat([X.iloc[train_idx], Y.iloc[train_idx]], axis=1)\n",
    "        test = pd.concat([X.iloc[test_idx], Y.iloc[test_idx]], axis=1)\n",
    "        \n",
    "        # Apply P to X_train and X_test, passing Y_train to P for class info\n",
    "        X_train_processed, X_test_processed = Preprocessor(train, test,\n",
    "                                                OD_majority=OD_majority,\n",
    "                                                OD_minority=OD_minority,\n",
    "                                                scaler=scaler)\n",
    "        # Append the processed fold to the list\n",
    "        # kFolds_list.append((X_train_processed, X_test_processed))  # Append imputed DataFrames\n",
    "        kFolds_list.append((X_train_processed.drop(columns=[\"DR\"]),\n",
    "                            X_test_processed.drop(columns=[\"DR\"]),\n",
    "                            X_train_processed[[\"DR\"]],\n",
    "                            X_test_processed[[\"DR\"]]))\n",
    "\n",
    "        print(f\"Fold: {fold+1}, Train: {X_train_processed.shape}, Test: {X_test_processed.shape}\")\n",
    "    return kFolds_list\n",
    "\n",
    "if outlier_detection:\n",
    "    do OD AND REMOVAL\n",
    "    \n",
    "oversample= Smotenc\n",
    "oversample + original training\n",
    "synthetic = synthesizer(oversample + original training)\n",
    "\n",
    "print similarity scores between original and synthetic data\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "save training and test data for each fold, automatic numbering convention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c57e2c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
