{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d772ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in d:\\adl\\adl\\venv\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in d:\\adl\\adl\\venv\\lib\\site-packages (from pandas) (2.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\adl\\adl\\venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\adl\\adl\\venv\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\adl\\adl\\venv\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in d:\\adl\\adl\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: optuna in d:\\adl\\adl\\venv\\lib\\site-packages (4.3.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in d:\\adl\\adl\\venv\\lib\\site-packages (from optuna) (1.15.2)\n",
      "Requirement already satisfied: colorlog in d:\\adl\\adl\\venv\\lib\\site-packages (from optuna) (6.9.0)\n",
      "Requirement already satisfied: numpy in d:\\adl\\adl\\venv\\lib\\site-packages (from optuna) (2.2.4)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\adl\\adl\\venv\\lib\\site-packages (from optuna) (24.2)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in d:\\adl\\adl\\venv\\lib\\site-packages (from optuna) (2.0.40)\n",
      "Requirement already satisfied: tqdm in d:\\adl\\adl\\venv\\lib\\site-packages (from optuna) (4.67.1)\n",
      "Requirement already satisfied: PyYAML in d:\\adl\\adl\\venv\\lib\\site-packages (from optuna) (6.0.2)\n",
      "Requirement already satisfied: Mako in d:\\adl\\adl\\venv\\lib\\site-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
      "Requirement already satisfied: typing-extensions>=4.12 in d:\\adl\\adl\\venv\\lib\\site-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
      "Requirement already satisfied: greenlet>=1 in d:\\adl\\adl\\venv\\lib\\site-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
      "Requirement already satisfied: colorama in d:\\adl\\adl\\venv\\lib\\site-packages (from colorlog->optuna) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in d:\\adl\\adl\\venv\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
      "Requirement already satisfied: optuna-dashboard in d:\\adl\\adl\\venv\\lib\\site-packages (0.18.0)\n",
      "Requirement already satisfied: bottle>=0.13.0 in d:\\adl\\adl\\venv\\lib\\site-packages (from optuna-dashboard) (0.13.2)\n",
      "Requirement already satisfied: optuna>=3.1.0 in d:\\adl\\adl\\venv\\lib\\site-packages (from optuna-dashboard) (4.3.0)\n",
      "Requirement already satisfied: packaging in d:\\adl\\adl\\venv\\lib\\site-packages (from optuna-dashboard) (24.2)\n",
      "Requirement already satisfied: scikit-learn in d:\\adl\\adl\\venv\\lib\\site-packages (from optuna-dashboard) (1.6.1)\n",
      "Requirement already satisfied: alembic>=1.5.0 in d:\\adl\\adl\\venv\\lib\\site-packages (from optuna>=3.1.0->optuna-dashboard) (1.15.2)\n",
      "Requirement already satisfied: colorlog in d:\\adl\\adl\\venv\\lib\\site-packages (from optuna>=3.1.0->optuna-dashboard) (6.9.0)\n",
      "Requirement already satisfied: numpy in d:\\adl\\adl\\venv\\lib\\site-packages (from optuna>=3.1.0->optuna-dashboard) (2.2.4)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in d:\\adl\\adl\\venv\\lib\\site-packages (from optuna>=3.1.0->optuna-dashboard) (2.0.40)\n",
      "Requirement already satisfied: tqdm in d:\\adl\\adl\\venv\\lib\\site-packages (from optuna>=3.1.0->optuna-dashboard) (4.67.1)\n",
      "Requirement already satisfied: PyYAML in d:\\adl\\adl\\venv\\lib\\site-packages (from optuna>=3.1.0->optuna-dashboard) (6.0.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in d:\\adl\\adl\\venv\\lib\\site-packages (from scikit-learn->optuna-dashboard) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in d:\\adl\\adl\\venv\\lib\\site-packages (from scikit-learn->optuna-dashboard) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in d:\\adl\\adl\\venv\\lib\\site-packages (from scikit-learn->optuna-dashboard) (3.6.0)\n",
      "Requirement already satisfied: Mako in d:\\adl\\adl\\venv\\lib\\site-packages (from alembic>=1.5.0->optuna>=3.1.0->optuna-dashboard) (1.3.10)\n",
      "Requirement already satisfied: typing-extensions>=4.12 in d:\\adl\\adl\\venv\\lib\\site-packages (from alembic>=1.5.0->optuna>=3.1.0->optuna-dashboard) (4.12.2)\n",
      "Requirement already satisfied: greenlet>=1 in d:\\adl\\adl\\venv\\lib\\site-packages (from sqlalchemy>=1.4.2->optuna>=3.1.0->optuna-dashboard) (3.1.1)\n",
      "Requirement already satisfied: colorama in d:\\adl\\adl\\venv\\lib\\site-packages (from colorlog->optuna>=3.1.0->optuna-dashboard) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in d:\\adl\\adl\\venv\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna>=3.1.0->optuna-dashboard) (3.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement scikit (from versions: none)\n",
      "ERROR: No matching distribution found for scikit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in d:\\adl\\adl\\venv\\lib\\site-packages (0.13.0)\n",
      "Requirement already satisfied: numpy<3,>=1.24.3 in d:\\adl\\adl\\venv\\lib\\site-packages (from imbalanced-learn) (2.2.4)\n",
      "Requirement already satisfied: scipy<2,>=1.10.1 in d:\\adl\\adl\\venv\\lib\\site-packages (from imbalanced-learn) (1.15.2)\n",
      "Requirement already satisfied: scikit-learn<2,>=1.3.2 in d:\\adl\\adl\\venv\\lib\\site-packages (from imbalanced-learn) (1.6.1)\n",
      "Requirement already satisfied: sklearn-compat<1,>=0.1 in d:\\adl\\adl\\venv\\lib\\site-packages (from imbalanced-learn) (0.1.3)\n",
      "Requirement already satisfied: joblib<2,>=1.1.1 in d:\\adl\\adl\\venv\\lib\\site-packages (from imbalanced-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in d:\\adl\\adl\\venv\\lib\\site-packages (from imbalanced-learn) (3.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install optuna\n",
    "!pip install optuna-dashboard\n",
    "!pip install scikit\n",
    "!pip install imbalanced-learn\n",
    "from sklearn.preprocessing import (\n",
    "    MaxAbsScaler,\n",
    "    MinMaxScaler,\n",
    "    Normalizer,\n",
    "    PowerTransformer,\n",
    "    QuantileTransformer,\n",
    "    RobustScaler,\n",
    "    StandardScaler,\n",
    "    minmax_scale,\n",
    ")\n",
    "\n",
    "from sklearn.metrics import recall_score, accuracy_score,f1_score, precision_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.over_sampling import SMOTE, ADASYN, SMOTENC\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import warnings\n",
    "import optuna\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdf1a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using\", device)\n",
    "def init_weights(model):\n",
    "    if isinstance(model, nn.Linear):  # Apply only to linear layers\n",
    "        # He initialization (recommended for ReLU activations)\n",
    "        # print(\"Initializing weights using kaiming\")\n",
    "        nn.init.kaiming_normal_(model.weight, mode='fan_in', nonlinearity='relu')\n",
    "        \n",
    "        # Bias initialization (zero initialization is fine)\n",
    "        if model.bias is not None:\n",
    "            nn.init.zeros_(model.bias)\n",
    "def fold_to_dataloader_tensor(train_x, test_x, train_y, test_y, batch_size=64, device=device):\n",
    "    train_dataset = TensorDataset(\n",
    "        torch.tensor(train_x.values,dtype=torch.float32).to(device), \n",
    "        torch.tensor(train_y.values,dtype=torch.float32).to(device))\n",
    "    val_dataset = TensorDataset(\n",
    "        torch.tensor(test_x.values,dtype=torch.float32).to(device), \n",
    "        torch.tensor(test_y.values,dtype=torch.float32).to(device))\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=len(val_dataset), shuffle=True, drop_last=True)\n",
    "    return train_loader, val_loader \n",
    "\n",
    "def get_feature_count(loader):\n",
    "    \"\"\"returns the number of features in the dataset\"\"\"\n",
    "    return next(iter(loader))[0].shape[1]\n",
    "\n",
    "from Criterion_Models import *\n",
    "def criterion_mapping(criterion_choice:str, pos_weight:float=None, alpha:float=None, gamma:float=None):\n",
    "    \"\"\"\n",
    "    Feel free to add any custom loss functions here.\n",
    "    returns function for criterion\n",
    "    \"\"\"\n",
    "    if criterion_choice == \"FocalLoss\":\n",
    "        return FocalLoss(alpha =alpha, gamma=gamma)\n",
    "    elif criterion_choice == \"DiceLoss\":\n",
    "        return DiceLoss()\n",
    "    elif criterion_choice == \"BCEWithLogitsLoss\":\n",
    "        return nn.BCEWithLogitsLoss(pos_weight=torch.tensor([pos_weight])) if pos_weight else nn.BCEWithLogitsLoss()\n",
    "    return nn.BCEWithLogitsLoss() \n",
    "\n",
    "# def augment_data_in_place(X, X_test, Y=None, normalisation_method=MinMaxScaler(), robust_scaler=RobustScaler(), noise=None):\n",
    "#    # Create copies to avoid modifying original data\n",
    "#     X_transformed = X.copy()\n",
    "#     X_test_transformed = X_test.copy()\n",
    "    \n",
    "#     # Identify numerical columns (exclude binary ones)\n",
    "#     all_numerical_columns = ['Age', 'UAlb', 'Ucr', 'UACR', 'TC', 'TG', 'TCTG', 'LDLC', \n",
    "#                            'HDLC', 'Scr', 'BUN', 'FPG', 'HbA1c', 'Height', 'Weight', \n",
    "#                            'BMI', 'Duration']\n",
    "#     binary_columns = ['Gender', 'DR', 'Community_baihe', 'Community_chonggu', \n",
    "#                     'Community_huaxin', 'Community_jinze', 'Community_liantang', \n",
    "#                     'Community_xianghuaqiao', 'Community_xujin', 'Community_yingpu', \n",
    "#                     'Community_zhaoxian', 'Community_zhujiajiao']\n",
    "    \n",
    "#     # Find which numerical columns actually exist in the data\n",
    "#     numeric_cols = [col for col in all_numerical_columns if col in X.columns and col in X_test.columns]\n",
    "    \n",
    "#     if not numeric_cols:\n",
    "#         print(\"No matching numerical columns found for transformation.\")\n",
    "#         # Apply standard normalization to all data if no specific columns matched\n",
    "#         X_normalized = pd.DataFrame(normalisation_method.fit_transform(X), columns=X.columns, index=X.index)\n",
    "#         X_test_normalized = pd.DataFrame(normalisation_method.transform(X_test), columns=X_test.columns, index=X_test.index)\n",
    "#         return X_normalized, X_test_normalized\n",
    "    \n",
    "#     # 1. Apply log transformation to numeric columns (handling zeros/negatives with log1p)\n",
    "#     # Skip log transform for any columns that have negative values\n",
    "#     for col in numeric_cols:\n",
    "#         if (X_transformed[col].min() >= 0) and (X_test_transformed[col].min() >= 0):\n",
    "#             X_transformed[col] = np.log1p(X_transformed[col])\n",
    "#             X_test_transformed[col] = np.log1p(X_test_transformed[col])\n",
    "    \n",
    "#     # 2. Apply RobustScaler to handle outliers (only to numeric columns)\n",
    "#     if robust_scaler:\n",
    "#         robust_scaled_train = robust_scaler.fit_transform(X_transformed[numeric_cols])\n",
    "#         robust_scaled_test = robust_scaler.transform(X_test_transformed[numeric_cols])\n",
    "        \n",
    "#         X_transformed[numeric_cols] = robust_scaled_train\n",
    "#         X_test_transformed[numeric_cols] = robust_scaled_test\n",
    "    \n",
    "#     # 3. Apply final normalization method (to all columns)\n",
    "#     X_normalized = normalisation_method.fit_transform(X_transformed)\n",
    "#     X_test_normalized = normalisation_method.transform(X_test_transformed)\n",
    "    \n",
    "#     # Convert back to DataFrame with original column names\n",
    "#     X_normalized = pd.DataFrame(X_normalized, columns=X.columns, index=X.index)\n",
    "#     X_test_normalized = pd.DataFrame(X_test_normalized, columns=X_test.columns, index=X_test.index)\n",
    "    \n",
    "#     # 4. Add noise ONLY to negatives (class 0) if Y is provided and noise is set\n",
    "#     if noise is not None and noise > 0 and Y is not None:\n",
    "#         # Identify negative class indices (class 0)\n",
    "#         if isinstance(Y, pd.DataFrame):\n",
    "#             negative_indices = Y[Y.iloc[:, 0] == 0].index\n",
    "#         else:  # Handle Series case\n",
    "#             negative_indices = Y[Y == 0].index\n",
    "            \n",
    "#         # Add noise only to negative samples and only to numerical columns\n",
    "#         if len(negative_indices) > 0:\n",
    "#             noise_matrix = np.random.normal(0, noise, (len(negative_indices), len(numeric_cols)))\n",
    "#             X_normalized.loc[negative_indices, numeric_cols] += noise_matrix\n",
    "            \n",
    "#             # Ensure values stay within [0,1] range after noise addition\n",
    "#             X_normalized.loc[negative_indices, numeric_cols] = np.clip(\n",
    "#                 X_normalized.loc[negative_indices, numeric_cols], 0, 1)\n",
    "    \n",
    "#     return X_normalized, X_test_normalized\n",
    "\n",
    "\n",
    "# def iso_forest(X_train, Y_train, contamination=None, random_state=42):\n",
    "#     # print(\"Original\\n\", X_train.shape, Y_train.shape, X_test.shape, Y_test.shape)\n",
    "#     X_train_cleaned, Y_train_cleaned = X_train.copy(), Y_train.copy()\n",
    "    \n",
    "#     X_train_zeros = X_train[Y_train.iloc[:, 0] == 0]\n",
    "#     X_train_ones = X_train[Y_train.iloc[:, 0] == 1]\n",
    "#     Y_train_zeros = Y_train[Y_train.iloc[:, 0] == 0]\n",
    "#     Y_train_ones = Y_train[Y_train.iloc[:, 0] == 1] \n",
    "#     # print(\"Ones and zeros\\n\", X_train_zeros.shape, Y_train_zeros.shape, X_train_ones.shape, Y_train_ones.shape)\n",
    "#     #only class 0s\n",
    "#     if X_train_zeros.isna().any().any():\n",
    "#         print(\"got NaN values in the training set\")\n",
    "    \n",
    "#     # Apply Isolation Forest to majority class only\n",
    "#     iso_forest = IsolationForest(contamination=contamination, random_state=random_state)\n",
    "#     try:\n",
    "#         outliers = iso_forest.fit_predict(X_train_zeros)\n",
    "#     except UserWarning as e:\n",
    "#         print(\"Caught warning during IsolationForest fitting:\", e)\n",
    "#         outliers = np.ones(len(X_train_zeros))  # If warning occurs, keep all data\n",
    "#     # Keep only non-outlier majority samples\n",
    "#     X_train_zeros = X_train_zeros[outliers == 1]\n",
    "#     Y_train_zeros = Y_train_zeros[outliers == 1]\n",
    "#     # print(\"After iso:\\n\", X_train_zeros.shape, Y_train_zeros.shape, X_train_ones.shape, Y_train_ones.shape)\n",
    "    \n",
    "#     # Combine the cleaned majority class with the untouched minority class\n",
    "#     X_train_cleaned = pd.concat([X_train_zeros, X_train_ones])\n",
    "#     Y_train_cleaned = pd.concat([Y_train_zeros, Y_train_ones])\n",
    "#     return X_train_cleaned, Y_train_cleaned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d7ac6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42\n",
    "raw_dataset = pd.read_csv(\"./data/processed_data_encoded.csv\") #data has X and Y\n",
    "X = raw_dataset.drop(columns=[\"DR\"])\n",
    "Y = pd.DataFrame(raw_dataset[\"DR\"])\n",
    "# Slice your data\n",
    "\n",
    "\n",
    "X_FOR_FOLDS, X_FINAL_TEST, Y_FOR_FOLDS, Y_FINAL_TEST = train_test_split(X, Y, test_size=0.1, random_state=random_state, stratify=Y)\n",
    "df = pd.concat([X_FOR_FOLDS, Y_FOR_FOLDS], axis=1)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad18050",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'real_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msdv\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mevaluation\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msingle_table\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_column_plot\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msdv\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetadata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Metadata\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m metadata = Metadata.detect_from_dataframe(data=\u001b[43mreal_data\u001b[49m)\n\u001b[32m      8\u001b[39m metadata = Metadata.detect_from_dataframe(data=real_data)\n\u001b[32m      9\u001b[39m metadata.validate()\n",
      "\u001b[31mNameError\u001b[39m: name 'real_data' is not defined"
     ]
    }
   ],
   "source": [
    "import sdv\n",
    "from sdv.evaluation.single_table import run_diagnostic, evaluate_quality\n",
    "from sdv.evaluation.single_table import get_column_plot\n",
    "from sdv.metadata import Metadata\n",
    "\n",
    "metadata = Metadata.detect_from_dataframe(data=real_data)\n",
    "\n",
    "metadata = Metadata.detect_from_dataframe(data=real_data)\n",
    "metadata.validate()\n",
    "metadata.visualize()\n",
    "# 1. perform basic validity checks\n",
    "diagnostic = run_diagnostic(real_data, synthetic_data, metadata)\n",
    "\n",
    "# 2. measure the statistical similarity\n",
    "quality_report = evaluate_quality(real_data, synthetic_data, metadata)\n",
    "\n",
    "# 3. plot the data\n",
    "fig = get_column_plot(\n",
    "    real_data=real_data,\n",
    "    synthetic_data=synthetic_data,\n",
    "    metadata=metadata,\n",
    "    column_name='Age' #change this u decide\n",
    ")\n",
    "    \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d130ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Preprocessor(df, df_test, OD_majority, OD_minority, oversampler, scaler):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from imblearn.over_sampling import SMOTENC\n",
    "    import os # Added for directory creation\n",
    "    \n",
    "    cont_cols = ['Age', 'UAlb', 'Ucr', 'UACR', 'TC', 'TG', 'TCTG', \n",
    "                 'LDLC', 'HDLC', 'Scr', 'BUN', 'FPG', 'HbA1c', 'Height', 'Weight', 'BMI', 'Duration']\n",
    "    # Use the original encoded single column name here\n",
    "    cat_cols = ['Gender', 'Community'] \n",
    "    y_col = 'DR'\n",
    "\n",
    "    print(\"Original class distribution:\")\n",
    "    print(df[y_col].value_counts())\n",
    "\n",
    "    if y_col not in df.columns:\n",
    "        raise KeyError(f\"'{y_col}' column is missing in the DataFrame.\")\n",
    "\n",
    "    df_majority = df[df[y_col] == 0].copy()\n",
    "    df_minority = df[df[y_col] == 1].copy()\n",
    "\n",
    "    if OD_majority is not None:\n",
    "        outliers_majority = OD_majority.fit_predict(df_majority[cont_cols])\n",
    "        df_majority = df_majority[outliers_majority == 1]\n",
    "        print(f\"After OD, majority: {len(df_majority)}\")\n",
    "\n",
    "    if OD_minority is not None:\n",
    "        outliers_minority = OD_minority.fit_predict(df_minority[cont_cols])\n",
    "        df_minority = df_minority[outliers_minority == 1]\n",
    "        print(f\"After OD, minority: {len(df_minority)}\")\n",
    "\n",
    "    df_after_OD = pd.concat([df_majority, df_minority], ignore_index=True)\n",
    "    original_data_count = len(df_after_OD) # Store count before resampling\n",
    "\n",
    "    # --- Prepare for potential SMOTENC ---\n",
    "    X_pre_smote = df_after_OD.drop(columns=[y_col])\n",
    "    y_pre_smote = df_after_OD[y_col]\n",
    "    \n",
    "    synthetic_samples = pd.DataFrame() # Initialize empty dataframe\n",
    "\n",
    "    if oversampler is not None:\n",
    "        print(\"\\nApplying SMOTENC oversampling...\")\n",
    "\n",
    "        # Find indices of categorical features for SMOTENC\n",
    "        cat_indices = [X_pre_smote.columns.get_loc(col) for col in cat_cols if col in X_pre_smote.columns] # Check if cat_cols exist\n",
    "\n",
    "        # Ensure 'Community' is integer type for SMOTENC if it exists\n",
    "        if 'Community' in X_pre_smote.columns:\n",
    "             X_pre_smote['Community'] = X_pre_smote['Community'].astype(int)\n",
    "\n",
    "        oversampler_instance = SMOTENC(categorical_features=cat_indices, random_state=42)\n",
    "        X_resampled, y_resampled = oversampler_instance.fit_resample(X_pre_smote, y_pre_smote)\n",
    "\n",
    "        resampled_df = pd.DataFrame(X_resampled, columns=X_pre_smote.columns)\n",
    "        resampled_df[y_col] = y_resampled\n",
    "\n",
    "        # Identify synthetic samples (those added beyond the original count after OD)\n",
    "        synthetic_samples = resampled_df.iloc[original_data_count:].copy()\n",
    "        \n",
    "        print(\"\\nSynthetic Samples Statistics (before processing):\")\n",
    "        print(f\"Number of synthetic samples generated: {len(synthetic_samples)}\")\n",
    "        if not synthetic_samples.empty:\n",
    "            print(synthetic_samples[y_col].value_counts())\n",
    "        else:\n",
    "            print(\"No synthetic samples were generated.\")\n",
    "\n",
    "\n",
    "        # Update df_after_OD to be the resampled dataframe for subsequent steps\n",
    "        df_after_OD = resampled_df\n",
    "    \n",
    "    # --- Scaling Continuous Features (Applied to combined data and test set) ---\n",
    "    df_after_OD[cont_cols] = scaler.fit_transform(df_after_OD[cont_cols])\n",
    "    df_test[cont_cols] = scaler.transform(df_test[cont_cols])\n",
    "\n",
    "    # --- Map community integers (0â€“9) back to original names ---\n",
    "    # Use simpler names for mapping, prefix will be added by get_dummies\n",
    "    community_mapping = {\n",
    "        0: 'zhujiajiao', 1: 'baihe', 2: 'chonggu', 3: 'huaxin', 4: 'jinze',\n",
    "        5: 'liantang', 6: 'xianghuaqiao', 7: 'xujin', 8: 'yingpu', 9: 'zhaoxian'\n",
    "    }\n",
    "    \n",
    "    # Apply the mapping to both the training/resampled set and the test set\n",
    "    if 'Community' in df_after_OD.columns:\n",
    "        df_after_OD['Community'] = df_after_OD['Community'].astype(int).map(community_mapping) # Ensure int before map\n",
    "    if 'Community' in df_test.columns:\n",
    "        df_test['Community'] = df_test['Community'].astype(int).map(community_mapping) # Ensure int before map\n",
    "\n",
    "    # --- Apply mapping to synthetic samples before one-hot encoding ---\n",
    "    if not synthetic_samples.empty and 'Community' in synthetic_samples.columns:\n",
    "        synthetic_samples['Community'] = synthetic_samples['Community'].astype(int).map(community_mapping) # Ensure int before map\n",
    "\n",
    "    # --- One-hot encode the 'Community' column ---\n",
    "    # Use prefix and dtype=int directly in get_dummies\n",
    "    if 'Community' in df_after_OD.columns:\n",
    "        df_after_OD = pd.get_dummies(df_after_OD, columns=['Community'], prefix='Community', prefix_sep='_', drop_first=False, dtype=int)\n",
    "    if 'Community' in df_test.columns:\n",
    "        df_test = pd.get_dummies(df_test, columns=['Community'], prefix='Community', prefix_sep='_', drop_first=False, dtype=int)\n",
    "    \n",
    "    # --- One-hot encode synthetic samples similarly ---\n",
    "    if not synthetic_samples.empty and 'Community' in synthetic_samples.columns:\n",
    "         synthetic_samples = pd.get_dummies(synthetic_samples, columns=['Community'], prefix='Community', prefix_sep='_', drop_first=False, dtype=int)\n",
    "\n",
    "    # --- Align columns ---\n",
    "    # Get the list of columns AFTER one-hot encoding on the training set\n",
    "    final_train_cols = df_after_OD.columns\n",
    "    \n",
    "    # Align test set columns\n",
    "    df_test = df_test.reindex(columns=final_train_cols, fill_value=0)\n",
    "\n",
    "    # Align synthetic samples columns (important for consistent export)\n",
    "    if not synthetic_samples.empty:\n",
    "        synthetic_samples = synthetic_samples.reindex(columns=final_train_cols, fill_value=0) # Use final_train_cols for alignment\n",
    "        # Ensure the target column exists if it was dropped during alignment\n",
    "        if y_col not in synthetic_samples.columns and y_col in df_after_OD.columns:\n",
    "             synthetic_samples[y_col] = df_after_OD.loc[synthetic_samples.index, y_col]\n",
    "\n",
    "\n",
    "    # # --- Export Synthetic Samples ---\n",
    "    # if export_path and not synthetic_samples.empty:\n",
    "    #     # Ensure export directory exists\n",
    "    #     os.makedirs(export_path, exist_ok=True) \n",
    "    #     export_file = os.path.join(export_path, \"all_synthetic_samples.csv\")\n",
    "    #     synthetic_samples.to_csv(export_file, index=False)\n",
    "    #     print(f\"\\nExported {len(synthetic_samples)} synthetic samples with correct encoding to {export_file}\")\n",
    "    #     # print(\"Sample of exported synthetic data:\")\n",
    "    #     # print(synthetic_samples.head())\n",
    "    #     # print(\"Data types of exported synthetic data:\")\n",
    "    #     # print(synthetic_samples.dtypes)\n",
    "\n",
    "    print(\"\\nFinal preprocessed dataset shape:\")\n",
    "    print(f\"Train/Resampled data shape: {df_after_OD.shape}\")\n",
    "    print(\"Class distribution in final preprocessed data:\")\n",
    "    print(df_after_OD[y_col].value_counts())\n",
    "    print(f\"\\nTest data shape after preprocessing: {df_test.shape}\")\n",
    "\n",
    "    return df_after_OD, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38ac840",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def FOLDS_GENERATOR(dataset, n_splits=5, random_state=None, oversampler=None, noise=None,\n",
    "                     OD_majority=None, OD_minority=None, scaler=None):\n",
    "    kF = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    kFolds_list = []\n",
    "\n",
    "    # Convert column names to strings to ensure compatibility\n",
    "    df = dataset.copy()\n",
    "    X = df.drop(columns=[\"DR\"])\n",
    "    Y = pd.DataFrame(df[\"DR\"])\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(kF.split(X, Y)):\n",
    "        # Split the data into training and testing sets for this fold\n",
    "        train = pd.concat([X.iloc[train_idx], Y.iloc[train_idx]], axis=1)\n",
    "        test = pd.concat([X.iloc[test_idx], Y.iloc[test_idx]], axis=1)\n",
    "        \n",
    "        # Apply Preprocessing to training and test data\n",
    "        X_train_processed, X_test_processed = Preprocessor(train, test,\n",
    "                                                OD_majority=OD_majority,\n",
    "                                                OD_minority=OD_minority,\n",
    "                                                oversampler=oversampler,\n",
    "                                                scaler=scaler)\n",
    "\n",
    "        # Append processed data (excluding the target column 'DR')\n",
    "        kFolds_list.append((X_train_processed.drop(columns=[\"DR\"]),\n",
    "                            X_test_processed.drop(columns=[\"DR\"]),\n",
    "                            X_train_processed[[\"DR\"]],\n",
    "                            X_test_processed[[\"DR\"]]))\n",
    "\n",
    "        print(f\"Fold: {fold+1}, Train: {X_train_processed.shape}, Test: {X_test_processed.shape}\")\n",
    "    \n",
    "    return kFolds_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80faf996",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model, criterion, optimiser, scheduler, train_loader, val_loader, epochs=20, patience=5, device=device, threshold = 0.5):\n",
    "    # if isinstance(model.last_layer(), nn.Sigmoid) and isinstance(criterion, nn.BCEWithLogitsLoss):\n",
    "    #     raise ValueError(\"Model output is Sigmoid but criterion is BCEWithLogitsLoss. Please check your model and criterion compatibility.\")\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_state = None\n",
    "    wait = 0\n",
    "    criterion.to(device) #? Move criterion to device\n",
    "    #* Epoch Training loop for this fold\n",
    "    for epoch in range(1,epochs+1):\n",
    "        #* Set model to training mode: essential for dropout and batch norm layers\n",
    "        model.train()\n",
    "        running_loss = 0.0 #? loss for this epoch\n",
    "        #* Mini-batch training loop\n",
    "        for batch, (inputs, labels) in enumerate(train_loader,start=1):\n",
    "            optimiser.zero_grad() #? Zero the gradients\n",
    "            \n",
    "            \n",
    "            torch.set_printoptions(threshold=float('inf'))\n",
    "            \n",
    "            assert not torch.isnan(inputs).any(), \"Input has NaNs\"\n",
    "            assert not torch.isinf(inputs).any(), \"Input has Infs\"\n",
    "            outputs = model(inputs) #? Forward pass through the model\n",
    "            assert not torch.isnan(outputs).any(), \"Model output has NaNs\"\n",
    "            assert not torch.isinf(outputs).any(), \"Model output has Infs\"\n",
    "            loss = criterion(outputs, labels) #? Calculate loss\n",
    "            assert not torch.isnan(loss).any(), \"Model loss has NaNs\"\n",
    "            loss.backward() #? Backpropagation\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            running_loss += loss.item()\n",
    "            optimiser.step() #? Update weights\n",
    "            scheduler.step()\n",
    "                \n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        # print(f\"Epoch: {epoch}, training loss: {train_loss:.4f}\")\n",
    "    \n",
    "        #* Now we evaluate the model on the validation set, to track training vs validation loss\n",
    "        model.eval() #? Set model to evaluation mode\n",
    "        with torch.no_grad(): #? No need to track gradients during evaluation\n",
    "            val_loss = 0.0    \n",
    "            for batch, (inputs, labels) in enumerate(val_loader,start=1):#! one pass because val_loader batch size is all, if you want to do it in mini-batches, you MUST change the metric calculations to accept mini-batches\n",
    "                \n",
    "                outputs = model(inputs)\n",
    "                # labels = labels.cpu() \n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() #? Calculate loss\n",
    "            avg_val_loss = val_loss / len(val_loader)\n",
    "        loss_ratio = val_loss / train_loss    \n",
    "        pos_weight = loss_ratio  # or any other function of loss_ratio you choose\n",
    "    \n",
    "        # Update criterion with new pos_weight\n",
    "        criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([pos_weight]).to(device))\n",
    "        # Early stopping\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            best_model_state = model.state_dict()\n",
    "            wait = 0\n",
    "        elif avg_val_loss*0.95 <= best_val_loss:\n",
    "                wait = 0\n",
    "        else:\n",
    "            wait += 1\n",
    "        if wait >= patience:\n",
    "            print(f\"Early stopping triggered at epoch {epoch}, best val loss: {best_val_loss:.4f}\")\n",
    "            break\n",
    "        print(f\"Epoch: {epoch}\".ljust(12), f\"training loss:{train_loss:.3f}\".ljust(16), f\"best_val_loss:{best_val_loss:.3f}\".ljust(12), f\"Val Loss: {avg_val_loss:.3f}\", f\"Scheduler lr: {scheduler.get_last_lr()}\".ljust(50),end=\"\\r\")\n",
    "    #* Use best model to calculate metrics on the validation set\n",
    "    #! must be outside epoch loop, it comes after the training and cv loop\n",
    "    model.load_state_dict(best_model_state) #? Load the best model state\n",
    "    with torch.no_grad():\n",
    "        for batch, (inputs, labels) in enumerate(val_loader,start=1):#! one pass because val_loader batch size is all, if you want to do it in mini-batches, you MUST change the metric calculations to accept mini-batches\n",
    "                \n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                labels = labels.cpu() \n",
    "                # predictions = (torch.sigmoid(outputs) < 0.5).float().cpu().numpy()\n",
    "                predictions = (torch.sigmoid(outputs) >= threshold).float().cpu().numpy()\n",
    "                val_loss += loss.item() #? Calculate loss\n",
    "                \n",
    "    #! The following should have length equal to fold number           \n",
    "    accuracy=accuracy_score(labels, predictions) \n",
    "    precision=precision_score(labels, predictions, pos_label=1, zero_division=0)\n",
    "    recall=recall_score(labels, predictions, pos_label=1)\n",
    "    f1=f1_score(labels, predictions, pos_label=1)\n",
    "    auc=roc_auc_score(labels, predictions)\n",
    "    \n",
    "    return model, accuracy, precision, recall, f1, auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce2c9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have these functions defined elsewhere (as you mentioned):\n",
    "# init_weights(model)\n",
    "# fold_to_dataloader_tensor(train_x, test_x, train_y, test_y, batch_size=64, device=device)\n",
    "# get_feature_count(loader)\n",
    "# criterion_mapping(criterion_choice: str, pos_weight: float = None, alpha: float = None, gamma: float = None)\n",
    "\n",
    "def maximise_combined_score(trial):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Using device:\", device)\n",
    "    epochs = 10000\n",
    "    random_state = 42\n",
    "\n",
    "    # # Oversampling method - Hardcoded to ADASYN\n",
    "    # oversampling_method = \"ADASYN\"\n",
    "\n",
    "    # # Parameters for ADASYN\n",
    "    # if oversampling_method == \"ADASYN\":\n",
    "    #     n_neighbours_adasyn = trial.suggest_int(\"n_neighbours_adasyn\", 3, 10)  # Tune n_neighbors for ADASYN\n",
    "    #     sampling_strategy_adasyn = trial.suggest_categorical(\"sampling_strategy_adasyn\",\n",
    "    #                                                         ['minority', 'auto'])  # Example of tuning sampling_strategy\n",
    "    #     oversampler = ADASYN(sampling_strategy=sampling_strategy_adasyn, n_neighbors=n_neighbours_adasyn,\n",
    "    #                         random_state=random_state)\n",
    "    # else:\n",
    "    #     oversampler = None  # Or handle default if needed\n",
    "\n",
    "    oversampler = SMOTE(sampling_strategy=\"minority\", k_neighbors=5, random_state=42)\n",
    "\n",
    "    noise = trial.suggest_float(\"noise\", 0.0, 0.2)\n",
    "    \n",
    "    # Outlier Detection Models (Example: Isolation Forest)\n",
    "    od_majority = IsolationForest(contamination=trial.suggest_float(\"contamination_majority\", 0.01, 0.1), random_state=random_state)\n",
    "    od_minority = IsolationForest(contamination=trial.suggest_float(\"contamination_minority\", 0.01, 0.1), random_state=random_state)\n",
    "\n",
    "    # Scaler\n",
    "    scaler = RobustScaler() # Or StandardScaler() - You can also make this a hyperparameter if you want\n",
    "\n",
    "    kFolds = FOLDS_GENERATOR(df,\n",
    "                               n_splits=5,\n",
    "                               oversampler=oversampler, random_state=42, noise=noise,\n",
    "                               OD_majority=od_majority, OD_minority=od_minority, scaler=scaler) # Pass outlier models and scaler\n",
    "\n",
    "    # Model hyperparameters (first-level optimization)\n",
    "    hidden_dim = trial.suggest_int(\"hidden_dim\", 64, 256, step=32)\n",
    "    hidden_dim2 = trial.suggest_int(\"hidden_dim2\", 32, hidden_dim, step=32)\n",
    "    output_dim = trial.suggest_int(\"output_dim\", 4, hidden_dim2, step=2)\n",
    "\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.0, 0.4)\n",
    "    threshold = trial.suggest_float(\"threshold\", 0.3, 0.8)\n",
    "    # dropout = None\n",
    "    initial_lr = trial.suggest_float(\"initial_lr\", 1e-4, 1e-4, log=True)\n",
    "    max_lr = trial.suggest_float(\"max_lr\", 1e-4, 1e-4, log=True)\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-6, 1e-3, log=True)\n",
    "\n",
    "    # Loss function hyperparameters\n",
    "    criterion_choice = \"FocalLoss\"\n",
    "    # Hyperparameter exploration optimization\n",
    "    if criterion_choice == \"BCEWithLogitsLoss\":\n",
    "        pos_weight = trial.suggest_int(\"pos_weight\", 1, 1)\n",
    "        alpha = None\n",
    "        gamma = None\n",
    "    elif criterion_choice == \"FocalLoss\":\n",
    "        pos_weight = None\n",
    "        alpha = trial.suggest_float(\"alpha\", 0.25, 0.75)\n",
    "        gamma = trial.suggest_float(\"gamma\", 1.0, 5.0)\n",
    "    else:\n",
    "        pos_weight = None\n",
    "\n",
    "    # Initialize lists for metrics across folds\n",
    "    accuracy_list = []\n",
    "    precision_list = []\n",
    "    recall_list = []\n",
    "    f1_list = []\n",
    "    auc_list = []\n",
    "\n",
    "    # Cross-validation loop\n",
    "    for fold, (train_x, test_x, train_y, test_y) in enumerate(kFolds, start=1):\n",
    "        print(f\"Fold {fold}:\")\n",
    "        # Create DataLoader for current fold\n",
    "        train_loader, val_loader = fold_to_dataloader_tensor(train_x, test_x, train_y, test_y, batch_size=64,\n",
    "                                                            device=device)\n",
    "        # Instantiate and initialize the model\n",
    "        model = MyModel(input_dim=get_feature_count(train_loader), hidden_dim=hidden_dim, hidden_dim2=hidden_dim2,\n",
    "                        output_dim=output_dim, dropout=dropout)\n",
    "        model.to(device)\n",
    "        model.apply(init_weights)\n",
    "\n",
    "        # Map the choice to the actual loss function\n",
    "        criterion = criterion_mapping(criterion_choice, pos_weight, alpha, gamma)\n",
    "        optimiser = optim.Adam(model.parameters(), lr=initial_lr, weight_decay=weight_decay)\n",
    "        scheduler = torch.optim.lr_scheduler.CyclicLR(\n",
    "            optimiser,\n",
    "            base_lr=1e-5,\n",
    "            max_lr=max_lr,\n",
    "            cycle_momentum=False)\n",
    "\n",
    "        # Train and evaluate the model on the current fold\n",
    "        model, accuracy, precision, recall, f1, auc = train_and_evaluate(\n",
    "            model, criterion, optimiser, scheduler, train_loader, val_loader, epochs=epochs, patience=100,\n",
    "            device=device, threshold=threshold\n",
    "        )\n",
    "        print(f\"Accuracy: {accuracy:.4f}, precision: {precision:.4f}, recall: {recall:.4f}, f1: {f1:.4f}, auc: {auc:.4f}\")\n",
    "        del model\n",
    "        del train_loader\n",
    "        del val_loader\n",
    "\n",
    "        # Append the metrics from the current fold\n",
    "        accuracy_list.append(accuracy)\n",
    "        precision_list.append(precision)\n",
    "        recall_list.append(recall)\n",
    "        f1_list.append(f1)\n",
    "        auc_list.append(auc)\n",
    "\n",
    "    # Calculate the average metrics across all folds\n",
    "    avg_accuracy = np.sum(accuracy_list) / len(accuracy_list)\n",
    "    avg_precision = np.sum(precision_list) / len(precision_list)\n",
    "    avg_recall = np.sum(recall_list) / len(recall_list)\n",
    "    avg_f1 = np.sum(f1_list) / len(f1_list)\n",
    "    avg_auc = np.sum(auc_list) / len(auc_list)\n",
    "\n",
    "    # Combine metrics into a single \"score\"\n",
    "    # combined_score = (avg_f1 + avg_precision + avg_recall + avg_accuracy + avg_auc) / 5\n",
    "    combined_score = avg_f1\n",
    "\n",
    "    return combined_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0bfde0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyModel(\n",
      "  (block1): FeedForwardBlock(\n",
      "    (block): Sequential(\n",
      "      (0): Linear(in_features=20, out_features=64, bias=True)\n",
      "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6()\n",
      "    )\n",
      "  )\n",
      "  (block2): FeedForwardBlock(\n",
      "    (block): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=16, bias=True)\n",
      "      (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6()\n",
      "      (3): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (block3): FeedForwardBlock(\n",
      "    (block): Sequential(\n",
      "      (0): Linear(in_features=16, out_features=4, bias=True)\n",
      "      (1): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6()\n",
      "      (3): Dropout(p=0.2, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (output_layer): Linear(in_features=4, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class FeedForwardBlock(nn.Module):\n",
    "    def __init__(self, in_features, out_features, dropout=None, activation=nn.ReLU6):\n",
    "        super().__init__()\n",
    "        layers = [\n",
    "            nn.Linear(in_features, out_features),\n",
    "            nn.BatchNorm1d(out_features),\n",
    "            activation()\n",
    "        ]\n",
    "        if dropout and dropout > 0:\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "        self.block = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "def print_activations(x, name):\n",
    "    print(f\"{name}: min={x.min().item()}, max={x.max().item()}\")\n",
    "    return x\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, dropout= None, hidden_dim2= None):\n",
    "        super().__init__()\n",
    "        \n",
    "        # A couple of FeedForward blocks\n",
    "        self.block1 = FeedForwardBlock(input_dim, hidden_dim, dropout= None)\n",
    "        self.block2 = FeedForwardBlock(hidden_dim, hidden_dim2, dropout = dropout/2)\n",
    "        self.block3 = FeedForwardBlock(hidden_dim2, output_dim, dropout)\n",
    "\n",
    "        # Final output layer (could be softmax, sigmoid, or whatever your target is)\n",
    "        self.output_layer = nn.Linear(output_dim, 1)  # Just in case you're doing regression or binary classification\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.block1(x)\n",
    "        # x = print_activations(x, \"after block1\")\n",
    "        x = self.block2(x)\n",
    "        # x = print_activations(x, \"after block2\")\n",
    "        x = self.block3(x)\n",
    "        # x = print_activations(x, \"after block3\")\n",
    "        x = self.output_layer(x)  # Final linear layer\n",
    "        return x\n",
    "\n",
    "#* Test the model\n",
    "test_model = MyModel(input_dim = 20,\n",
    "                     hidden_dim = 64,\n",
    "                     hidden_dim2 = 16,\n",
    "                     output_dim = 4,\n",
    "                     dropout = .2)\n",
    "print(test_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5187dc94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bottle v0.13.2 server starting up (using WSGIRefServer())...\n",
      "Listening on http://localhost:8080/\n",
      "Hit Ctrl-C to quit.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4129\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 4007\n",
      "After OD, minority: 424\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3583\n",
      "DR\n",
      "1.0    3583\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (8014, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    4007\n",
      "1.0    4007\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1149, 29)\n",
      "Fold: 1, Train: (8014, 29), Test: (1149, 29)\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4129\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 4007\n",
      "After OD, minority: 424\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3583\n",
      "DR\n",
      "1.0    3583\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (8014, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    4007\n",
      "1.0    4007\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1149, 29)\n",
      "Fold: 2, Train: (8014, 29), Test: (1149, 29)\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4130\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 4008\n",
      "After OD, minority: 424\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3584\n",
      "DR\n",
      "1.0    3584\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (8016, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    4008\n",
      "1.0    4008\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1148, 29)\n",
      "Fold: 3, Train: (8016, 29), Test: (1148, 29)\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4130\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 4008\n",
      "After OD, minority: 424\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3584\n",
      "DR\n",
      "1.0    3584\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (8016, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    4008\n",
      "1.0    4008\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1148, 29)\n",
      "Fold: 4, Train: (8016, 29), Test: (1148, 29)\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4130\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 4008\n",
      "After OD, minority: 424\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3584\n",
      "DR\n",
      "1.0    3584\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (8016, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    4008\n",
      "1.0    4008\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1148, 29)\n",
      "Fold: 5, Train: (8016, 29), Test: (1148, 29)\n",
      "Fold 1:\n",
      "Early stopping triggered at epoch 101, best val loss: 0.0966s: 0.613 Scheduler lr: [3.2500000000000004e-05]            \n",
      "Accuracy: 0.7659, precision: 0.2046, recall: 0.4569, f1: 0.2827, auc: 0.6287\n",
      "Fold 2:\n",
      "Early stopping triggered at epoch 101, best val loss: 0.3507s: 0.544 Scheduler lr: [3.2500000000000004e-05]            \n",
      "Accuracy: 0.7990, precision: 0.2249, recall: 0.4052, f1: 0.2892, auc: 0.6242\n",
      "Fold 3:\n",
      "Early stopping triggered at epoch 101, best val loss: 0.2737s: 0.591 Scheduler lr: [3.2500000000000004e-05]            \n",
      "Accuracy: 0.7639, precision: 0.2008, recall: 0.4483, f1: 0.2773, auc: 0.6238\n",
      "Fold 4:\n",
      "Early stopping triggered at epoch 101, best val loss: 0.1021s: 0.683 Scheduler lr: [3.2500000000000004e-05]            \n",
      "Accuracy: 0.7674, precision: 0.1760, recall: 0.3534, f1: 0.2350, auc: 0.5837\n",
      "Fold 5:\n",
      "Epoch: 100   training loss:0.481 best_val_loss:0.220 Val Loss: 0.610 Scheduler lr: [3.2500000000000004e-05]            \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-19 20:12:40,253] Trial 372 finished with value: 0.2660683270883844 and parameters: {'noise': 0.10835042056722323, 'contamination_majority': 0.029545754816802945, 'contamination_minority': 0.08522334622749295, 'hidden_dim': 128, 'hidden_dim2': 32, 'output_dim': 16, 'dropout': 0.3104723150803224, 'threshold': 0.6609806248636275, 'initial_lr': 0.0001, 'max_lr': 0.0001, 'weight_decay': 2.4380045183227757e-06, 'alpha': 0.26184933150189316, 'gamma': 2.08828401985302}. Best is trial 186 with value: 0.3760217983651226.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at epoch 101, best val loss: 0.2201\n",
      "Accuracy: 0.7866, precision: 0.1914, recall: 0.3448, f1: 0.2462, auc: 0.5905\n",
      "Using device: cpu\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4129\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 4052\n",
      "After OD, minority: 446\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3606\n",
      "DR\n",
      "1.0    3606\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (8104, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    4052\n",
      "1.0    4052\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1149, 29)\n",
      "Fold: 1, Train: (8104, 29), Test: (1149, 29)\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4129\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 4052\n",
      "After OD, minority: 446\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3606\n",
      "DR\n",
      "1.0    3606\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (8104, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    4052\n",
      "1.0    4052\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1149, 29)\n",
      "Fold: 2, Train: (8104, 29), Test: (1149, 29)\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4130\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 4053\n",
      "After OD, minority: 446\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3607\n",
      "DR\n",
      "1.0    3607\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (8106, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    4053\n",
      "1.0    4053\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1148, 29)\n",
      "Fold: 3, Train: (8106, 29), Test: (1148, 29)\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4130\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 4053\n",
      "After OD, minority: 446\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3607\n",
      "DR\n",
      "1.0    3607\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (8106, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    4053\n",
      "1.0    4053\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1148, 29)\n",
      "Fold: 4, Train: (8106, 29), Test: (1148, 29)\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4130\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 4053\n",
      "After OD, minority: 446\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3607\n",
      "DR\n",
      "1.0    3607\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (8106, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    4053\n",
      "1.0    4053\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1148, 29)\n",
      "Fold: 5, Train: (8106, 29), Test: (1148, 29)\n",
      "Fold 1:\n",
      "Early stopping triggered at epoch 101, best val loss: 0.2567s: 0.599 Scheduler lr: [3.7000000000000066e-05]            \n",
      "Accuracy: 0.7772, precision: 0.2388, recall: 0.5517, f1: 0.3333, auc: 0.6771\n",
      "Fold 2:\n",
      "Early stopping triggered at epoch 101, best val loss: 0.2096s: 0.593 Scheduler lr: [3.7000000000000066e-05]            \n",
      "Accuracy: 0.7398, precision: 0.2077, recall: 0.5603, f1: 0.3030, auc: 0.6601\n",
      "Fold 3:\n",
      "Early stopping triggered at epoch 101, best val loss: 0.0781s: 0.591 Scheduler lr: [3.7000000000000066e-05]            \n",
      "Accuracy: 0.7753, precision: 0.2042, recall: 0.4224, f1: 0.2753, auc: 0.6187\n",
      "Fold 4:\n",
      "Early stopping triggered at epoch 101, best val loss: 0.3170s: 0.598 Scheduler lr: [3.7000000000000066e-05]            \n",
      "Accuracy: 0.7936, precision: 0.2237, recall: 0.4224, f1: 0.2925, auc: 0.6288\n",
      "Fold 5:\n",
      "Epoch: 100   training loss:0.509 best_val_loss:0.112 Val Loss: 0.615 Scheduler lr: [3.7000000000000066e-05]            \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-19 20:15:18,280] Trial 373 finished with value: 0.29897590461829626 and parameters: {'noise': 0.09779109449284387, 'contamination_majority': 0.018449788644334927, 'contamination_minority': 0.03844547089600037, 'hidden_dim': 96, 'hidden_dim2': 32, 'output_dim': 16, 'dropout': 0.3026421601815699, 'threshold': 0.6326350552638221, 'initial_lr': 0.0001, 'max_lr': 0.0001, 'weight_decay': 5.3251201957563426e-06, 'alpha': 0.2609396313276586, 'gamma': 1.914988873406386}. Best is trial 186 with value: 0.3760217983651226.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at epoch 101, best val loss: 0.1122\n",
      "Accuracy: 0.7875, precision: 0.2193, recall: 0.4310, f1: 0.2907, auc: 0.6293\n",
      "Using device: cpu\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4129\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 3907\n",
      "After OD, minority: 433\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3474\n",
      "DR\n",
      "1.0    3474\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (7814, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    3907\n",
      "1.0    3907\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1149, 29)\n",
      "Fold: 1, Train: (7814, 29), Test: (1149, 29)\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4129\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 3907\n",
      "After OD, minority: 433\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3474\n",
      "DR\n",
      "1.0    3474\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (7814, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    3907\n",
      "1.0    3907\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1149, 29)\n",
      "Fold: 2, Train: (7814, 29), Test: (1149, 29)\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4130\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 3908\n",
      "After OD, minority: 433\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3475\n",
      "DR\n",
      "1.0    3475\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (7816, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    3908\n",
      "1.0    3908\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1148, 29)\n",
      "Fold: 3, Train: (7816, 29), Test: (1148, 29)\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4130\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 3908\n",
      "After OD, minority: 433\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3475\n",
      "DR\n",
      "1.0    3475\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (7816, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    3908\n",
      "1.0    3908\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1148, 29)\n",
      "Fold: 4, Train: (7816, 29), Test: (1148, 29)\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4130\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 3908\n",
      "After OD, minority: 433\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3475\n",
      "DR\n",
      "1.0    3475\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (7816, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    3908\n",
      "1.0    3908\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1148, 29)\n",
      "Fold: 5, Train: (7816, 29), Test: (1148, 29)\n",
      "Fold 1:\n",
      "Early stopping triggered at epoch 101, best val loss: 0.0979s: 0.616 Scheduler lr: [1.8999999999999967e-05]            \n",
      "Accuracy: 0.8007, precision: 0.2372, recall: 0.4397, f1: 0.3082, auc: 0.6404\n",
      "Fold 2:\n",
      "Early stopping triggered at epoch 101, best val loss: 0.1704s: 0.615 Scheduler lr: [1.8999999999999967e-05]            \n",
      "Accuracy: 0.7833, precision: 0.2194, recall: 0.4483, f1: 0.2946, auc: 0.6346\n",
      "Fold 3:\n",
      "Early stopping triggered at epoch 101, best val loss: 0.1871s: 0.616 Scheduler lr: [1.8999999999999967e-05]            \n",
      "Accuracy: 0.7814, precision: 0.2128, recall: 0.4310, f1: 0.2849, auc: 0.6259\n",
      "Fold 4:\n",
      "Early stopping triggered at epoch 101, best val loss: 0.1388s: 0.613 Scheduler lr: [1.8999999999999967e-05]            \n",
      "Accuracy: 0.7979, precision: 0.2315, recall: 0.4310, f1: 0.3012, auc: 0.6351\n",
      "Fold 5:\n",
      "Epoch: 100   training loss:0.488 best_val_loss:0.123 Val Loss: 0.621 Scheduler lr: [1.8999999999999967e-05]            \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-19 20:17:49,692] Trial 374 finished with value: 0.29172332194398365 and parameters: {'noise': 0.09140298191243562, 'contamination_majority': 0.05360391741760563, 'contamination_minority': 0.06684831017210989, 'hidden_dim': 96, 'hidden_dim2': 32, 'output_dim': 14, 'dropout': 0.307279638638952, 'threshold': 0.6790844032779271, 'initial_lr': 0.0001, 'max_lr': 0.0001, 'weight_decay': 2.8171622660201433e-06, 'alpha': 0.274917596541452, 'gamma': 1.7994276960145072}. Best is trial 186 with value: 0.3760217983651226.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at epoch 101, best val loss: 0.1228\n",
      "Accuracy: 0.8066, precision: 0.2181, recall: 0.3534, f1: 0.2697, auc: 0.6055\n",
      "Using device: cpu\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4129\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 3965\n",
      "After OD, minority: 442\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3523\n",
      "DR\n",
      "1.0    3523\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (7930, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    3965\n",
      "1.0    3965\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1149, 29)\n",
      "Fold: 1, Train: (7930, 29), Test: (1149, 29)\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4129\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 3965\n",
      "After OD, minority: 442\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3523\n",
      "DR\n",
      "1.0    3523\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (7930, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    3965\n",
      "1.0    3965\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1149, 29)\n",
      "Fold: 2, Train: (7930, 29), Test: (1149, 29)\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4130\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 3965\n",
      "After OD, minority: 442\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3523\n",
      "DR\n",
      "1.0    3523\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (7930, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    3965\n",
      "1.0    3965\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1148, 29)\n",
      "Fold: 3, Train: (7930, 29), Test: (1148, 29)\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4130\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 3965\n",
      "After OD, minority: 442\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3523\n",
      "DR\n",
      "1.0    3523\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (7930, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    3965\n",
      "1.0    3965\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1148, 29)\n",
      "Fold: 4, Train: (7930, 29), Test: (1148, 29)\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4130\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 3965\n",
      "After OD, minority: 442\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3523\n",
      "DR\n",
      "1.0    3523\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (7930, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    3965\n",
      "1.0    3965\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1148, 29)\n",
      "Fold: 5, Train: (7930, 29), Test: (1148, 29)\n",
      "Fold 1:\n",
      "Early stopping triggered at epoch 101, best val loss: 0.0921s: 0.636 Scheduler lr: [2.3500000000000036e-05]            \n",
      "Accuracy: 0.7415, precision: 0.2033, recall: 0.5345, f1: 0.2945, auc: 0.6496\n",
      "Fold 2:\n",
      "Early stopping triggered at epoch 101, best val loss: 0.1516s: 0.586 Scheduler lr: [2.3500000000000036e-05]            \n",
      "Accuracy: 0.7850, precision: 0.2236, recall: 0.4569, f1: 0.3003, auc: 0.6394\n",
      "Fold 3:\n",
      "Early stopping triggered at epoch 101, best val loss: 0.1533s: 0.627 Scheduler lr: [2.3500000000000036e-05]            \n",
      "Accuracy: 0.7822, precision: 0.2137, recall: 0.4310, f1: 0.2857, auc: 0.6264\n",
      "Fold 4:\n",
      "Early stopping triggered at epoch 101, best val loss: 0.3284s: 0.638 Scheduler lr: [2.3500000000000036e-05]            \n",
      "Accuracy: 0.7666, precision: 0.2121, recall: 0.4828, f1: 0.2947, auc: 0.6406\n",
      "Fold 5:\n",
      "Epoch: 100   training loss:0.472 best_val_loss:0.117 Val Loss: 0.640 Scheduler lr: [2.3500000000000036e-05]            \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-19 20:20:24,635] Trial 375 finished with value: 0.29128766795879646 and parameters: {'noise': 0.10187863464407144, 'contamination_majority': 0.039725284291119656, 'contamination_minority': 0.045968282792857654, 'hidden_dim': 160, 'hidden_dim2': 64, 'output_dim': 18, 'dropout': 0.3741084555480753, 'threshold': 0.6178464065224417, 'initial_lr': 0.0001, 'max_lr': 0.0001, 'weight_decay': 2.207506880291867e-06, 'alpha': 0.2614023783931377, 'gamma': 2.1726091968089585}. Best is trial 186 with value: 0.3760217983651226.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at epoch 101, best val loss: 0.1173\n",
      "Accuracy: 0.7639, precision: 0.2031, recall: 0.4569, f1: 0.2812, auc: 0.6277\n",
      "Using device: cpu\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4129\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 4069\n",
      "After OD, minority: 427\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3642\n",
      "DR\n",
      "1.0    3642\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (8138, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    4069\n",
      "1.0    4069\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1149, 29)\n",
      "Fold: 1, Train: (8138, 29), Test: (1149, 29)\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4129\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 4069\n",
      "After OD, minority: 427\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3642\n",
      "DR\n",
      "1.0    3642\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (8138, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    4069\n",
      "1.0    4069\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1149, 29)\n",
      "Fold: 2, Train: (8138, 29), Test: (1149, 29)\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4130\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 4070\n",
      "After OD, minority: 427\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3643\n",
      "DR\n",
      "1.0    3643\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (8140, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    4070\n",
      "1.0    4070\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1148, 29)\n",
      "Fold: 3, Train: (8140, 29), Test: (1148, 29)\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4130\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 4070\n",
      "After OD, minority: 427\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3643\n",
      "DR\n",
      "1.0    3643\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (8140, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    4070\n",
      "1.0    4070\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1148, 29)\n",
      "Fold: 4, Train: (8140, 29), Test: (1148, 29)\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4130\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 4070\n",
      "After OD, minority: 427\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3643\n",
      "DR\n",
      "1.0    3643\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (8140, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    4070\n",
      "1.0    4070\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1148, 29)\n",
      "Fold: 5, Train: (8140, 29), Test: (1148, 29)\n",
      "Fold 1:\n",
      "Early stopping triggered at epoch 101, best val loss: 0.1802s: 0.590 Scheduler lr: [4.149999999999997e-05]             \n",
      "Accuracy: 0.7650, precision: 0.2127, recall: 0.4914, f1: 0.2969, auc: 0.6436\n",
      "Fold 2:\n",
      "Early stopping triggered at epoch 101, best val loss: 0.3309s: 0.568 Scheduler lr: [4.149999999999997e-05]             \n",
      "Accuracy: 0.7815, precision: 0.2152, recall: 0.4397, f1: 0.2890, auc: 0.6298\n",
      "Fold 3:\n",
      "Early stopping triggered at epoch 101, best val loss: 0.0801s: 0.582 Scheduler lr: [4.149999999999997e-05]             \n",
      "Accuracy: 0.7805, precision: 0.2069, recall: 0.4138, f1: 0.2759, auc: 0.6177\n",
      "Fold 4:\n",
      "Early stopping triggered at epoch 101, best val loss: 0.0996s: 0.596 Scheduler lr: [4.149999999999997e-05]             \n",
      "Accuracy: 0.7779, precision: 0.1883, recall: 0.3621, f1: 0.2478, auc: 0.5933\n",
      "Fold 5:\n",
      "Epoch: 100   training loss:0.510 best_val_loss:0.167 Val Loss: 0.657 Scheduler lr: [4.149999999999997e-05]             \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-19 20:22:59,621] Trial 376 finished with value: 0.2754565577502055 and parameters: {'noise': 0.09511802148706994, 'contamination_majority': 0.014300352711247924, 'contamination_minority': 0.07813277989295112, 'hidden_dim': 96, 'hidden_dim2': 32, 'output_dim': 16, 'dropout': 0.3499587661367845, 'threshold': 0.6437930975126986, 'initial_lr': 0.0001, 'max_lr': 0.0001, 'weight_decay': 2.578758053257922e-06, 'alpha': 0.2707007603575886, 'gamma': 2.2700497806110618}. Best is trial 186 with value: 0.3760217983651226.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at epoch 101, best val loss: 0.1668\n",
      "Accuracy: 0.7761, precision: 0.2000, recall: 0.4052, f1: 0.2678, auc: 0.6115\n",
      "Using device: cpu\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4129\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 3984\n",
      "After OD, minority: 444\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3540\n",
      "DR\n",
      "1.0    3540\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (7968, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    3984\n",
      "1.0    3984\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1149, 29)\n",
      "Fold: 1, Train: (7968, 29), Test: (1149, 29)\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4129\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 3984\n",
      "After OD, minority: 444\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3540\n",
      "DR\n",
      "1.0    3540\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (7968, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    3984\n",
      "1.0    3984\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1149, 29)\n",
      "Fold: 2, Train: (7968, 29), Test: (1149, 29)\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4130\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 3985\n",
      "After OD, minority: 444\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3541\n",
      "DR\n",
      "1.0    3541\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (7970, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    3985\n",
      "1.0    3985\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1148, 29)\n",
      "Fold: 3, Train: (7970, 29), Test: (1148, 29)\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4130\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 3985\n",
      "After OD, minority: 444\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3541\n",
      "DR\n",
      "1.0    3541\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (7970, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    3985\n",
      "1.0    3985\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1148, 29)\n",
      "Fold: 4, Train: (7970, 29), Test: (1148, 29)\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4130\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 3985\n",
      "After OD, minority: 444\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3541\n",
      "DR\n",
      "1.0    3541\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (7970, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    3985\n",
      "1.0    3985\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1148, 29)\n",
      "Fold: 5, Train: (7970, 29), Test: (1148, 29)\n",
      "Fold 1:\n",
      "Early stopping triggered at epoch 101, best val loss: 0.2750s: 0.600 Scheduler lr: [2.7999999999999935e-05]            \n",
      "Accuracy: 0.7546, precision: 0.2138, recall: 0.5345, f1: 0.3054, auc: 0.6569\n",
      "Fold 2:\n",
      "Early stopping triggered at epoch 101, best val loss: 0.1055s: 0.592 Scheduler lr: [2.7999999999999935e-05]            \n",
      "Accuracy: 0.7285, precision: 0.2048, recall: 0.5862, f1: 0.3036, auc: 0.6653\n",
      "Fold 3:\n",
      "Early stopping triggered at epoch 101, best val loss: 0.1828s: 0.595 Scheduler lr: [2.7999999999999935e-05]            \n",
      "Accuracy: 0.7404, precision: 0.1926, recall: 0.4914, f1: 0.2767, auc: 0.6299\n",
      "Fold 4:\n",
      "Early stopping triggered at epoch 378, best val loss: 0.5532s: 0.642 Scheduler lr: [6.634000000000011e-05]             \n",
      "Accuracy: 0.7561, precision: 0.1917, recall: 0.4397, f1: 0.2670, auc: 0.6157\n",
      "Fold 5:\n",
      "Epoch: 100   training loss:0.525 best_val_loss:0.398 Val Loss: 0.584 Scheduler lr: [2.7999999999999935e-05]            \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-19 20:26:50,728] Trial 377 finished with value: 0.2878225301412078 and parameters: {'noise': 0.05150372472945547, 'contamination_majority': 0.035003650709749354, 'contamination_minority': 0.04210466960788894, 'hidden_dim': 64, 'hidden_dim2': 32, 'output_dim': 14, 'dropout': 0.3628572215550028, 'threshold': 0.5973223034896055, 'initial_lr': 0.0001, 'max_lr': 0.0001, 'weight_decay': 9.996176278981723e-06, 'alpha': 0.2616540715676343, 'gamma': 1.0530638035028386}. Best is trial 186 with value: 0.3760217983651226.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at epoch 101, best val loss: 0.3981\n",
      "Accuracy: 0.7439, precision: 0.1993, recall: 0.5086, f1: 0.2864, auc: 0.6395\n",
      "Using device: cpu\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4129\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 4035\n",
      "After OD, minority: 450\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3585\n",
      "DR\n",
      "1.0    3585\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (8070, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    4035\n",
      "1.0    4035\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1149, 29)\n",
      "Fold: 1, Train: (8070, 29), Test: (1149, 29)\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4129\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 4035\n",
      "After OD, minority: 450\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3585\n",
      "DR\n",
      "1.0    3585\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (8070, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    4035\n",
      "1.0    4035\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1149, 29)\n",
      "Fold: 2, Train: (8070, 29), Test: (1149, 29)\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4130\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 4036\n",
      "After OD, minority: 450\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3586\n",
      "DR\n",
      "1.0    3586\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (8072, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    4036\n",
      "1.0    4036\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1148, 29)\n",
      "Fold: 3, Train: (8072, 29), Test: (1148, 29)\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4130\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 4036\n",
      "After OD, minority: 450\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3586\n",
      "DR\n",
      "1.0    3586\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (8072, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    4036\n",
      "1.0    4036\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1148, 29)\n",
      "Fold: 4, Train: (8072, 29), Test: (1148, 29)\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4130\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 4036\n",
      "After OD, minority: 450\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3586\n",
      "DR\n",
      "1.0    3586\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (8072, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    4036\n",
      "1.0    4036\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1148, 29)\n",
      "Fold: 5, Train: (8072, 29), Test: (1148, 29)\n",
      "Fold 1:\n",
      "Early stopping triggered at epoch 101, best val loss: 0.1240s: 0.567 Scheduler lr: [3.7000000000000066e-05]            \n",
      "Accuracy: 0.7406, precision: 0.2226, recall: 0.6293, f1: 0.3288, auc: 0.6912\n",
      "Fold 2:\n",
      "Early stopping triggered at epoch 101, best val loss: 0.2188s: 0.602 Scheduler lr: [3.7000000000000066e-05]            \n",
      "Accuracy: 0.7433, precision: 0.1903, recall: 0.4741, f1: 0.2716, auc: 0.6238\n",
      "Fold 3:\n",
      "Early stopping triggered at epoch 101, best val loss: 0.0619s: 0.588 Scheduler lr: [3.7000000000000066e-05]            \n",
      "Accuracy: 0.7317, precision: 0.2000, recall: 0.5517, f1: 0.2936, auc: 0.6518\n",
      "Fold 4:\n",
      "Early stopping triggered at epoch 101, best val loss: 0.1155s: 0.577 Scheduler lr: [3.7000000000000066e-05]            \n",
      "Accuracy: 0.7587, precision: 0.1962, recall: 0.4483, f1: 0.2730, auc: 0.6209\n",
      "Fold 5:\n",
      "Epoch: 100   training loss:0.485 best_val_loss:0.202 Val Loss: 0.619 Scheduler lr: [3.7000000000000066e-05]            \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-19 20:29:24,373] Trial 378 finished with value: 0.2906819577641844 and parameters: {'noise': 0.046467010469864824, 'contamination_majority': 0.02271739901839484, 'contamination_minority': 0.028335623084163805, 'hidden_dim': 128, 'hidden_dim2': 32, 'output_dim': 16, 'dropout': 0.3348438672567847, 'threshold': 0.5698164725283504, 'initial_lr': 0.0001, 'max_lr': 0.0001, 'weight_decay': 1.4690949733222596e-05, 'alpha': 0.2857866142897278, 'gamma': 2.09077711013869}. Best is trial 186 with value: 0.3760217983651226.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at epoch 101, best val loss: 0.2025\n",
      "Accuracy: 0.7526, precision: 0.2021, recall: 0.4914, f1: 0.2864, auc: 0.6367\n",
      "Using device: cpu\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4129\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 3795\n",
      "After OD, minority: 438\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3357\n",
      "DR\n",
      "1.0    3357\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (7590, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    3795\n",
      "1.0    3795\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1149, 29)\n",
      "Fold: 1, Train: (7590, 29), Test: (1149, 29)\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4129\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 3795\n",
      "After OD, minority: 438\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3357\n",
      "DR\n",
      "1.0    3357\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (7590, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    3795\n",
      "1.0    3795\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1149, 29)\n",
      "Fold: 2, Train: (7590, 29), Test: (1149, 29)\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4130\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 3796\n",
      "After OD, minority: 438\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3358\n",
      "DR\n",
      "1.0    3358\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (7592, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    3796\n",
      "1.0    3796\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1148, 29)\n",
      "Fold: 3, Train: (7592, 29), Test: (1148, 29)\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4130\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 3796\n",
      "After OD, minority: 438\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3358\n",
      "DR\n",
      "1.0    3358\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (7592, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    3796\n",
      "1.0    3796\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1148, 29)\n",
      "Fold: 4, Train: (7592, 29), Test: (1148, 29)\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4130\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 3796\n",
      "After OD, minority: 438\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3358\n",
      "DR\n",
      "1.0    3358\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (7592, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    3796\n",
      "1.0    3796\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1148, 29)\n",
      "Fold: 5, Train: (7592, 29), Test: (1148, 29)\n",
      "Fold 1:\n",
      "Early stopping triggered at epoch 101, best val loss: 0.3748s: 0.645 Scheduler lr: [1.8999999999999967e-05]            \n",
      "Accuracy: 0.8042, precision: 0.2620, recall: 0.5172, f1: 0.3478, auc: 0.6768\n",
      "Fold 2:\n",
      "Early stopping triggered at epoch 101, best val loss: 0.2530s: 0.654 Scheduler lr: [1.8999999999999967e-05]            \n",
      "Accuracy: 0.7894, precision: 0.2284, recall: 0.4569, f1: 0.3046, auc: 0.6418\n",
      "Fold 3:\n",
      "Early stopping triggered at epoch 101, best val loss: 0.2174s: 0.664 Scheduler lr: [1.8999999999999967e-05]            \n",
      "Accuracy: 0.7953, precision: 0.2233, recall: 0.4138, f1: 0.2900, auc: 0.6260\n",
      "Fold 4:\n",
      "Early stopping triggered at epoch 101, best val loss: 0.1220s: 0.664 Scheduler lr: [1.8999999999999967e-05]            \n",
      "Accuracy: 0.7718, precision: 0.2126, recall: 0.4655, f1: 0.2919, auc: 0.6359\n",
      "Fold 5:\n",
      "Epoch: 100   training loss:0.496 best_val_loss:0.122 Val Loss: 0.607 Scheduler lr: [1.8999999999999967e-05]            \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-19 20:31:51,020] Trial 379 finished with value: 0.3041900505697836 and parameters: {'noise': 0.0633796505865331, 'contamination_majority': 0.0808108527018307, 'contamination_minority': 0.05561329898670978, 'hidden_dim': 96, 'hidden_dim2': 32, 'output_dim': 12, 'dropout': 0.31875277423583515, 'threshold': 0.6697519225090818, 'initial_lr': 0.0001, 'max_lr': 0.0001, 'weight_decay': 3.062619611875207e-06, 'alpha': 0.26052603043330924, 'gamma': 2.0844159979808223}. Best is trial 186 with value: 0.3760217983651226.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at epoch 101, best val loss: 0.1223\n",
      "Accuracy: 0.8005, precision: 0.2244, recall: 0.3966, f1: 0.2866, auc: 0.6212\n",
      "Using device: cpu\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4129\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 3873\n",
      "After OD, minority: 458\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3415\n",
      "DR\n",
      "1.0    3415\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (7746, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    3873\n",
      "1.0    3873\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1149, 29)\n",
      "Fold: 1, Train: (7746, 29), Test: (1149, 29)\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4129\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 3873\n",
      "After OD, minority: 458\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3415\n",
      "DR\n",
      "1.0    3415\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (7746, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    3873\n",
      "1.0    3873\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1149, 29)\n",
      "Fold: 2, Train: (7746, 29), Test: (1149, 29)\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4130\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 3874\n",
      "After OD, minority: 458\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3416\n",
      "DR\n",
      "1.0    3416\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (7748, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    3874\n",
      "1.0    3874\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1148, 29)\n",
      "Fold: 3, Train: (7748, 29), Test: (1148, 29)\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4130\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 3874\n",
      "After OD, minority: 458\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3416\n",
      "DR\n",
      "1.0    3416\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (7748, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    3874\n",
      "1.0    3874\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1148, 29)\n",
      "Fold: 4, Train: (7748, 29), Test: (1148, 29)\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4130\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 3874\n",
      "After OD, minority: 458\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3416\n",
      "DR\n",
      "1.0    3416\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (7748, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    3874\n",
      "1.0    3874\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1148, 29)\n",
      "Fold: 5, Train: (7748, 29), Test: (1148, 29)\n",
      "Fold 1:\n",
      "Early stopping triggered at epoch 101, best val loss: 0.0940s: 0.617 Scheduler lr: [1.4500000000000064e-05]            \n",
      "Accuracy: 0.7720, precision: 0.2374, recall: 0.5690, f1: 0.3350, auc: 0.6819\n",
      "Fold 2:\n",
      "Early stopping triggered at epoch 101, best val loss: 0.1145s: 0.624 Scheduler lr: [1.4500000000000064e-05]            \n",
      "Accuracy: 0.7511, precision: 0.2089, recall: 0.5259, f1: 0.2990, auc: 0.6511\n",
      "Fold 3:\n",
      "Early stopping triggered at epoch 101, best val loss: 0.0566s: 0.652 Scheduler lr: [1.4500000000000064e-05]            \n",
      "Accuracy: 0.7770, precision: 0.2287, recall: 0.5086, f1: 0.3155, auc: 0.6579\n",
      "Fold 4:\n",
      "Early stopping triggered at epoch 101, best val loss: 0.3609s: 0.689 Scheduler lr: [1.4500000000000064e-05]            \n",
      "Accuracy: 0.7744, precision: 0.2239, recall: 0.5000, f1: 0.3093, auc: 0.6526\n",
      "Fold 5:\n",
      "Epoch: 100   training loss:0.522 best_val_loss:0.136 Val Loss: 0.591 Scheduler lr: [1.4500000000000064e-05]            \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-19 20:34:19,676] Trial 380 finished with value: 0.3174664182156182 and parameters: {'noise': 0.12199189509986613, 'contamination_majority': 0.06191789342639787, 'contamination_minority': 0.012298695312932553, 'hidden_dim': 64, 'hidden_dim2': 32, 'output_dim': 14, 'dropout': 0.3556347305888206, 'threshold': 0.6263672853150598, 'initial_lr': 0.0001, 'max_lr': 0.0001, 'weight_decay': 3.8094680858354213e-06, 'alpha': 0.270850539138205, 'gamma': 1.906918464714619}. Best is trial 186 with value: 0.3760217983651226.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at epoch 101, best val loss: 0.1363\n",
      "Accuracy: 0.8005, precision: 0.2489, recall: 0.4828, f1: 0.3284, auc: 0.6595\n",
      "Using device: cpu\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4129\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 4019\n",
      "After OD, minority: 452\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3567\n",
      "DR\n",
      "1.0    3567\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (8038, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    4019\n",
      "1.0    4019\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1149, 29)\n",
      "Fold: 1, Train: (8038, 29), Test: (1149, 29)\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4129\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 4019\n",
      "After OD, minority: 452\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3567\n",
      "DR\n",
      "1.0    3567\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (8038, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    4019\n",
      "1.0    4019\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1149, 29)\n",
      "Fold: 2, Train: (8038, 29), Test: (1149, 29)\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4130\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 4020\n",
      "After OD, minority: 452\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3568\n",
      "DR\n",
      "1.0    3568\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (8040, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    4020\n",
      "1.0    4020\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1148, 29)\n",
      "Fold: 3, Train: (8040, 29), Test: (1148, 29)\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4130\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 4020\n",
      "After OD, minority: 452\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3568\n",
      "DR\n",
      "1.0    3568\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (8040, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    4020\n",
      "1.0    4020\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1148, 29)\n",
      "Fold: 4, Train: (8040, 29), Test: (1148, 29)\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4130\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 4020\n",
      "After OD, minority: 452\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3568\n",
      "DR\n",
      "1.0    3568\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (8040, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    4020\n",
      "1.0    4020\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1148, 29)\n",
      "Fold: 5, Train: (8040, 29), Test: (1148, 29)\n",
      "Fold 1:\n",
      "Early stopping triggered at epoch 101, best val loss: 0.0665s: 0.598 Scheduler lr: [3.2500000000000004e-05]            \n",
      "Accuracy: 0.8233, precision: 0.2649, recall: 0.4224, f1: 0.3256, auc: 0.6454\n",
      "Fold 2:\n",
      "Early stopping triggered at epoch 101, best val loss: 0.0900s: 0.567 Scheduler lr: [3.2500000000000004e-05]            \n",
      "Accuracy: 0.8181, precision: 0.2216, recall: 0.3190, f1: 0.2615, auc: 0.5966\n",
      "Fold 3:\n",
      "Early stopping triggered at epoch 101, best val loss: 0.1020s: 0.623 Scheduler lr: [3.2500000000000004e-05]            \n",
      "Accuracy: 0.8031, precision: 0.2250, recall: 0.3879, f1: 0.2848, auc: 0.6189\n",
      "Fold 4:\n",
      "Early stopping triggered at epoch 101, best val loss: 0.2140s: 0.616 Scheduler lr: [3.2500000000000004e-05]            \n",
      "Accuracy: 0.8145, precision: 0.2513, recall: 0.4224, f1: 0.3151, auc: 0.6405\n",
      "Fold 5:\n",
      "Epoch: 100   training loss:0.497 best_val_loss:0.334 Val Loss: 0.573 Scheduler lr: [3.2500000000000004e-05]            \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-19 20:36:55,278] Trial 381 finished with value: 0.2900292111601626 and parameters: {'noise': 0.12914187178670214, 'contamination_majority': 0.026545734755385287, 'contamination_minority': 0.02443642740264373, 'hidden_dim': 96, 'hidden_dim2': 64, 'output_dim': 10, 'dropout': 0.3863899576081594, 'threshold': 0.7010272303455395, 'initial_lr': 0.0001, 'max_lr': 0.0001, 'weight_decay': 1.973184552082458e-06, 'alpha': 0.26102931571952415, 'gamma': 1.8280085843206837}. Best is trial 186 with value: 0.3760217983651226.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at epoch 101, best val loss: 0.3336\n",
      "Accuracy: 0.8293, precision: 0.2333, recall: 0.3017, f1: 0.2632, auc: 0.5951\n",
      "Using device: cpu\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4129\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 3942\n",
      "After OD, minority: 434\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3508\n",
      "DR\n",
      "1.0    3508\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (7884, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    3942\n",
      "1.0    3942\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1149, 29)\n",
      "Fold: 1, Train: (7884, 29), Test: (1149, 29)\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4129\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 3942\n",
      "After OD, minority: 434\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3508\n",
      "DR\n",
      "1.0    3508\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (7884, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    3942\n",
      "1.0    3942\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1149, 29)\n",
      "Fold: 2, Train: (7884, 29), Test: (1149, 29)\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4130\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 3943\n",
      "After OD, minority: 434\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3509\n",
      "DR\n",
      "1.0    3509\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (7886, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    3943\n",
      "1.0    3943\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1148, 29)\n",
      "Fold: 3, Train: (7886, 29), Test: (1148, 29)\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4130\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 3943\n",
      "After OD, minority: 434\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3509\n",
      "DR\n",
      "1.0    3509\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (7886, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    3943\n",
      "1.0    3943\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1148, 29)\n",
      "Fold: 4, Train: (7886, 29), Test: (1148, 29)\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4130\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 3943\n",
      "After OD, minority: 434\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3509\n",
      "DR\n",
      "1.0    3509\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (7886, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    3943\n",
      "1.0    3943\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1148, 29)\n",
      "Fold: 5, Train: (7886, 29), Test: (1148, 29)\n",
      "Fold 1:\n",
      "Early stopping triggered at epoch 101, best val loss: 0.0543s: 0.602 Scheduler lr: [2.3500000000000036e-05]            \n",
      "Accuracy: 0.7868, precision: 0.2278, recall: 0.4655, f1: 0.3059, auc: 0.6442\n",
      "Fold 2:\n",
      "Early stopping triggered at epoch 101, best val loss: 0.0249s: 0.549 Scheduler lr: [2.3500000000000036e-05]            \n",
      "Accuracy: 0.8172, precision: 0.2418, recall: 0.3793, f1: 0.2953, auc: 0.6229\n",
      "Fold 3:\n",
      "Early stopping triggered at epoch 101, best val loss: 0.0467s: 0.634 Scheduler lr: [2.3500000000000036e-05]            \n",
      "Accuracy: 0.7892, precision: 0.2162, recall: 0.4138, f1: 0.2840, auc: 0.6226\n",
      "Fold 4:\n",
      "Early stopping triggered at epoch 101, best val loss: 0.0231s: 0.587 Scheduler lr: [2.3500000000000036e-05]            \n",
      "Accuracy: 0.8197, precision: 0.2593, recall: 0.4224, f1: 0.3213, auc: 0.6434\n",
      "Fold 5:\n",
      "Epoch: 100   training loss:0.514 best_val_loss:0.080 Val Loss: 0.586 Scheduler lr: [2.3500000000000036e-05]            \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-19 20:39:24,912] Trial 382 finished with value: 0.29529647194838365 and parameters: {'noise': 0.0784029926630946, 'contamination_majority': 0.04520709881428564, 'contamination_minority': 0.06281043670962466, 'hidden_dim': 64, 'hidden_dim2': 32, 'output_dim': 14, 'dropout': 0.34339482032944785, 'threshold': 0.6854891017295993, 'initial_lr': 0.0001, 'max_lr': 0.0001, 'weight_decay': 1.5862065154490242e-06, 'alpha': 0.27958559834274654, 'gamma': 4.8020383755436296}. Best is trial 186 with value: 0.3760217983651226.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at epoch 101, best val loss: 0.0804\n",
      "Accuracy: 0.8162, precision: 0.2254, recall: 0.3362, f1: 0.2699, auc: 0.6032\n",
      "Using device: cpu\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4129\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 3818\n",
      "After OD, minority: 436\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3382\n",
      "DR\n",
      "1.0    3382\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (7636, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    3818\n",
      "1.0    3818\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1149, 29)\n",
      "Fold: 1, Train: (7636, 29), Test: (1149, 29)\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4129\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 3818\n",
      "After OD, minority: 436\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3382\n",
      "DR\n",
      "1.0    3382\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (7636, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    3818\n",
      "1.0    3818\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1149, 29)\n",
      "Fold: 2, Train: (7636, 29), Test: (1149, 29)\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4130\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 3819\n",
      "After OD, minority: 436\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3383\n",
      "DR\n",
      "1.0    3383\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (7638, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    3819\n",
      "1.0    3819\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1148, 29)\n",
      "Fold: 3, Train: (7638, 29), Test: (1148, 29)\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4130\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 3819\n",
      "After OD, minority: 436\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3383\n",
      "DR\n",
      "1.0    3383\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (7638, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    3819\n",
      "1.0    3819\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1148, 29)\n",
      "Fold: 4, Train: (7638, 29), Test: (1148, 29)\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4130\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 3819\n",
      "After OD, minority: 436\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3383\n",
      "DR\n",
      "1.0    3383\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (7638, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    3819\n",
      "1.0    3819\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1148, 29)\n",
      "Fold: 5, Train: (7638, 29), Test: (1148, 29)\n",
      "Fold 1:\n",
      "Early stopping triggered at epoch 101, best val loss: 0.1417s: 0.599 Scheduler lr: [1.4499999999999985e-05]            \n",
      "Accuracy: 0.7868, precision: 0.2410, recall: 0.5172, f1: 0.3288, auc: 0.6671\n",
      "Fold 2:\n",
      "Early stopping triggered at epoch 101, best val loss: 0.1567s: 0.599 Scheduler lr: [1.4499999999999985e-05]            \n",
      "Accuracy: 0.7755, precision: 0.2290, recall: 0.5172, f1: 0.3175, auc: 0.6608\n",
      "Fold 3:\n",
      "Early stopping triggered at epoch 264, best val loss: 0.6122s: 0.738 Scheduler lr: [4.163500000000013e-05]             \n",
      "Accuracy: 0.7587, precision: 0.1892, recall: 0.4224, f1: 0.2613, auc: 0.6095\n",
      "Fold 4:\n",
      "Early stopping triggered at epoch 101, best val loss: 0.2682s: 0.639 Scheduler lr: [1.4499999999999985e-05]            \n",
      "Accuracy: 0.7753, precision: 0.2160, recall: 0.4655, f1: 0.2951, auc: 0.6378\n",
      "Fold 5:\n",
      "Epoch: 100   training loss:0.497 best_val_loss:0.330 Val Loss: 0.595 Scheduler lr: [1.4499999999999985e-05]            \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-19 20:42:38,822] Trial 383 finished with value: 0.3012096628099709 and parameters: {'noise': 0.0871490504220909, 'contamination_majority': 0.07529668348859905, 'contamination_minority': 0.05877034297128753, 'hidden_dim': 96, 'hidden_dim2': 32, 'output_dim': 14, 'dropout': 0.37672657273414856, 'threshold': 0.6540110306456082, 'initial_lr': 0.0001, 'max_lr': 0.0001, 'weight_decay': 1.8403266702372338e-05, 'alpha': 0.2609854746949904, 'gamma': 1.9164574606721245}. Best is trial 186 with value: 0.3760217983651226.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at epoch 101, best val loss: 0.3297\n",
      "Accuracy: 0.8040, precision: 0.2367, recall: 0.4224, f1: 0.3034, auc: 0.6347\n",
      "Using device: cpu\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4129\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 3917\n",
      "After OD, minority: 422\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3495\n",
      "DR\n",
      "1.0    3495\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (7834, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    3917\n",
      "1.0    3917\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1149, 29)\n",
      "Fold: 1, Train: (7834, 29), Test: (1149, 29)\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4129\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 3917\n",
      "After OD, minority: 422\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3495\n",
      "DR\n",
      "1.0    3495\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (7834, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    3917\n",
      "1.0    3917\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1149, 29)\n",
      "Fold: 2, Train: (7834, 29), Test: (1149, 29)\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4130\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 3918\n",
      "After OD, minority: 422\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3496\n",
      "DR\n",
      "1.0    3496\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (7836, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    3918\n",
      "1.0    3918\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1148, 29)\n",
      "Fold: 3, Train: (7836, 29), Test: (1148, 29)\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4130\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 3918\n",
      "After OD, minority: 422\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3496\n",
      "DR\n",
      "1.0    3496\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (7836, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    3918\n",
      "1.0    3918\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1148, 29)\n",
      "Fold: 4, Train: (7836, 29), Test: (1148, 29)\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4130\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 3918\n",
      "After OD, minority: 422\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3496\n",
      "DR\n",
      "1.0    3496\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (7836, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    3918\n",
      "1.0    3918\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1148, 29)\n",
      "Fold: 5, Train: (7836, 29), Test: (1148, 29)\n",
      "Fold 1:\n",
      "Early stopping triggered at epoch 101, best val loss: 0.2720s: 0.593 Scheduler lr: [1.8999999999999967e-05]            \n",
      "Accuracy: 0.7485, precision: 0.2182, recall: 0.5776, f1: 0.3168, auc: 0.6726\n",
      "Fold 2:\n",
      "Early stopping triggered at epoch 101, best val loss: 0.2023s: 0.569 Scheduler lr: [1.8999999999999967e-05]            \n",
      "Accuracy: 0.7493, precision: 0.2095, recall: 0.5345, f1: 0.3010, auc: 0.6540\n",
      "Fold 3:\n",
      "Early stopping triggered at epoch 101, best val loss: 0.1946s: 0.639 Scheduler lr: [1.8999999999999967e-05]            \n",
      "Accuracy: 0.7343, precision: 0.1961, recall: 0.5259, f1: 0.2857, auc: 0.6418\n",
      "Fold 4:\n",
      "Early stopping triggered at epoch 101, best val loss: 0.1022s: 0.581 Scheduler lr: [1.8999999999999967e-05]            \n",
      "Accuracy: 0.7291, precision: 0.1803, recall: 0.4741, f1: 0.2613, auc: 0.6159\n",
      "Fold 5:\n",
      "Epoch: 100   training loss:0.512 best_val_loss:0.136 Val Loss: 0.667 Scheduler lr: [1.8999999999999967e-05]            \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-19 20:45:08,477] Trial 384 finished with value: 0.28475520887487005 and parameters: {'noise': 0.06817517972514996, 'contamination_majority': 0.05113185570924678, 'contamination_minority': 0.09021113034971895, 'hidden_dim': 64, 'hidden_dim2': 32, 'output_dim': 20, 'dropout': 0.3643361138398215, 'threshold': 0.5858775052689703, 'initial_lr': 0.0001, 'max_lr': 0.0001, 'weight_decay': 1.2599110836551111e-05, 'alpha': 0.2708482480915445, 'gamma': 1.742893267957576}. Best is trial 186 with value: 0.3760217983651226.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at epoch 101, best val loss: 0.1361\n",
      "Accuracy: 0.6960, precision: 0.1718, recall: 0.5259, f1: 0.2590, auc: 0.6205\n",
      "Using device: cpu\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4129\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 3896\n",
      "After OD, minority: 439\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3457\n",
      "DR\n",
      "1.0    3457\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (7792, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    3896\n",
      "1.0    3896\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1149, 29)\n",
      "Fold: 1, Train: (7792, 29), Test: (1149, 29)\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4129\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 3896\n",
      "After OD, minority: 439\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3457\n",
      "DR\n",
      "1.0    3457\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (7792, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    3896\n",
      "1.0    3896\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1149, 29)\n",
      "Fold: 2, Train: (7792, 29), Test: (1149, 29)\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4130\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 3897\n",
      "After OD, minority: 439\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3458\n",
      "DR\n",
      "1.0    3458\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (7794, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    3897\n",
      "1.0    3897\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1148, 29)\n",
      "Fold: 3, Train: (7794, 29), Test: (1148, 29)\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4130\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 3897\n",
      "After OD, minority: 439\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3458\n",
      "DR\n",
      "1.0    3458\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (7794, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    3897\n",
      "1.0    3897\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1148, 29)\n",
      "Fold: 4, Train: (7794, 29), Test: (1148, 29)\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4130\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 3897\n",
      "After OD, minority: 439\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3458\n",
      "DR\n",
      "1.0    3458\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (7794, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    3897\n",
      "1.0    3897\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1148, 29)\n",
      "Fold: 5, Train: (7794, 29), Test: (1148, 29)\n",
      "Fold 1:\n",
      "Early stopping triggered at epoch 101, best val loss: 0.0767s: 0.609 Scheduler lr: [1.4500000000000064e-05]            \n",
      "Accuracy: 0.7624, precision: 0.2145, recall: 0.5086, f1: 0.3018, auc: 0.6498\n",
      "Fold 2:\n",
      "Early stopping triggered at epoch 101, best val loss: 0.0831s: 0.600 Scheduler lr: [1.4500000000000064e-05]            \n",
      "Accuracy: 0.7746, precision: 0.2105, recall: 0.4483, f1: 0.2865, auc: 0.6298\n",
      "Fold 3:\n",
      "Early stopping triggered at epoch 101, best val loss: 0.1108s: 0.595 Scheduler lr: [1.4500000000000064e-05]            \n",
      "Accuracy: 0.7700, precision: 0.2016, recall: 0.4310, f1: 0.2747, auc: 0.6196\n",
      "Fold 4:\n",
      "Early stopping triggered at epoch 101, best val loss: 0.0848s: 0.642 Scheduler lr: [1.4500000000000064e-05]            \n",
      "Accuracy: 0.7509, precision: 0.1964, recall: 0.4741, f1: 0.2778, auc: 0.6281\n",
      "Fold 5:\n",
      "Epoch: 100   training loss:0.469 best_val_loss:0.094 Val Loss: 0.598 Scheduler lr: [1.4500000000000064e-05]            \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-19 20:47:39,413] Trial 385 finished with value: 0.28435728935612686 and parameters: {'noise': 0.060629921195571215, 'contamination_majority': 0.05629415413530761, 'contamination_minority': 0.051852328420047195, 'hidden_dim': 128, 'hidden_dim2': 96, 'output_dim': 8, 'dropout': 0.32507979275463694, 'threshold': 0.6037306785915846, 'initial_lr': 0.0001, 'max_lr': 0.0001, 'weight_decay': 2.3331890237183102e-06, 'alpha': 0.7300197171363594, 'gamma': 2.081601177913083}. Best is trial 186 with value: 0.3760217983651226.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at epoch 101, best val loss: 0.0942\n",
      "Accuracy: 0.7726, precision: 0.2065, recall: 0.4397, f1: 0.2810, auc: 0.6249\n",
      "Using device: cpu\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4129\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 3810\n",
      "After OD, minority: 429\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3381\n",
      "DR\n",
      "1.0    3381\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (7620, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    3810\n",
      "1.0    3810\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1149, 29)\n",
      "Fold: 1, Train: (7620, 29), Test: (1149, 29)\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4129\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 3810\n",
      "After OD, minority: 429\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3381\n",
      "DR\n",
      "1.0    3381\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (7620, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    3810\n",
      "1.0    3810\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1149, 29)\n",
      "Fold: 2, Train: (7620, 29), Test: (1149, 29)\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4130\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 3811\n",
      "After OD, minority: 429\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3382\n",
      "DR\n",
      "1.0    3382\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (7622, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    3811\n",
      "1.0    3811\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1148, 29)\n",
      "Fold: 3, Train: (7622, 29), Test: (1148, 29)\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4130\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 3811\n",
      "After OD, minority: 429\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3382\n",
      "DR\n",
      "1.0    3382\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (7622, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    3811\n",
      "1.0    3811\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1148, 29)\n",
      "Fold: 4, Train: (7622, 29), Test: (1148, 29)\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4130\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 3811\n",
      "After OD, minority: 429\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3382\n",
      "DR\n",
      "1.0    3382\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (7622, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    3811\n",
      "1.0    3811\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1148, 29)\n",
      "Fold: 5, Train: (7622, 29), Test: (1148, 29)\n",
      "Fold 1:\n",
      "Early stopping triggered at epoch 101, best val loss: 0.2629s: 0.655 Scheduler lr: [1.4499999999999985e-05]            \n",
      "Accuracy: 0.7842, precision: 0.2273, recall: 0.4741, f1: 0.3073, auc: 0.6466\n",
      "Fold 2:\n",
      "Early stopping triggered at epoch 101, best val loss: 0.0743s: 0.662 Scheduler lr: [1.4499999999999985e-05]            \n",
      "Accuracy: 0.7459, precision: 0.2027, recall: 0.5172, f1: 0.2913, auc: 0.6444\n",
      "Fold 3:\n",
      "Early stopping triggered at epoch 101, best val loss: 0.2085s: 0.631 Scheduler lr: [1.4499999999999985e-05]            \n",
      "Accuracy: 0.7831, precision: 0.2044, recall: 0.3966, f1: 0.2698, auc: 0.6116\n",
      "Fold 4:\n",
      "Early stopping triggered at epoch 101, best val loss: 0.4728s: 0.614 Scheduler lr: [1.4499999999999985e-05]            \n",
      "Accuracy: 0.7970, precision: 0.2146, recall: 0.3793, f1: 0.2741, auc: 0.6117\n",
      "Fold 5:\n",
      "Epoch: 100   training loss:0.487 best_val_loss:0.113 Val Loss: 0.619 Scheduler lr: [1.4499999999999985e-05]            \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-19 20:50:07,819] Trial 386 finished with value: 0.2836207509968136 and parameters: {'noise': 0.05453933323860114, 'contamination_majority': 0.07710603366803784, 'contamination_minority': 0.07396828362249139, 'hidden_dim': 96, 'hidden_dim2': 32, 'output_dim': 12, 'dropout': 0.2743555443643348, 'threshold': 0.6763751404980817, 'initial_lr': 0.0001, 'max_lr': 0.0001, 'weight_decay': 7.359617571430806e-06, 'alpha': 0.25982346153182884, 'gamma': 2.1579533079313316}. Best is trial 186 with value: 0.3760217983651226.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at epoch 101, best val loss: 0.1132\n",
      "Accuracy: 0.8031, precision: 0.2194, recall: 0.3707, f1: 0.2756, auc: 0.6112\n",
      "Using device: cpu\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4129\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 3848\n",
      "After OD, minority: 449\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3399\n",
      "DR\n",
      "1.0    3399\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (7696, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    3848\n",
      "1.0    3848\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1149, 29)\n",
      "Fold: 1, Train: (7696, 29), Test: (1149, 29)\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4129\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 3848\n",
      "After OD, minority: 449\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3399\n",
      "DR\n",
      "1.0    3399\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (7696, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    3848\n",
      "1.0    3848\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1149, 29)\n",
      "Fold: 2, Train: (7696, 29), Test: (1149, 29)\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4130\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 3849\n",
      "After OD, minority: 449\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3400\n",
      "DR\n",
      "1.0    3400\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (7698, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    3849\n",
      "1.0    3849\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1148, 29)\n",
      "Fold: 3, Train: (7698, 29), Test: (1148, 29)\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4130\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 3849\n",
      "After OD, minority: 449\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3400\n",
      "DR\n",
      "1.0    3400\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (7698, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    3849\n",
      "1.0    3849\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1148, 29)\n",
      "Fold: 4, Train: (7698, 29), Test: (1148, 29)\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4130\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 3849\n",
      "After OD, minority: 449\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3400\n",
      "DR\n",
      "1.0    3400\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (7698, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    3849\n",
      "1.0    3849\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1148, 29)\n",
      "Fold: 5, Train: (7698, 29), Test: (1148, 29)\n",
      "Fold 1:\n",
      "Early stopping triggered at epoch 101, best val loss: 0.2938s: 0.597 Scheduler lr: [1e-05]                             \n",
      "Accuracy: 0.7963, precision: 0.2479, recall: 0.5000, f1: 0.3314, auc: 0.6648\n",
      "Fold 2:\n",
      "Early stopping triggered at epoch 101, best val loss: 0.0912s: 0.667 Scheduler lr: [1e-05]                             \n",
      "Accuracy: 0.7319, precision: 0.1943, recall: 0.5259, f1: 0.2837, auc: 0.6405\n",
      "Fold 3:\n",
      "Early stopping triggered at epoch 101, best val loss: 0.1502s: 0.581 Scheduler lr: [1e-05]                             \n",
      "Accuracy: 0.8127, precision: 0.2462, recall: 0.4138, f1: 0.3087, auc: 0.6357\n",
      "Fold 4:\n",
      "Early stopping triggered at epoch 101, best val loss: 0.1424s: 0.606 Scheduler lr: [1e-05]                             \n",
      "Accuracy: 0.7848, precision: 0.2305, recall: 0.4828, f1: 0.3120, auc: 0.6508\n",
      "Fold 5:\n",
      "Epoch: 100   training loss:0.502 best_val_loss:0.283 Val Loss: 0.626 Scheduler lr: [1e-05]                             \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-19 20:52:35,195] Trial 387 finished with value: 0.3093840001350803 and parameters: {'noise': 0.11346088269107032, 'contamination_majority': 0.06786342254435931, 'contamination_minority': 0.03236079348707309, 'hidden_dim': 96, 'hidden_dim2': 32, 'output_dim': 14, 'dropout': 0.3555766117007662, 'threshold': 0.6625296224545638, 'initial_lr': 0.0001, 'max_lr': 0.0001, 'weight_decay': 1.9998123907631955e-06, 'alpha': 0.296385729690008, 'gamma': 1.913015422151413}. Best is trial 186 with value: 0.3760217983651226.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at epoch 101, best val loss: 0.2834\n",
      "Accuracy: 0.7840, precision: 0.2295, recall: 0.4828, f1: 0.3111, auc: 0.6503\n",
      "Using device: cpu\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4129\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 3756\n",
      "After OD, minority: 454\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3302\n",
      "DR\n",
      "1.0    3302\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (7512, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    3756\n",
      "1.0    3756\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1149, 29)\n",
      "Fold: 1, Train: (7512, 29), Test: (1149, 29)\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4129\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 3756\n",
      "After OD, minority: 454\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3302\n",
      "DR\n",
      "1.0    3302\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (7512, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    3756\n",
      "1.0    3756\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1149, 29)\n",
      "Fold: 2, Train: (7512, 29), Test: (1149, 29)\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4130\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 3757\n",
      "After OD, minority: 454\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3303\n",
      "DR\n",
      "1.0    3303\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (7514, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    3757\n",
      "1.0    3757\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1148, 29)\n",
      "Fold: 3, Train: (7514, 29), Test: (1148, 29)\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4130\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 3757\n",
      "After OD, minority: 454\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3303\n",
      "DR\n",
      "1.0    3303\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (7514, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    3757\n",
      "1.0    3757\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1148, 29)\n",
      "Fold: 4, Train: (7514, 29), Test: (1148, 29)\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4130\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 3757\n",
      "After OD, minority: 454\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3303\n",
      "DR\n",
      "1.0    3303\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (7514, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    3757\n",
      "1.0    3757\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1148, 29)\n",
      "Fold: 5, Train: (7514, 29), Test: (1148, 29)\n",
      "Fold 1:\n",
      "Early stopping triggered at epoch 101, best val loss: 0.1246s: 0.681 Scheduler lr: [2.3500000000000036e-05]            \n",
      "Accuracy: 0.7659, precision: 0.2198, recall: 0.5172, f1: 0.3085, auc: 0.6555\n",
      "Fold 2:\n",
      "Early stopping triggered at epoch 101, best val loss: 0.2030s: 0.707 Scheduler lr: [2.3500000000000036e-05]            \n",
      "Accuracy: 0.7598, precision: 0.2080, recall: 0.4914, f1: 0.2923, auc: 0.6407\n",
      "Fold 3:\n",
      "Early stopping triggered at epoch 101, best val loss: 0.2017s: 0.696 Scheduler lr: [2.3500000000000036e-05]            \n",
      "Accuracy: 0.7726, precision: 0.2134, recall: 0.4655, f1: 0.2927, auc: 0.6363\n",
      "Fold 4:\n",
      "Early stopping triggered at epoch 101, best val loss: 0.3744s: 0.763 Scheduler lr: [2.3500000000000036e-05]            \n",
      "Accuracy: 0.7517, precision: 0.2014, recall: 0.4914, f1: 0.2857, auc: 0.6362\n",
      "Fold 5:\n",
      "Epoch: 100   training loss:0.546 best_val_loss:0.243 Val Loss: 0.732 Scheduler lr: [2.3500000000000036e-05]            \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-19 20:54:58,969] Trial 388 finished with value: 0.29330242780033 and parameters: {'noise': 0.0720516816796202, 'contamination_majority': 0.09025461097910031, 'contamination_minority': 0.020701016676937835, 'hidden_dim': 64, 'hidden_dim2': 32, 'output_dim': 16, 'dropout': 0.34647959521210847, 'threshold': 0.6410159550994524, 'initial_lr': 0.0001, 'max_lr': 0.0001, 'weight_decay': 1.610985443275502e-05, 'alpha': 0.26077344298720617, 'gamma': 2.192786716822537}. Best is trial 186 with value: 0.3760217983651226.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at epoch 101, best val loss: 0.2427\n",
      "Accuracy: 0.7796, precision: 0.2134, recall: 0.4397, f1: 0.2873, auc: 0.6287\n",
      "Using device: cpu\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4129\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 3774\n",
      "After OD, minority: 446\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3328\n",
      "DR\n",
      "1.0    3328\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (7548, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    3774\n",
      "1.0    3774\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1149, 29)\n",
      "Fold: 1, Train: (7548, 29), Test: (1149, 29)\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4129\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 3774\n",
      "After OD, minority: 446\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3328\n",
      "DR\n",
      "1.0    3328\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (7548, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    3774\n",
      "1.0    3774\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1149, 29)\n",
      "Fold: 2, Train: (7548, 29), Test: (1149, 29)\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4130\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 3775\n",
      "After OD, minority: 446\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3329\n",
      "DR\n",
      "1.0    3329\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (7550, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    3775\n",
      "1.0    3775\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1148, 29)\n",
      "Fold: 3, Train: (7550, 29), Test: (1148, 29)\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4130\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 3775\n",
      "After OD, minority: 446\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3329\n",
      "DR\n",
      "1.0    3329\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (7550, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    3775\n",
      "1.0    3775\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1148, 29)\n",
      "Fold: 4, Train: (7550, 29), Test: (1148, 29)\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4130\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 3775\n",
      "After OD, minority: 446\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3329\n",
      "DR\n",
      "1.0    3329\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (7550, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    3775\n",
      "1.0    3775\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1148, 29)\n",
      "Fold: 5, Train: (7550, 29), Test: (1148, 29)\n",
      "Fold 1:\n",
      "Early stopping triggered at epoch 101, best val loss: 0.0883s: 0.670 Scheduler lr: [2.3500000000000036e-05]            \n",
      "Accuracy: 0.8138, precision: 0.2500, recall: 0.4224, f1: 0.3141, auc: 0.6401\n",
      "Fold 2:\n",
      "Early stopping triggered at epoch 101, best val loss: 0.1174s: 0.714 Scheduler lr: [2.3500000000000036e-05]            \n",
      "Accuracy: 0.7824, precision: 0.2112, recall: 0.4224, f1: 0.2816, auc: 0.6226\n",
      "Fold 3:\n",
      "Early stopping triggered at epoch 101, best val loss: 0.3551s: 0.708 Scheduler lr: [2.3500000000000036e-05]            \n",
      "Accuracy: 0.8031, precision: 0.2135, recall: 0.3534, f1: 0.2662, auc: 0.6036\n",
      "Fold 4:\n",
      "Early stopping triggered at epoch 101, best val loss: 0.1694s: 0.699 Scheduler lr: [2.3500000000000036e-05]            \n",
      "Accuracy: 0.7901, precision: 0.2271, recall: 0.4483, f1: 0.3014, auc: 0.6384\n",
      "Fold 5:\n",
      "Epoch: 100   training loss:0.482 best_val_loss:0.181 Val Loss: 0.630 Scheduler lr: [2.3500000000000036e-05]            \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-19 20:57:25,358] Trial 389 finished with value: 0.2907647688010476 and parameters: {'noise': 0.09799024379788907, 'contamination_majority': 0.08583641671946232, 'contamination_minority': 0.03805011260704845, 'hidden_dim': 96, 'hidden_dim2': 64, 'output_dim': 18, 'dropout': 0.33503991144297035, 'threshold': 0.7154781281597243, 'initial_lr': 0.0001, 'max_lr': 0.0001, 'weight_decay': 4.335773861456956e-06, 'alpha': 0.27235039955975143, 'gamma': 2.0837172636170855}. Best is trial 186 with value: 0.3760217983651226.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at epoch 101, best val loss: 0.1807\n",
      "Accuracy: 0.8127, precision: 0.2353, recall: 0.3793, f1: 0.2904, auc: 0.6204\n",
      "Using device: cpu\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4129\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 3868\n",
      "After OD, minority: 440\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3428\n",
      "DR\n",
      "1.0    3428\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (7736, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    3868\n",
      "1.0    3868\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1149, 29)\n",
      "Fold: 1, Train: (7736, 29), Test: (1149, 29)\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4129\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 3868\n",
      "After OD, minority: 440\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3428\n",
      "DR\n",
      "1.0    3428\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (7736, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    3868\n",
      "1.0    3868\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1149, 29)\n",
      "Fold: 2, Train: (7736, 29), Test: (1149, 29)\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4130\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 3869\n",
      "After OD, minority: 440\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3429\n",
      "DR\n",
      "1.0    3429\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (7738, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    3869\n",
      "1.0    3869\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1148, 29)\n",
      "Fold: 3, Train: (7738, 29), Test: (1148, 29)\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4130\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 3869\n",
      "After OD, minority: 440\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3429\n",
      "DR\n",
      "1.0    3429\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (7738, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    3869\n",
      "1.0    3869\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1148, 29)\n",
      "Fold: 4, Train: (7738, 29), Test: (1148, 29)\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4130\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 3869\n",
      "After OD, minority: 440\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3429\n",
      "DR\n",
      "1.0    3429\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (7738, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    3869\n",
      "1.0    3869\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1148, 29)\n",
      "Fold: 5, Train: (7738, 29), Test: (1148, 29)\n",
      "Fold 1:\n",
      "Early stopping triggered at epoch 101, best val loss: 0.2423s: 0.612 Scheduler lr: [1e-05]                             \n",
      "Accuracy: 0.8129, precision: 0.2381, recall: 0.3879, f1: 0.2951, auc: 0.6243\n",
      "Fold 2:\n",
      "Early stopping triggered at epoch 101, best val loss: 0.0814s: 0.594 Scheduler lr: [1e-05]                             \n",
      "Accuracy: 0.7937, precision: 0.2077, recall: 0.3707, f1: 0.2663, auc: 0.6060\n",
      "Fold 3:\n",
      "Early stopping triggered at epoch 101, best val loss: 0.2287s: 0.590 Scheduler lr: [1e-05]                             \n",
      "Accuracy: 0.8197, precision: 0.2370, recall: 0.3534, f1: 0.2837, auc: 0.6128\n",
      "Fold 4:\n",
      "Early stopping triggered at epoch 101, best val loss: 0.0957s: 0.616 Scheduler lr: [1e-05]                             \n",
      "Accuracy: 0.8110, precision: 0.2560, recall: 0.4569, f1: 0.3282, auc: 0.6538\n",
      "Fold 5:\n",
      "Epoch: 100   training loss:0.516 best_val_loss:0.063 Val Loss: 0.637 Scheduler lr: [1e-05]                             \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-19 20:59:52,544] Trial 390 finished with value: 0.29572709151469956 and parameters: {'noise': 0.0824181245934378, 'contamination_majority': 0.06313820902042062, 'contamination_minority': 0.050151040491882834, 'hidden_dim': 64, 'hidden_dim2': 32, 'output_dim': 14, 'dropout': 0.3700485127711045, 'threshold': 0.6964446928863567, 'initial_lr': 0.0001, 'max_lr': 0.0001, 'weight_decay': 1.4415642529802693e-06, 'alpha': 0.5314558909035842, 'gamma': 1.9109117933016937}. Best is trial 186 with value: 0.3760217983651226.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at epoch 101, best val loss: 0.0629\n",
      "Accuracy: 0.7979, precision: 0.2339, recall: 0.4397, f1: 0.3054, auc: 0.6389\n",
      "Using device: cpu\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4129\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 3884\n",
      "After OD, minority: 417\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3467\n",
      "DR\n",
      "1.0    3467\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (7768, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    3884\n",
      "1.0    3884\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1149, 29)\n",
      "Fold: 1, Train: (7768, 29), Test: (1149, 29)\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4129\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 3884\n",
      "After OD, minority: 417\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3467\n",
      "DR\n",
      "1.0    3467\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (7768, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    3884\n",
      "1.0    3884\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1149, 29)\n",
      "Fold: 2, Train: (7768, 29), Test: (1149, 29)\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4130\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 3885\n",
      "After OD, minority: 417\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3468\n",
      "DR\n",
      "1.0    3468\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (7770, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    3885\n",
      "1.0    3885\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1148, 29)\n",
      "Fold: 3, Train: (7770, 29), Test: (1148, 29)\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4130\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 3885\n",
      "After OD, minority: 417\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3468\n",
      "DR\n",
      "1.0    3468\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (7770, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    3885\n",
      "1.0    3885\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1148, 29)\n",
      "Fold: 4, Train: (7770, 29), Test: (1148, 29)\n",
      "Original class distribution:\n",
      "DR\n",
      "0.0    4130\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "After OD, majority: 3885\n",
      "After OD, minority: 417\n",
      "\n",
      "Applying SMOTENC oversampling...\n",
      "\n",
      "Synthetic Samples Statistics (before processing):\n",
      "Number of synthetic samples generated: 3468\n",
      "DR\n",
      "1.0    3468\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape:\n",
      "Train/Resampled data shape: (7770, 29)\n",
      "Class distribution in final preprocessed data:\n",
      "DR\n",
      "0.0    3885\n",
      "1.0    3885\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test data shape after preprocessing: (1148, 29)\n",
      "Fold: 5, Train: (7770, 29), Test: (1148, 29)\n",
      "Fold 1:\n",
      "Early stopping triggered at epoch 101, best val loss: 0.0677s: 0.601 Scheduler lr: [1.4500000000000064e-05]            \n",
      "Accuracy: 0.7433, precision: 0.2046, recall: 0.5345, f1: 0.2959, auc: 0.6506\n",
      "Fold 2:\n",
      "Epoch: 33    training loss:0.531 best_val_loss:0.088 Val Loss: 0.552 Scheduler lr: [1.0314999999999987e-05]            \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-04-19 21:00:35,692] Trial 391 failed with parameters: {'noise': 0.04404934868476605, 'contamination_majority': 0.05916053976984549, 'contamination_minority': 0.09967952857256879, 'hidden_dim': 128, 'hidden_dim2': 32, 'output_dim': 12, 'dropout': 0.3933588239971092, 'threshold': 0.6307883441465651, 'initial_lr': 0.0001, 'max_lr': 0.0001, 'weight_decay': 2.6953930386429522e-06, 'alpha': 0.26152046727069156, 'gamma': 2.0913875058071643} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\ADL\\ADL\\venv\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\ciont\\AppData\\Local\\Temp\\ipykernel_6872\\1183512598.py\", line 97, in maximise_combined_score\n",
      "    model, accuracy, precision, recall, f1, auc = train_and_evaluate(\n",
      "                                                  ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\ciont\\AppData\\Local\\Temp\\ipykernel_6872\\109133456.py\", line 28, in train_and_evaluate\n",
      "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
      "  File \"d:\\ADL\\ADL\\venv\\Lib\\site-packages\\torch\\nn\\utils\\clip_grad.py\", line 34, in _no_grad_wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\ADL\\ADL\\venv\\Lib\\site-packages\\torch\\nn\\utils\\clip_grad.py\", line 215, in clip_grad_norm_\n",
      "    total_norm = _get_total_norm(grads, norm_type, error_if_nonfinite, foreach)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\ADL\\ADL\\venv\\Lib\\site-packages\\torch\\nn\\utils\\clip_grad.py\", line 34, in _no_grad_wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\ADL\\ADL\\venv\\Lib\\site-packages\\torch\\nn\\utils\\clip_grad.py\", line 87, in _get_total_norm\n",
      "    norms.extend(torch._foreach_norm(device_tensors, norm_type))\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2025-04-19 21:00:35,727] Trial 391 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mDR\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m df.columns:\n\u001b[32m     23\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33mDR\u001b[39m\u001b[33m'\u001b[39m\u001b[33m column is missing in the DataFrame. Please ensure it is present before running the optimization.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaximise_combined_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# Print results\u001b[39;00m\n\u001b[32m     28\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBest trial:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\ADL\\ADL\\venv\\Lib\\site-packages\\optuna\\study\\study.py:475\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    373\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    374\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    375\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    382\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    383\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    384\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    385\u001b[39m \n\u001b[32m    386\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    473\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    474\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m475\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    476\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    477\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    478\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    479\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\ADL\\ADL\\venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:63\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     62\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     76\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\ADL\\ADL\\venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:160\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    157\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m     frozen_trial = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    162\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    163\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\ADL\\ADL\\venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:248\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    241\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    243\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    244\u001b[39m     frozen_trial.state == TrialState.FAIL\n\u001b[32m    245\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    246\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    247\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m248\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\ADL\\ADL\\venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:197\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    196\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m197\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    198\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    199\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    200\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 97\u001b[39m, in \u001b[36mmaximise_combined_score\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m     90\u001b[39m scheduler = torch.optim.lr_scheduler.CyclicLR(\n\u001b[32m     91\u001b[39m     optimiser,\n\u001b[32m     92\u001b[39m     base_lr=\u001b[32m1e-5\u001b[39m,\n\u001b[32m     93\u001b[39m     max_lr=max_lr,\n\u001b[32m     94\u001b[39m     cycle_momentum=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     96\u001b[39m \u001b[38;5;66;03m# Train and evaluate the model on the current fold\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m model, accuracy, precision, recall, f1, auc = \u001b[43mtrain_and_evaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     98\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimiser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m=\u001b[49m\u001b[43mthreshold\u001b[49m\n\u001b[32m    100\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    101\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAccuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, precision: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprecision\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, recall: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrecall\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, f1: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf1\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, auc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mauc\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m model\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 28\u001b[39m, in \u001b[36mtrain_and_evaluate\u001b[39m\u001b[34m(model, criterion, optimiser, scheduler, train_loader, val_loader, epochs, patience, device, threshold)\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch.isnan(loss).any(), \u001b[33m\"\u001b[39m\u001b[33mModel loss has NaNs\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     27\u001b[39m loss.backward() \u001b[38;5;66;03m#? Backpropagation\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mutils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclip_grad_norm_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_norm\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1.0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m running_loss += loss.item()\n\u001b[32m     30\u001b[39m optimiser.step() \u001b[38;5;66;03m#? Update weights\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\ADL\\ADL\\venv\\Lib\\site-packages\\torch\\nn\\utils\\clip_grad.py:34\u001b[39m, in \u001b[36m_no_grad.<locals>._no_grad_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_no_grad_wrapper\u001b[39m(*args, **kwargs):\n\u001b[32m     33\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\ADL\\ADL\\venv\\Lib\\site-packages\\torch\\nn\\utils\\clip_grad.py:215\u001b[39m, in \u001b[36mclip_grad_norm_\u001b[39m\u001b[34m(parameters, max_norm, norm_type, error_if_nonfinite, foreach)\u001b[39m\n\u001b[32m    213\u001b[39m     parameters = \u001b[38;5;28mlist\u001b[39m(parameters)\n\u001b[32m    214\u001b[39m grads = [p.grad \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m parameters \u001b[38;5;28;01mif\u001b[39;00m p.grad \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[32m--> \u001b[39m\u001b[32m215\u001b[39m total_norm = \u001b[43m_get_total_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_if_nonfinite\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforeach\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    216\u001b[39m _clip_grads_with_norm_(parameters, max_norm, total_norm, foreach)\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m total_norm\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\ADL\\ADL\\venv\\Lib\\site-packages\\torch\\nn\\utils\\clip_grad.py:34\u001b[39m, in \u001b[36m_no_grad.<locals>._no_grad_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_no_grad_wrapper\u001b[39m(*args, **kwargs):\n\u001b[32m     33\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\ADL\\ADL\\venv\\Lib\\site-packages\\torch\\nn\\utils\\clip_grad.py:87\u001b[39m, in \u001b[36m_get_total_norm\u001b[39m\u001b[34m(tensors, norm_type, error_if_nonfinite, foreach)\u001b[39m\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m (device, _), ([device_tensors], _) \u001b[38;5;129;01min\u001b[39;00m grouped_tensors.items():\n\u001b[32m     84\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (foreach \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m _has_foreach_support(device_tensors, device)) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m     85\u001b[39m         foreach \u001b[38;5;129;01mand\u001b[39;00m _device_has_foreach_support(device)\n\u001b[32m     86\u001b[39m     ):\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m         norms.extend(\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_foreach_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice_tensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm_type\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     88\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m foreach:\n\u001b[32m     89\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m     90\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mforeach=True was passed, but can\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt use the foreach API on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice.type\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m tensors\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     91\u001b[39m         )\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import optuna\n",
    "from optuna_dashboard import run_server\n",
    "# !fuser -k 8080/tcp\n",
    "\n",
    "# Define your persistent storage\n",
    "storage = \"sqlite:///opt6.db\"\n",
    "\n",
    "# Create or load your study\n",
    "study_name = \"optuna6\"\n",
    "try:\n",
    "    study = optuna.load_study(study_name=study_name, storage=storage)\n",
    "except KeyError:\n",
    "    study = optuna.create_study(study_name=study_name, direction=\"maximize\", storage=storage)\n",
    "\n",
    "# Start Optuna Dashboard in a separate thread\n",
    "dashboard_thread = threading.Thread(target=lambda: run_server(storage), daemon=True)\n",
    "dashboard_thread.start()\n",
    "\n",
    "# Run optimization\n",
    "# Ensure the 'DR' column exists in the DataFrame\n",
    "if 'DR' not in df.columns:\n",
    "    raise KeyError(\"'DR' column is missing in the DataFrame. Please ensure it is present before running the optimization.\")\n",
    "\n",
    "study.optimize(maximise_combined_score, n_trials=100)\n",
    "\n",
    "# Print results\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(f\"  Combined score: {trial.value}\")\n",
    "print(\"  Best hyperparameters:\")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec695f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
