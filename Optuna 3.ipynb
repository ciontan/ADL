{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9230c445-891b-41ec-83f2-7f3d6c14d0af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (1.26.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: optuna in /home/jovyan/.local/lib/python3.11/site-packages (4.2.1)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /opt/conda/lib/python3.11/site-packages (from optuna) (1.12.1)\n",
      "Requirement already satisfied: colorlog in /home/jovyan/.local/lib/python3.11/site-packages (from optuna) (6.9.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from optuna) (1.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from optuna) (23.2)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /opt/conda/lib/python3.11/site-packages (from optuna) (2.0.23)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from optuna) (4.66.1)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.11/site-packages (from optuna) (6.0.1)\n",
      "Requirement already satisfied: Mako in /opt/conda/lib/python3.11/site-packages (from alembic>=1.5.0->optuna) (1.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4 in /opt/conda/lib/python3.11/site-packages (from alembic>=1.5.0->optuna) (4.8.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.11/site-packages (from sqlalchemy>=1.4.2->optuna) (3.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /opt/conda/lib/python3.11/site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.3)\n",
      "Requirement already satisfied: optuna-dashboard in /home/jovyan/.local/lib/python3.11/site-packages (0.18.0)\n",
      "Requirement already satisfied: bottle>=0.13.0 in /home/jovyan/.local/lib/python3.11/site-packages (from optuna-dashboard) (0.13.2)\n",
      "Requirement already satisfied: optuna>=3.1.0 in /home/jovyan/.local/lib/python3.11/site-packages (from optuna-dashboard) (4.2.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from optuna-dashboard) (23.2)\n",
      "Requirement already satisfied: scikit-learn in /home/jovyan/.local/lib/python3.11/site-packages (from optuna-dashboard) (1.6.1)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /opt/conda/lib/python3.11/site-packages (from optuna>=3.1.0->optuna-dashboard) (1.12.1)\n",
      "Requirement already satisfied: colorlog in /home/jovyan/.local/lib/python3.11/site-packages (from optuna>=3.1.0->optuna-dashboard) (6.9.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from optuna>=3.1.0->optuna-dashboard) (1.26.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /opt/conda/lib/python3.11/site-packages (from optuna>=3.1.0->optuna-dashboard) (2.0.23)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from optuna>=3.1.0->optuna-dashboard) (4.66.1)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.11/site-packages (from optuna>=3.1.0->optuna-dashboard) (6.0.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/jovyan/.local/lib/python3.11/site-packages (from scikit-learn->optuna-dashboard) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/jovyan/.local/lib/python3.11/site-packages (from scikit-learn->optuna-dashboard) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/jovyan/.local/lib/python3.11/site-packages (from scikit-learn->optuna-dashboard) (3.6.0)\n",
      "Requirement already satisfied: Mako in /opt/conda/lib/python3.11/site-packages (from alembic>=1.5.0->optuna>=3.1.0->optuna-dashboard) (1.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4 in /opt/conda/lib/python3.11/site-packages (from alembic>=1.5.0->optuna>=3.1.0->optuna-dashboard) (4.8.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.11/site-packages (from sqlalchemy>=1.4.2->optuna>=3.1.0->optuna-dashboard) (3.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /opt/conda/lib/python3.11/site-packages (from Mako->alembic>=1.5.0->optuna>=3.1.0->optuna-dashboard) (2.1.3)\n",
      "ERROR: unknown command \"installl\" - maybe you meant \"install\"\n",
      "Requirement already satisfied: imbalanced-learn in /opt/conda/lib/python3.11/site-packages (0.13.0)\n",
      "Requirement already satisfied: numpy<3,>=1.24.3 in /opt/conda/lib/python3.11/site-packages (from imbalanced-learn) (1.26.0)\n",
      "Requirement already satisfied: scipy<2,>=1.10.1 in /home/jovyan/.local/lib/python3.11/site-packages (from imbalanced-learn) (1.15.2)\n",
      "Requirement already satisfied: scikit-learn<2,>=1.3.2 in /home/jovyan/.local/lib/python3.11/site-packages (from imbalanced-learn) (1.6.1)\n",
      "Requirement already satisfied: sklearn-compat<1,>=0.1 in /opt/conda/lib/python3.11/site-packages (from imbalanced-learn) (0.1.3)\n",
      "Requirement already satisfied: joblib<2,>=1.1.1 in /home/jovyan/.local/lib/python3.11/site-packages (from imbalanced-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in /home/jovyan/.local/lib/python3.11/site-packages (from imbalanced-learn) (3.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install optuna\n",
    "!pip install optuna-dashboard\n",
    "!pip installl scikit\n",
    "!pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "255c0953",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import (\n",
    "    MaxAbsScaler,\n",
    "    MinMaxScaler,\n",
    "    Normalizer,\n",
    "    PowerTransformer,\n",
    "    QuantileTransformer,\n",
    "    RobustScaler,\n",
    "    StandardScaler,\n",
    "    minmax_scale,\n",
    ")\n",
    "from sklearn.metrics import recall_score, accuracy_score,f1_score, precision_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from imblearn.pipeline import Pipeline\n",
    "import warnings\n",
    "import optuna\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cbd367d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "random_state = 42\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "raw_dataset = pd.read_csv(\"./data/processed_data.csv\") #data has X and Y\n",
    "X = raw_dataset.drop(columns=[\"DR\"])\n",
    "Y = pd.DataFrame(raw_dataset[\"DR\"])\n",
    "\n",
    "#* 90/10 split for training and final test\n",
    "X_FOR_FOLDS, X_FINAL_TEST, Y_FOR_FOLDS, Y_FINAL_TEST = train_test_split(X, Y, test_size=0.1, random_state=random_state, stratify=Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81efd19",
   "metadata": {},
   "source": [
    "Helper functions that don't need tweakin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7e54029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from modularModels1 import BlockMaker, modularNN, BasicModel\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using\", device)\n",
    "\n",
    "def init_weights(model): #tested already\n",
    "    if isinstance(model, nn.Linear):  # Apply only to linear layers\n",
    "        nn.init.xavier_uniform_(model.weight)\n",
    "        if model.bias is not None:\n",
    "            nn.init.zeros_(model.bias)\n",
    "            \n",
    "def fold_to_dataloader_tensor(train_x, test_x, train_y, test_y, batch_size=64, device=device):\n",
    "    train_dataset = TensorDataset(\n",
    "        torch.tensor(train_x.values,dtype=torch.float32).to(device), \n",
    "        torch.tensor(train_y.values,dtype=torch.float32).to(device))\n",
    "    val_dataset = TensorDataset(\n",
    "        torch.tensor(test_x.values,dtype=torch.float32).to(device), \n",
    "        torch.tensor(test_y.values,dtype=torch.float32).to(device))\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=len(val_dataset), shuffle=False)\n",
    "    return train_loader, val_loader \n",
    "\n",
    "def get_feature_count(loader):\n",
    "    \"\"\"returns the number of features in the dataset\"\"\"\n",
    "    return next(iter(loader))[0].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a19d07a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Criterion_Models import *\n",
    "def criterion_mapping(criterion_choice:str, pos_weight:float=None, alpha:float=None, gamma:float=None):\n",
    "    \"\"\"\n",
    "    Feel free to add any custom loss functions here.\n",
    "    returns function for criterion\n",
    "    \"\"\"\n",
    "    if criterion_choice == \"FocalLoss\":\n",
    "        return FocalLoss(alpha =alpha, gamma=gamma)\n",
    "    elif criterion_choice == \"DiceLoss\":\n",
    "        return DiceLoss()\n",
    "    elif criterion_choice == \"BCEWithLogitsLoss\":\n",
    "        return nn.BCEWithLogitsLoss(pos_weight=torch.tensor([pos_weight])) if pos_weight else nn.BCEWithLogitsLoss()\n",
    "    return nn.BCEWithLogitsLoss() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86721b4d",
   "metadata": {},
   "source": [
    "Helper functions that could use tweakin to improve model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8673bf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FOLDS_GENERATOR(X, Y, normalisation_method=MinMaxScaler(), n_splits=5, random_state=None, oversampler=None):\n",
    "    \"\"\"\n",
    "    Generates stratified folds with specified normalization.\n",
    "    \n",
    "    For list of scalers, see:\n",
    "    https://scikit-learn.org/stable/api/sklearn.preprocessing.html\n",
    "    \n",
    "    For more details on scaling and normalization effects, see:\n",
    "    https://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.html#\n",
    "    \n",
    "    normalisation_method should be an instance of a scaler, e.g.,\n",
    "    - MinMaxScaler()\n",
    "    - MaxAbsScaler()\n",
    "    - Quantile_Transform(output_distribution='uniform')\n",
    "    \n",
    "    Returns a list of tuples, each containing:\n",
    "    (X_train_scaled, X_test_scaled, Y_train, Y_test), representing data for each fold\n",
    "    \"\"\"\n",
    "    kF = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    kFolds_list = []\n",
    "    \n",
    "    for fold, (train_idx, test_idx) in enumerate(kF.split(X, Y)):\n",
    "        # Split the data into training and testing sets for this fold\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        Y_train, Y_test = Y.iloc[train_idx], Y.iloc[test_idx]\n",
    "        \n",
    "        # IsolationForest for outlier removal (optional)\n",
    "        iso_forest = IsolationForest(contamination=0.05, random_state=random_state)\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\", UserWarning)\n",
    "            outliers = iso_forest.fit_predict(X_train)    \n",
    "        X_train = X_train[outliers == 1]\n",
    "        Y_train = Y_train[outliers == 1]\n",
    "        \n",
    "        # Scale the entire data (binary and continuous together)\n",
    "        X_train_scaled = normalisation_method.fit_transform(X_train)\n",
    "        X_test_scaled = normalisation_method.transform(X_test)\n",
    "\n",
    "        # Handle oversampling if needed\n",
    "        if oversampler:\n",
    "            # Apply oversampling to both features and target\n",
    "            X_train_scaled, Y_train = oversampler.fit_resample(X_train_scaled, Y_train)\n",
    "\n",
    "        # Convert scaled data back to DataFrame with the correct column names\n",
    "        X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "        X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n",
    "        \n",
    "        # Handle community columns\n",
    "        community_cols = [col for col in X_train_scaled.columns if col.startswith('Community')] \n",
    "\n",
    "        # Check for rows where multiple communities are flagged\n",
    "        for idx, row in X_train_scaled[community_cols].iterrows():\n",
    "            if set(np.unique(row)) != {0, 1}:  # If the unique values aren't just 0 or 1\n",
    "                # Fix row by ensuring only one community is marked\n",
    "                X_train_scaled.loc[idx, community_cols] = 0  # Set all community columns to 0\n",
    "                max_col = row.idxmax()  # Find the column with the maximum value\n",
    "                X_train_scaled.at[idx, max_col] = 1  # Set the column with the max value to 1\n",
    "\n",
    "        # Ensure 'gender' is still binary (0 or 1)\n",
    "        if 'Gender' in X_train_scaled.columns:\n",
    "            X_train_scaled['Gender'] = (X_train_scaled['Gender'] > 0.5).astype(int)\n",
    "            X_test_scaled['Gender'] = (X_test_scaled['Gender'] > 0.5).astype(int)\n",
    "        \n",
    "        # Append the processed fold to the list\n",
    "        kFolds_list.append((X_train_scaled, X_test_scaled, Y_train, Y_test))\n",
    "        \n",
    "        print(f\"Fold: {fold+1}, Train: {kFolds_list[fold][0].shape}, Test: {kFolds_list[fold][1].shape}\")\n",
    "    \n",
    "    return kFolds_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4aa9daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model, criterion, optimiser, scheduler, train_loader, val_loader, epochs=20, patience=5, device=device):\n",
    "    if isinstance(model.last_layer(), nn.Sigmoid) and isinstance(criterion, nn.BCEWithLogitsLoss):\n",
    "        raise ValueError(\"Model output is Sigmoid but criterion is BCEWithLogitsLoss. Please check your model and criterion compatibility.\")\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_state = None\n",
    "    wait = 0\n",
    "\n",
    "    \n",
    "    #* Epoch Training loop for this fold\n",
    "    for epoch in range(1,epochs+1):\n",
    "        #* Set model to training mode: essential for dropout and batch norm layers\n",
    "        model.train()\n",
    "        running_loss = 0.0 #? loss for this epoch\n",
    "        #* Mini-batch training loop\n",
    "        for batch, (inputs, labels) in enumerate(train_loader,start=1):\n",
    "            optimiser.zero_grad() #? Zero the gradients\n",
    "            outputs = model(inputs) #? Forward pass through the model\n",
    "            loss = criterion(outputs, labels) #? Calculate loss\n",
    "            loss.backward() #? Backpropagation\n",
    "            running_loss += loss.item()\n",
    "            optimiser.step() #? Update weights\n",
    "            if isinstance(scheduler,torch.optim.lr_scheduler.OneCycleLR):\n",
    "                scheduler.step()\n",
    "        if not isinstance(scheduler,torch.optim.lr_scheduler.OneCycleLR):\n",
    "            scheduler.step()\n",
    "                \n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        # print(f\"Epoch: {epoch}, training loss: {train_loss:.4f}\")\n",
    "    \n",
    "        #* Now we evaluate the model on the validation set, to track training vs validation loss\n",
    "        model.eval() #? Set model to evaluation mode\n",
    "        with torch.no_grad(): #? No need to track gradients during evaluation\n",
    "            val_loss = 0.0    \n",
    "            for batch, (inputs, labels) in enumerate(val_loader,start=1):#! one pass because val_loader batch size is all, if you want to do it in mini-batches, you MUST change the metric calculations to accept mini-batches\n",
    "                outputs = model(inputs)\n",
    "                # labels = labels.cpu() \n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() #? Calculate loss\n",
    "            avg_val_loss = val_loss / len(val_loader)\n",
    "            # print(f\"Epoch: {epoch}, training loss: {train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n",
    "            # print(f\"Epoch: {epoch}\".ljust(12), f\"training loss:{train_loss:.4f}\".ljust(12), f\"Val Loss: {avg_val_loss:.4f}\",end=\"\\r\")\n",
    "        \n",
    "        # Early stopping\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            best_model_state = model.state_dict()\n",
    "            wait = 0\n",
    "        elif avg_val_loss*0.85 <= best_val_loss:\n",
    "                wait = 0\n",
    "        else:\n",
    "            wait += 1\n",
    "        if wait >= patience:\n",
    "            print(f\"Early stopping triggered at epoch {epoch}, best val loss: {best_val_loss:.4f}\")\n",
    "            break\n",
    "        print(f\"Epoch: {epoch}\".ljust(12), f\"training loss:{train_loss:.4f}\".ljust(12), f\"best_val_loss:{best_val_loss:.4f}\".ljust(12), f\"Val Loss: {avg_val_loss:.4f}\",end=\"\\r\")\n",
    "    #* Use best model to calculate metrics on the validation set\n",
    "    #! must be outside epoch loop, it comes after the training and cv loop\n",
    "    model.load_state_dict(best_model_state) #? Load the best model state\n",
    "    with torch.no_grad():\n",
    "        for batch, (inputs, labels) in enumerate(val_loader,start=1):#! one pass because val_loader batch size is all, if you want to do it in mini-batches, you MUST change the metric calculations to accept mini-batches\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                labels = labels.cpu() \n",
    "                predictions = (torch.sigmoid(outputs) < 0.5).float().cpu().numpy()\n",
    "                \n",
    "                val_loss += loss.item() #? Calculate loss\n",
    "                \n",
    "    #! The following should have length equal to fold number           \n",
    "    accuracy=accuracy_score(labels, predictions) \n",
    "    precision=precision_score(labels, predictions, pos_label=1, zero_division=0)\n",
    "    recall=recall_score(labels, predictions, pos_label=1)\n",
    "    f1=f1_score(labels, predictions, pos_label=1)\n",
    "    auc=roc_auc_score(labels, predictions)\n",
    "    \n",
    "    return model, accuracy, precision, recall, f1, auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7000f2cd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class BinaryClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "            # nn.Sigmoid()\n",
    "   \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "    \n",
    "    def last_layer(self):\n",
    "        return self.net[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d49d191",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class FeedForwardBlock(nn.Module):\n",
    "    def __init__(self, in_features, out_features, dropout=0.1, activation=nn.ReLU):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Linear(in_features, out_features),\n",
    "            nn.BatchNorm1d(out_features),\n",
    "            activation(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, dropout=0.2):\n",
    "        super().__init__()\n",
    "        \n",
    "        # A couple of FeedForward blocks\n",
    "        self.block1 = FeedForwardBlock(input_dim, hidden_dim, dropout)\n",
    "        self.block2 = FeedForwardBlock(hidden_dim, hidden_dim, dropout)\n",
    "        self.block3 = FeedForwardBlock(hidden_dim, output_dim, dropout)\n",
    "\n",
    "        # Final output layer (could be softmax, sigmoid, or whatever your target is)\n",
    "        self.output_layer = nn.Linear(output_dim, 1)  # Just in case you're doing regression or binary classification\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.output_layer(x)  # Final linear layer\n",
    "        return x\n",
    "    \n",
    "    def last_layer(self):\n",
    "        return self.output_layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1eabae8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maximise_combined_score(trial):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Using device:\", device)\n",
    "    epochs = 10000\n",
    "    random_state = 42\n",
    "    oversampler = ADASYN(sampling_strategy='minority', n_neighbors=5, random_state=random_state)\n",
    "    if isinstance(oversampler, ADASYN):\n",
    "        n_neighbours = trial.suggest_int(\"n_neighbours\", 1, 10)\n",
    "        oversampler = ADASYN(sampling_strategy='minority', n_neighbors=n_neighbours, random_state=random_state)\n",
    "    \n",
    "    normalisation_method = trial.suggest_categorical(\"normalisation_method\", [\n",
    "        \"MinMaxScaler\",\n",
    "        # \"MaxAbsScaler\",\n",
    "        # \"StandardScaler\",\n",
    "        # \"RobustScaler\",\n",
    "        # \"PowerTransformer\",\n",
    "        # \"QuantileTransformer\",\n",
    "    ])\n",
    "    if normalisation_method:\n",
    "        if normalisation_method == \"MinMaxScaler\":\n",
    "            normalisation_method = MinMaxScaler()\n",
    "        elif normalisation_method == \"MaxAbsScaler\":\n",
    "            normalisation_method = MaxAbsScaler()\n",
    "        elif normalisation_method == \"StandardScaler\":\n",
    "            normalisation_method = StandardScaler()\n",
    "        elif normalisation_method == \"RobustScaler\":\n",
    "            normalisation_method = RobustScaler()\n",
    "        elif normalisation_method == \"PowerTransformer\":\n",
    "            normalisation_method = PowerTransformer()\n",
    "        elif normalisation_method == \"QuantileTransformer\":\n",
    "            normalisation_method = QuantileTransformer(output_distribution='uniform')\n",
    "        else:\n",
    "            normalisation_method = MinMaxScaler()\n",
    "    \n",
    "    kFolds = FOLDS_GENERATOR(X_FOR_FOLDS, Y_FOR_FOLDS, \n",
    "                         normalisation_method = normalisation_method, \n",
    "                         n_splits=5, \n",
    "                         oversampler = oversampler, random_state=42)\n",
    "                        \n",
    "    # Model hyperparameters (first-level optimization)\n",
    "    hidden_dim = trial.suggest_int(\"hidden_dim\", 28, 256)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.1, 0.5)\n",
    "    initial_lr = trial.suggest_float(\"initial_lr\", 1e-5, 1e-3, log=True)\n",
    "    max_lr = trial.suggest_float(\"max_lr\", 1e-3, 1e-1, log=True)\n",
    "    \n",
    "    # Loss function hyperparameters\n",
    "    criterion_choice = trial.suggest_categorical(\"criterion\", [\"BCEWithLogitsLoss\", \"FocalLoss\"]) \n",
    "    \n",
    "    # Hyperparameter exploration optimization\n",
    "    if criterion_choice == \"BCEWithLogitsLoss\":\n",
    "        pos_weight = trial.suggest_int(\"pos_weight\", 1, 10)\n",
    "        alpha = None\n",
    "        gamma = None\n",
    "    elif criterion_choice == \"FocalLoss\":\n",
    "        pos_weight= None\n",
    "        alpha = trial.suggest_float(\"alpha\", 1, 10)\n",
    "        gamma = trial.suggest_float(\"gamma\", 0, 5)\n",
    "    else:\n",
    "        pos_weight = None\n",
    "    \n",
    "    # Initialize lists for metrics across folds\n",
    "    accuracy_list = []\n",
    "    precision_list = []\n",
    "    recall_list = []\n",
    "    f1_list = []\n",
    "    auc_list = []\n",
    "\n",
    "    # Cross-validation loop\n",
    "    for fold, (train_x, test_x, train_y, test_y) in enumerate(kFolds, start=1):\n",
    "        # Create DataLoader for current fold\n",
    "        train_loader, val_loader = fold_to_dataloader_tensor(train_x, test_x, train_y, test_y, batch_size=512, device=device)\n",
    "        # Calculate steps_per_epoch from the current fold's train_loader\n",
    "        train_loader_len = len(train_loader)\n",
    "        \n",
    "        # Instantiate and initialize the model\n",
    "        # model = BinaryClassifier(input_dim=get_feature_count(train_loader), hidden_dim=hidden_dim, dropout=dropout)\n",
    "        model = MyModel(input_dim=get_feature_count(train_loader), hidden_dim=hidden_dim, output_dim=hidden_dim, dropout=dropout)\n",
    "        model.to(device)\n",
    "        model.apply(init_weights)\n",
    "        \n",
    "        # Map the choice to the actual loss function\n",
    "        criterion = criterion_mapping(criterion_choice, pos_weight, alpha, gamma).to(device)\n",
    "        optimiser = optim.Adam(model.parameters(), lr=initial_lr)\n",
    "\n",
    "        \n",
    "        # Initialize scheduler\n",
    "        scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "            optimiser,\n",
    "            max_lr=max_lr,\n",
    "            steps_per_epoch=train_loader_len,\n",
    "            epochs=epochs,\n",
    "            anneal_strategy='linear'\n",
    "        )\n",
    "        print(f\"Fold {fold}:\")\n",
    "        # Train and evaluate the model on the current fold\n",
    "        model, accuracy, precision, recall, f1, auc = train_and_evaluate(\n",
    "            model, criterion, optimiser, scheduler, train_loader, val_loader, epochs=epochs, patience=30, device=device\n",
    "        )\n",
    "        print(f\"Accuracy: {accuracy:.4f}, precision: {precision:.4f}, recall: {recall:.4f}, f1: {f1:.4f}, auc: {auc:.4f}\")\n",
    "\n",
    "        # Append the metrics from the current fold\n",
    "        accuracy_list.append(accuracy)\n",
    "        precision_list.append(precision)\n",
    "        recall_list.append(recall)\n",
    "        f1_list.append(f1)\n",
    "        auc_list.append(auc)\n",
    "\n",
    "    # Calculate the average metrics across all folds\n",
    "    avg_accuracy = np.sum(accuracy_list) / len(accuracy_list)\n",
    "    avg_precision = np.sum(precision_list) / len(precision_list)\n",
    "    avg_recall = np.sum(recall_list) / len(recall_list)\n",
    "    avg_f1 = np.sum(f1_list) / len(f1_list)\n",
    "    avg_auc = np.sum(auc_list) / len(auc_list)\n",
    "\n",
    "    # Combine metrics into a single \"score\"\n",
    "    # combined_score = (avg_f1 + avg_precision + avg_recall + avg_accuracy + avg_auc) / 5\n",
    "    combined_score = avg_f1\n",
    "\n",
    "    return combined_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11392d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-14 04:41:16,033] A new study created in RDB with name: my_cursed_study\n",
      "Bottle v0.13.2 server starting up (using WSGIRefServer())...\n",
      "Listening on http://localhost:8080/\n",
      "Hit Ctrl-C to quit.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Fold: 1, Train: (7720, 28), Test: (1149, 28)\n",
      "Fold: 2, Train: (7933, 28), Test: (1149, 28)\n",
      "Fold: 3, Train: (7844, 28), Test: (1148, 28)\n",
      "Fold: 4, Train: (7974, 28), Test: (1148, 28)\n",
      "Fold: 5, Train: (7984, 28), Test: (1148, 28)\n",
      "Fold 1:\n",
      "Early stopping triggered at epoch 365, best val loss: 0.8345oss: 1.0479\n",
      "Accuracy: 0.2019, precision: 0.0884, recall: 0.7414, f1: 0.1579, auc: 0.4414\n",
      "Fold 2:\n",
      "Early stopping triggered at epoch 33, best val loss: 0.7077Loss: 0.9108\n",
      "Accuracy: 0.4970, precision: 0.0266, recall: 0.1121, f1: 0.0430, auc: 0.3261\n",
      "Fold 3:\n",
      "Early stopping triggered at epoch 34, best val loss: 0.6658Loss: 0.9454\n",
      "Accuracy: 0.5375, precision: 0.0419, recall: 0.1638, f1: 0.0668, auc: 0.3716\n",
      "Fold 4:\n",
      "Early stopping triggered at epoch 231, best val loss: 0.8836oss: 1.1072\n",
      "Accuracy: 0.2082, precision: 0.0857, recall: 0.7069, f1: 0.1528, auc: 0.4295\n",
      "Fold 5:\n",
      "Epoch: 186   training loss:0.2984 best_val_loss:0.8213 Val Loss: 1.0195\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-14 04:42:43,008] Trial 0 finished with value: 0.1129849393384675 and parameters: {'n_neighbours': 1, 'normalisation_method': 'MinMaxScaler', 'hidden_dim': 144, 'dropout': 0.13962726108715434, 'initial_lr': 0.0004309950799024789, 'max_lr': 0.0024107424878657287, 'criterion': 'BCEWithLogitsLoss', 'pos_weight': 2}. Best is trial 0 with value: 0.1129849393384675.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at epoch 187, best val loss: 0.8213\n",
      "Accuracy: 0.2666, precision: 0.0818, recall: 0.6121, f1: 0.1443, auc: 0.4199\n",
      "Using device: cuda\n",
      "Fold: 1, Train: (8038, 28), Test: (1149, 28)\n",
      "Fold: 2, Train: (7863, 28), Test: (1149, 28)\n",
      "Fold: 3, Train: (7869, 28), Test: (1148, 28)\n",
      "Fold: 4, Train: (7929, 28), Test: (1148, 28)\n",
      "Fold: 5, Train: (7974, 28), Test: (1148, 28)\n",
      "Fold 1:\n",
      "Early stopping triggered at epoch 33, best val loss: 0.4762Loss: 0.6732\n",
      "Accuracy: 0.5100, precision: 0.0521, recall: 0.2241, f1: 0.0846, auc: 0.3831\n",
      "Fold 2:\n",
      "Early stopping triggered at epoch 35, best val loss: 0.4257Loss: 0.7595\n",
      "Accuracy: 0.5083, precision: 0.0465, recall: 0.1983, f1: 0.0753, auc: 0.3707\n",
      "Fold 3:\n",
      "Early stopping triggered at epoch 362, best val loss: 0.5603oss: 0.6958\n",
      "Accuracy: 0.2866, precision: 0.0698, recall: 0.4914, f1: 0.1222, auc: 0.3775\n",
      "Fold 4:\n",
      "Early stopping triggered at epoch 344, best val loss: 0.5937oss: 0.7422\n",
      "Accuracy: 0.2953, precision: 0.0738, recall: 0.5172, f1: 0.1292, auc: 0.3938\n",
      "Fold 5:\n",
      "Epoch: 381   training loss:0.2779 best_val_loss:0.6343 Val Loss: 0.7988\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-14 04:44:41,287] Trial 1 finished with value: 0.11242004051220982 and parameters: {'n_neighbours': 2, 'normalisation_method': 'MinMaxScaler', 'hidden_dim': 155, 'dropout': 0.2516359405709947, 'initial_lr': 0.00022817518077666336, 'max_lr': 0.0015430427069904776, 'criterion': 'FocalLoss', 'alpha': 9.760302607482629, 'gamma': 3.623053506022107}. Best is trial 0 with value: 0.1129849393384675.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at epoch 383, best val loss: 0.6343oss: 0.8076\n",
      "Accuracy: 0.3040, precision: 0.0861, recall: 0.6121, f1: 0.1509, auc: 0.4407\n",
      "Using device: cuda\n",
      "Fold: 1, Train: (7907, 28), Test: (1149, 28)\n",
      "Fold: 2, Train: (7830, 28), Test: (1149, 28)\n",
      "Fold: 3, Train: (7869, 28), Test: (1148, 28)\n",
      "Fold: 4, Train: (7926, 28), Test: (1148, 28)\n",
      "Fold: 5, Train: (7935, 28), Test: (1148, 28)\n",
      "Fold 1:\n",
      "Early stopping triggered at epoch 39, best val loss: 0.7559Loss: 1.0315\n",
      "Accuracy: 0.6118, precision: 0.0442, recall: 0.1379, f1: 0.0669, auc: 0.4015\n",
      "Fold 2:\n",
      "Early stopping triggered at epoch 32, best val loss: 0.7110Loss: 0.8656\n",
      "Accuracy: 0.4900, precision: 0.0632, recall: 0.2931, f1: 0.1040, auc: 0.4026\n",
      "Fold 3:\n",
      "Early stopping triggered at epoch 41, best val loss: 0.6655Loss: 0.9756\n",
      "Accuracy: 0.5610, precision: 0.0403, recall: 0.1466, f1: 0.0632, auc: 0.3771\n",
      "Fold 4:\n",
      "Early stopping triggered at epoch 493, best val loss: 0.8634oss: 1.0310\n",
      "Accuracy: 0.3850, precision: 0.0636, recall: 0.3707, f1: 0.1086, auc: 0.3787\n",
      "Fold 5:\n",
      "Epoch: 264   training loss:0.7115 best_val_loss:0.7635 Val Loss: 0.9104\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-14 04:46:07,963] Trial 2 finished with value: 0.08135012116026838 and parameters: {'n_neighbours': 6, 'normalisation_method': 'MinMaxScaler', 'hidden_dim': 88, 'dropout': 0.4653950443531102, 'initial_lr': 0.00011109310459315, 'max_lr': 0.0021810359678713443, 'criterion': 'FocalLoss', 'alpha': 4.691818045718026, 'gamma': 1.887392931427051}. Best is trial 0 with value: 0.1129849393384675.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at epoch 266, best val loss: 0.7635oss: 0.9079\n",
      "Accuracy: 0.4399, precision: 0.0385, recall: 0.1897, f1: 0.0640, auc: 0.3288\n",
      "Using device: cuda\n",
      "Fold: 1, Train: (8000, 28), Test: (1149, 28)\n",
      "Fold: 2, Train: (7948, 28), Test: (1149, 28)\n",
      "Fold: 3, Train: (7979, 28), Test: (1148, 28)\n",
      "Fold: 4, Train: (7918, 28), Test: (1148, 28)\n",
      "Fold: 5, Train: (7960, 28), Test: (1148, 28)\n",
      "Fold 1:\n",
      "Early stopping triggered at epoch 40, best val loss: 0.9384Loss: 1.2251\n",
      "Accuracy: 0.6345, precision: 0.0220, recall: 0.0603, f1: 0.0323, auc: 0.3796\n",
      "Fold 2:\n",
      "Early stopping triggered at epoch 34, best val loss: 0.8068Loss: 1.1691\n",
      "Accuracy: 0.6084, precision: 0.0309, recall: 0.0948, f1: 0.0466, auc: 0.3804\n",
      "Fold 3:\n",
      "Early stopping triggered at epoch 36, best val loss: 0.7309Loss: 1.2737\n",
      "Accuracy: 0.6420, precision: 0.0257, recall: 0.0690, f1: 0.0375, auc: 0.3877\n",
      "Fold 4:\n",
      "Early stopping triggered at epoch 38, best val loss: 0.8543Loss: 1.2729\n",
      "Accuracy: 0.6437, precision: 0.0259, recall: 0.0690, f1: 0.0376, auc: 0.3886\n",
      "Fold 5:\n",
      "Early stopping triggered at epoch 35, best val loss: 0.8519Loss: 1.3722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-14 04:46:30,516] Trial 3 finished with value: 0.03546192679736998 and parameters: {'n_neighbours': 8, 'normalisation_method': 'MinMaxScaler', 'hidden_dim': 241, 'dropout': 0.3215834620653315, 'initial_lr': 0.0007669535362643324, 'max_lr': 0.0017613261642258778, 'criterion': 'BCEWithLogitsLoss', 'pos_weight': 3}. Best is trial 0 with value: 0.1129849393384675.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7082, precision: 0.0176, recall: 0.0345, f1: 0.0233, auc: 0.4092\n",
      "Using device: cuda\n",
      "Fold: 1, Train: (7907, 28), Test: (1149, 28)\n",
      "Fold: 2, Train: (7830, 28), Test: (1149, 28)\n",
      "Fold: 3, Train: (7869, 28), Test: (1148, 28)\n",
      "Fold: 4, Train: (7926, 28), Test: (1148, 28)\n",
      "Fold: 5, Train: (7935, 28), Test: (1148, 28)\n",
      "Fold 1:\n",
      "Early stopping triggered at epoch 771, best val loss: 0.2423oss: 0.2959\n",
      "Accuracy: 0.2454, precision: 0.0718, recall: 0.5431, f1: 0.1269, auc: 0.3776\n",
      "Fold 2:\n",
      "Early stopping triggered at epoch 42, best val loss: 0.2077Loss: 0.3036\n",
      "Accuracy: 0.5518, precision: 0.0476, recall: 0.1810, f1: 0.0754, auc: 0.3872\n",
      "Fold 3:\n",
      "Early stopping triggered at epoch 464, best val loss: 0.2492oss: 0.3087\n",
      "Accuracy: 0.2892, precision: 0.0700, recall: 0.4914, f1: 0.1226, auc: 0.3789\n",
      "Fold 4:\n",
      "Early stopping triggered at epoch 463, best val loss: 0.2757oss: 0.3513\n",
      "Accuracy: 0.3267, precision: 0.0761, recall: 0.5086, f1: 0.1324, auc: 0.4074\n",
      "Fold 5:\n",
      "Early stopping triggered at epoch 536, best val loss: 0.2933oss: 0.3779\n",
      "Accuracy: 0.3110, precision: 0.0712, recall: 0.4828, f1: 0.1240, auc: 0.3872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-14 04:50:10,830] Trial 4 finished with value: 0.11626785718707724 and parameters: {'n_neighbours': 6, 'normalisation_method': 'MinMaxScaler', 'hidden_dim': 37, 'dropout': 0.38621572630322587, 'initial_lr': 0.0005439365419238597, 'max_lr': 0.0036938235636118553, 'criterion': 'FocalLoss', 'alpha': 3.219033697862632, 'gamma': 2.920192474538018}. Best is trial 4 with value: 0.11626785718707724.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Fold: 1, Train: (8006, 28), Test: (1149, 28)\n",
      "Fold: 2, Train: (7891, 28), Test: (1149, 28)\n",
      "Fold: 3, Train: (7933, 28), Test: (1148, 28)\n",
      "Fold: 4, Train: (7957, 28), Test: (1148, 28)\n",
      "Fold: 5, Train: (7951, 28), Test: (1148, 28)\n",
      "Fold 1:\n",
      "Early stopping triggered at epoch 49, best val loss: 1.7162Loss: 2.1647\n",
      "Accuracy: 0.4360, precision: 0.0507, recall: 0.2586, f1: 0.0847, auc: 0.3573\n",
      "Fold 2:\n",
      "Early stopping triggered at epoch 673, best val loss: 1.8838oss: 2.2708\n",
      "Accuracy: 0.2071, precision: 0.0829, recall: 0.6810, f1: 0.1478, auc: 0.4175\n",
      "Fold 3:\n",
      "Early stopping triggered at epoch 32, best val loss: 1.5919Loss: 1.9776\n",
      "Accuracy: 0.3711, precision: 0.0684, recall: 0.4138, f1: 0.1174, auc: 0.3900\n",
      "Fold 4:\n",
      "Early stopping triggered at epoch 46, best val loss: 1.6948Loss: 2.3392\n",
      "Accuracy: 0.4826, precision: 0.0404, recall: 0.1810, f1: 0.0660, auc: 0.3488\n",
      "Fold 5:\n",
      "Epoch: 486   training loss:0.9731 best_val_loss:2.2135 Val Loss: 2.6981\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-14 04:52:29,558] Trial 5 finished with value: 0.11047118564285882 and parameters: {'n_neighbours': 3, 'normalisation_method': 'MinMaxScaler', 'hidden_dim': 71, 'dropout': 0.17609397736552485, 'initial_lr': 8.075927713791958e-05, 'max_lr': 0.0012899206911295277, 'criterion': 'FocalLoss', 'alpha': 7.287975711851987, 'gamma': 1.1831772550851367}. Best is trial 4 with value: 0.11626785718707724.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at epoch 487, best val loss: 2.2135\n",
      "Accuracy: 0.2831, precision: 0.0777, recall: 0.5603, f1: 0.1364, auc: 0.4061\n",
      "Using device: cuda\n",
      "Fold: 1, Train: (7910, 28), Test: (1149, 28)\n",
      "Fold: 2, Train: (7926, 28), Test: (1149, 28)\n",
      "Fold: 3, Train: (7964, 28), Test: (1148, 28)\n",
      "Fold: 4, Train: (7982, 28), Test: (1148, 28)\n",
      "Fold: 5, Train: (7889, 28), Test: (1148, 28)\n",
      "Fold 1:\n",
      "Early stopping triggered at epoch 236, best val loss: 0.1505oss: 0.2219\n",
      "Accuracy: 0.2332, precision: 0.0783, recall: 0.6121, f1: 0.1388, auc: 0.4014\n",
      "Fold 2:\n",
      "Early stopping triggered at epoch 213, best val loss: 0.1548oss: 0.1991\n",
      "Accuracy: 0.2576, precision: 0.0759, recall: 0.5690, f1: 0.1340, auc: 0.3958\n",
      "Fold 3:\n",
      "Early stopping triggered at epoch 31, best val loss: 0.1049Loss: 0.1743\n",
      "Accuracy: 0.4904, precision: 0.0429, recall: 0.1897, f1: 0.0700, auc: 0.3569\n",
      "Fold 4:\n",
      "Early stopping triggered at epoch 175, best val loss: 0.1976oss: 0.2710\n",
      "Accuracy: 0.3441, precision: 0.0770, recall: 0.5000, f1: 0.1335, auc: 0.4133\n",
      "Fold 5:\n",
      "Early stopping triggered at epoch 182, best val loss: 0.1845oss: 0.2387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-14 04:53:54,232] Trial 6 finished with value: 0.12253456760599071 and parameters: {'n_neighbours': 7, 'normalisation_method': 'MinMaxScaler', 'hidden_dim': 144, 'dropout': 0.317305447714535, 'initial_lr': 1.1223412344842623e-05, 'max_lr': 0.012221795469566836, 'criterion': 'FocalLoss', 'alpha': 3.875769218673787, 'gamma': 4.052870354476955}. Best is trial 6 with value: 0.12253456760599071.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3493, precision: 0.0788, recall: 0.5086, f1: 0.1364, auc: 0.4200\n",
      "Using device: cuda\n",
      "Fold: 1, Train: (7901, 28), Test: (1149, 28)\n",
      "Fold: 2, Train: (7913, 28), Test: (1149, 28)\n",
      "Fold: 3, Train: (7954, 28), Test: (1148, 28)\n",
      "Fold: 4, Train: (7844, 28), Test: (1148, 28)\n",
      "Fold: 5, Train: (7879, 28), Test: (1148, 28)\n",
      "Fold 1:\n",
      "Early stopping triggered at epoch 646, best val loss: 0.1245oss: 0.1511\n",
      "Accuracy: 0.2524, precision: 0.0593, recall: 0.4310, f1: 0.1043, auc: 0.3317\n",
      "Fold 2:\n",
      "Early stopping triggered at epoch 32, best val loss: 0.0917Loss: 0.1487\n",
      "Accuracy: 0.4386, precision: 0.0509, recall: 0.2586, f1: 0.0851, auc: 0.3587\n",
      "Fold 3:\n",
      "Early stopping triggered at epoch 31, best val loss: 0.1203Loss: 0.1633\n",
      "Accuracy: 0.5122, precision: 0.0595, recall: 0.2586, f1: 0.0968, auc: 0.3997\n",
      "Fold 4:\n",
      "Early stopping triggered at epoch 32, best val loss: 0.1206Loss: 0.1829\n",
      "Accuracy: 0.5897, precision: 0.0639, recall: 0.2241, f1: 0.0994, auc: 0.4275\n",
      "Fold 5:\n",
      "Early stopping triggered at epoch 460, best val loss: 0.1537oss: 0.1985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-14 04:55:51,775] Trial 7 finished with value: 0.10041742077727016 and parameters: {'n_neighbours': 4, 'normalisation_method': 'MinMaxScaler', 'hidden_dim': 56, 'dropout': 0.36880364575676294, 'initial_lr': 0.00013047078020295608, 'max_lr': 0.0029112508273309444, 'criterion': 'FocalLoss', 'alpha': 2.914095169028494, 'gamma': 3.7066718550045237}. Best is trial 6 with value: 0.12253456760599071.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3659, precision: 0.0678, recall: 0.4138, f1: 0.1165, auc: 0.3871\n",
      "Using device: cuda\n",
      "Fold: 1, Train: (7996, 28), Test: (1149, 28)\n",
      "Fold: 2, Train: (7899, 28), Test: (1149, 28)\n",
      "Fold: 3, Train: (7902, 28), Test: (1148, 28)\n",
      "Fold: 4, Train: (7943, 28), Test: (1148, 28)\n",
      "Fold: 5, Train: (7959, 28), Test: (1148, 28)\n",
      "Fold 1:\n",
      "Early stopping triggered at epoch 36, best val loss: 1.1335Loss: 1.9394\n",
      "Accuracy: 0.7250, precision: 0.0238, recall: 0.0431, f1: 0.0307, auc: 0.4223\n",
      "Fold 2:\n",
      "Early stopping triggered at epoch 34, best val loss: 1.2448Loss: 1.9023\n",
      "Accuracy: 0.6710, precision: 0.0355, recall: 0.0862, f1: 0.0503, auc: 0.4114\n",
      "Fold 3:\n",
      "Early stopping triggered at epoch 35, best val loss: 1.3131Loss: 2.0271\n",
      "Accuracy: 0.6594, precision: 0.0307, recall: 0.0776, f1: 0.0440, auc: 0.4012\n",
      "Fold 4:\n",
      "Early stopping triggered at epoch 35, best val loss: 1.1985Loss: 2.0796\n",
      "Accuracy: 0.6890, precision: 0.0347, recall: 0.0776, f1: 0.0480, auc: 0.4177\n",
      "Fold 5:\n",
      "Epoch: 34    training loss:1.2671 best_val_loss:1.1967 Val Loss: 2.2144\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-14 04:56:11,313] Trial 8 finished with value: 0.039833078210999094 and parameters: {'n_neighbours': 10, 'normalisation_method': 'MinMaxScaler', 'hidden_dim': 239, 'dropout': 0.18792017237504643, 'initial_lr': 0.0004086743885462221, 'max_lr': 0.0026111472466707358, 'criterion': 'BCEWithLogitsLoss', 'pos_weight': 9}. Best is trial 6 with value: 0.12253456760599071.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at epoch 35, best val loss: 1.1967\n",
      "Accuracy: 0.7413, precision: 0.0212, recall: 0.0345, f1: 0.0262, auc: 0.4276\n",
      "Using device: cuda\n",
      "Fold: 1, Train: (7996, 28), Test: (1149, 28)\n",
      "Fold: 2, Train: (7899, 28), Test: (1149, 28)\n",
      "Fold: 3, Train: (7902, 28), Test: (1148, 28)\n",
      "Fold: 4, Train: (7943, 28), Test: (1148, 28)\n",
      "Fold: 5, Train: (7959, 28), Test: (1148, 28)\n",
      "Fold 1:\n",
      "Early stopping triggered at epoch 101, best val loss: 0.9508oss: 1.3935\n",
      "Accuracy: 0.2237, precision: 0.0828, recall: 0.6638, f1: 0.1472, auc: 0.4190\n",
      "Fold 2:\n",
      "Early stopping triggered at epoch 98, best val loss: 0.9711Loss: 1.5161\n",
      "Accuracy: 0.2524, precision: 0.0821, recall: 0.6293, f1: 0.1453, auc: 0.4197\n",
      "Fold 3:\n",
      "Early stopping triggered at epoch 76, best val loss: 0.9922Loss: 1.5156\n",
      "Accuracy: 0.2491, precision: 0.0761, recall: 0.5776, f1: 0.1345, auc: 0.3949\n",
      "Fold 4:\n",
      "Early stopping triggered at epoch 79, best val loss: 1.0106Loss: 1.5929\n",
      "Accuracy: 0.2657, precision: 0.0846, recall: 0.6379, f1: 0.1493, auc: 0.4309\n",
      "Fold 5:\n",
      "Early stopping triggered at epoch 79, best val loss: 1.0718Loss: 1.8626\n",
      "Accuracy: 0.2430, precision: 0.0831, recall: 0.6466, f1: 0.1472, auc: 0.4221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-14 04:56:57,406] Trial 9 finished with value: 0.1447173110235096 and parameters: {'n_neighbours': 10, 'normalisation_method': 'MinMaxScaler', 'hidden_dim': 138, 'dropout': 0.22708580936855066, 'initial_lr': 0.0007234932839435135, 'max_lr': 0.028599905026939036, 'criterion': 'FocalLoss', 'alpha': 9.769057208382337, 'gamma': 2.739713166026787}. Best is trial 9 with value: 0.1447173110235096.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Fold: 1, Train: (7996, 28), Test: (1149, 28)\n",
      "Fold: 2, Train: (7899, 28), Test: (1149, 28)\n",
      "Fold: 3, Train: (7902, 28), Test: (1148, 28)\n",
      "Fold: 4, Train: (7943, 28), Test: (1148, 28)\n",
      "Fold: 5, Train: (7959, 28), Test: (1148, 28)\n",
      "Fold 1:\n",
      "Early stopping triggered at epoch 42, best val loss: 1.6935Loss: 4.8720\n",
      "Accuracy: 0.2237, precision: 0.0828, recall: 0.6638, f1: 0.1472, auc: 0.4190\n",
      "Fold 2:\n",
      "Early stopping triggered at epoch 43, best val loss: 1.7584Loss: 4.5450\n",
      "Accuracy: 0.2298, precision: 0.0770, recall: 0.6034, f1: 0.1366, auc: 0.3956\n",
      "Fold 3:\n",
      "Early stopping triggered at epoch 36, best val loss: 1.7828Loss: 4.7221\n",
      "Accuracy: 0.2422, precision: 0.0774, recall: 0.5948, f1: 0.1369, auc: 0.3987\n",
      "Fold 4:\n",
      "Early stopping triggered at epoch 36, best val loss: 1.6784Loss: 4.7097\n",
      "Accuracy: 0.2605, precision: 0.0959, recall: 0.7500, f1: 0.1701, auc: 0.4777\n",
      "Fold 5:\n",
      "Early stopping triggered at epoch 37, best val loss: 2.0523Loss: 6.2028\n",
      "Accuracy: 0.2822, precision: 0.0855, recall: 0.6293, f1: 0.1505, auc: 0.4363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-14 04:57:18,319] Trial 10 finished with value: 0.14826422033526776 and parameters: {'n_neighbours': 10, 'normalisation_method': 'MinMaxScaler', 'hidden_dim': 207, 'dropout': 0.10273150441735247, 'initial_lr': 3.6997860866652396e-05, 'max_lr': 0.060729968263262164, 'criterion': 'BCEWithLogitsLoss', 'pos_weight': 10}. Best is trial 10 with value: 0.14826422033526776.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Fold: 1, Train: (7996, 28), Test: (1149, 28)\n",
      "Fold: 2, Train: (7899, 28), Test: (1149, 28)\n",
      "Fold: 3, Train: (7902, 28), Test: (1148, 28)\n",
      "Fold: 4, Train: (7943, 28), Test: (1148, 28)\n",
      "Fold: 5, Train: (7959, 28), Test: (1148, 28)\n",
      "Fold 1:\n",
      "Early stopping triggered at epoch 39, best val loss: 1.6287Loss: 4.5129\n",
      "Accuracy: 0.2576, precision: 0.0855, recall: 0.6552, f1: 0.1512, auc: 0.4341\n",
      "Fold 2:\n",
      "Early stopping triggered at epoch 41, best val loss: 1.6529Loss: 3.7853\n",
      "Accuracy: 0.2158, precision: 0.0847, recall: 0.6897, f1: 0.1508, auc: 0.4261\n",
      "Fold 3:\n",
      "Early stopping triggered at epoch 34, best val loss: 1.5413Loss: 4.2202\n",
      "Accuracy: 0.2230, precision: 0.0783, recall: 0.6207, f1: 0.1390, auc: 0.3995\n",
      "Fold 4:\n",
      "Early stopping triggered at epoch 37, best val loss: 1.7602Loss: 4.7582\n",
      "Accuracy: 0.2465, precision: 0.0834, recall: 0.6466, f1: 0.1478, auc: 0.4241\n",
      "Fold 5:\n",
      "Epoch: 35    training loss:0.3084 best_val_loss:2.0930 Val Loss: 5.6061\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-14 04:57:39,478] Trial 11 finished with value: 0.14835309576025285 and parameters: {'n_neighbours': 10, 'normalisation_method': 'MinMaxScaler', 'hidden_dim': 191, 'dropout': 0.10177896503042716, 'initial_lr': 3.207942163549735e-05, 'max_lr': 0.06155308061074295, 'criterion': 'BCEWithLogitsLoss', 'pos_weight': 10}. Best is trial 11 with value: 0.14835309576025285.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at epoch 37, best val loss: 2.0930Loss: 6.6321\n",
      "Accuracy: 0.2474, precision: 0.0863, recall: 0.6724, f1: 0.1529, auc: 0.4360\n",
      "Using device: cuda\n",
      "Fold: 1, Train: (8026, 28), Test: (1149, 28)\n",
      "Fold: 2, Train: (7936, 28), Test: (1149, 28)\n",
      "Fold: 3, Train: (7947, 28), Test: (1148, 28)\n",
      "Fold: 4, Train: (7981, 28), Test: (1148, 28)\n",
      "Fold: 5, Train: (7995, 28), Test: (1148, 28)\n",
      "Fold 1:\n",
      "Early stopping triggered at epoch 40, best val loss: 1.7322Loss: 4.0188\n",
      "Accuracy: 0.2428, precision: 0.0677, recall: 0.5086, f1: 0.1194, auc: 0.3608\n",
      "Fold 2:\n",
      "Early stopping triggered at epoch 39, best val loss: 1.7448Loss: 3.8934\n",
      "Accuracy: 0.2393, precision: 0.0880, recall: 0.6983, f1: 0.1564, auc: 0.4430\n",
      "Fold 3:\n",
      "Early stopping triggered at epoch 36, best val loss: 1.7998Loss: 4.4571\n",
      "Accuracy: 0.2169, precision: 0.0768, recall: 0.6121, f1: 0.1364, auc: 0.3923\n",
      "Fold 4:\n",
      "Early stopping triggered at epoch 36, best val loss: 1.7900Loss: 5.7858\n",
      "Accuracy: 0.2204, precision: 0.0896, recall: 0.7328, f1: 0.1596, auc: 0.4478\n",
      "Fold 5:\n",
      "Epoch: 36    training loss:0.2350 best_val_loss:1.7984 Val Loss: 6.1537\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-14 04:58:00,125] Trial 12 finished with value: 0.14519875671586707 and parameters: {'n_neighbours': 9, 'normalisation_method': 'MinMaxScaler', 'hidden_dim': 202, 'dropout': 0.10146828100197043, 'initial_lr': 2.762502944174571e-05, 'max_lr': 0.08847843280136795, 'criterion': 'BCEWithLogitsLoss', 'pos_weight': 10}. Best is trial 11 with value: 0.14835309576025285.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at epoch 38, best val loss: 1.7984Loss: 5.8176\n",
      "Accuracy: 0.2735, precision: 0.0874, recall: 0.6552, f1: 0.1542, auc: 0.4429\n",
      "Using device: cuda\n",
      "Fold: 1, Train: (8000, 28), Test: (1149, 28)\n",
      "Fold: 2, Train: (7948, 28), Test: (1149, 28)\n",
      "Fold: 3, Train: (7979, 28), Test: (1148, 28)\n",
      "Fold: 4, Train: (7918, 28), Test: (1148, 28)\n",
      "Fold: 5, Train: (7960, 28), Test: (1148, 28)\n",
      "Fold 1:\n",
      "Early stopping triggered at epoch 39, best val loss: 1.6168Loss: 4.1423\n",
      "Accuracy: 0.2463, precision: 0.0748, recall: 0.5690, f1: 0.1323, auc: 0.3895\n",
      "Fold 2:\n",
      "Early stopping triggered at epoch 43, best val loss: 1.5254Loss: 3.2674\n",
      "Accuracy: 0.2315, precision: 0.0696, recall: 0.5345, f1: 0.1231, auc: 0.3660\n",
      "Fold 3:\n",
      "Early stopping triggered at epoch 38, best val loss: 1.7067Loss: 4.5255\n",
      "Accuracy: 0.2047, precision: 0.0836, recall: 0.6897, f1: 0.1491, auc: 0.4199\n",
      "Fold 4:\n",
      "Early stopping triggered at epoch 37, best val loss: 1.7406Loss: 4.7219\n",
      "Accuracy: 0.2213, precision: 0.0844, recall: 0.6810, f1: 0.1502, auc: 0.4253\n",
      "Fold 5:\n",
      "Epoch: 35    training loss:0.2439 best_val_loss:1.5926 Val Loss: 5.4173\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-14 04:58:22,266] Trial 13 finished with value: 0.14120731042344953 and parameters: {'n_neighbours': 8, 'normalisation_method': 'MinMaxScaler', 'hidden_dim': 194, 'dropout': 0.11126080815235195, 'initial_lr': 3.759785289731451e-05, 'max_lr': 0.09433870140139126, 'criterion': 'BCEWithLogitsLoss', 'pos_weight': 8}. Best is trial 11 with value: 0.14835309576025285.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at epoch 36, best val loss: 1.5926\n",
      "Accuracy: 0.2770, precision: 0.0858, recall: 0.6379, f1: 0.1513, auc: 0.4372\n",
      "Using device: cuda\n",
      "Fold: 1, Train: (7996, 28), Test: (1149, 28)\n",
      "Fold: 2, Train: (7899, 28), Test: (1149, 28)\n",
      "Fold: 3, Train: (7902, 28), Test: (1148, 28)\n",
      "Fold: 4, Train: (7943, 28), Test: (1148, 28)\n",
      "Fold: 5, Train: (7959, 28), Test: (1148, 28)\n",
      "Fold 1:\n",
      "Early stopping triggered at epoch 65, best val loss: 1.5414Loss: 2.9915\n",
      "Accuracy: 0.2332, precision: 0.0811, recall: 0.6379, f1: 0.1438, auc: 0.4129\n",
      "Fold 2:\n",
      "Early stopping triggered at epoch 31, best val loss: 1.2175Loss: 1.8915\n",
      "Accuracy: 0.3621, precision: 0.0624, recall: 0.3793, f1: 0.1072, auc: 0.3697\n",
      "Fold 3:\n",
      "Early stopping triggered at epoch 31, best val loss: 1.2033Loss: 2.2983\n",
      "Accuracy: 0.3092, precision: 0.0666, recall: 0.4483, f1: 0.1159, auc: 0.3709\n",
      "Fold 4:\n",
      "Early stopping triggered at epoch 38, best val loss: 1.5129Loss: 2.8593\n",
      "Accuracy: 0.2822, precision: 0.0864, recall: 0.6379, f1: 0.1523, auc: 0.4401\n",
      "Fold 5:\n",
      "Epoch: 37    training loss:0.4178 best_val_loss:1.4990 Val Loss: 2.9614\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-14 04:58:45,852] Trial 14 finished with value: 0.12887207730618844 and parameters: {'n_neighbours': 10, 'normalisation_method': 'MinMaxScaler', 'hidden_dim': 194, 'dropout': 0.17021809325462822, 'initial_lr': 3.8075667284375674e-05, 'max_lr': 0.037555196256603585, 'criterion': 'BCEWithLogitsLoss', 'pos_weight': 7}. Best is trial 11 with value: 0.14835309576025285.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at epoch 38, best val loss: 1.4990\n",
      "Accuracy: 0.3179, precision: 0.0719, recall: 0.4828, f1: 0.1251, auc: 0.3911\n",
      "Using device: cuda\n",
      "Fold: 1, Train: (8000, 28), Test: (1149, 28)\n",
      "Fold: 2, Train: (7948, 28), Test: (1149, 28)\n",
      "Fold: 3, Train: (7979, 28), Test: (1148, 28)\n",
      "Fold: 4, Train: (7918, 28), Test: (1148, 28)\n",
      "Fold: 5, Train: (7960, 28), Test: (1148, 28)\n",
      "Fold 1:\n",
      "Early stopping triggered at epoch 58, best val loss: 1.3214Loss: 2.1439\n",
      "Accuracy: 0.2507, precision: 0.0800, recall: 0.6121, f1: 0.1416, auc: 0.4111\n",
      "Fold 2:\n",
      "Early stopping triggered at epoch 64, best val loss: 1.2906Loss: 2.1743\n",
      "Accuracy: 0.2446, precision: 0.0766, recall: 0.5862, f1: 0.1355, auc: 0.3962\n",
      "Fold 3:\n",
      "Early stopping triggered at epoch 50, best val loss: 1.4304Loss: 2.3782\n",
      "Accuracy: 0.2631, precision: 0.0686, recall: 0.5000, f1: 0.1206, auc: 0.3682\n",
      "Fold 4:\n",
      "Early stopping triggered at epoch 31, best val loss: 1.1527Loss: 1.7928\n",
      "Accuracy: 0.3606, precision: 0.0623, recall: 0.3793, f1: 0.1071, auc: 0.3689\n",
      "Fold 5:\n",
      "Early stopping triggered at epoch 62, best val loss: 1.5750Loss: 3.0856\n",
      "Accuracy: 0.2857, precision: 0.0789, recall: 0.5690, f1: 0.1387, auc: 0.4114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-14 04:59:14,429] Trial 15 finished with value: 0.12866539706913982 and parameters: {'n_neighbours': 8, 'normalisation_method': 'MinMaxScaler', 'hidden_dim': 216, 'dropout': 0.23235695695152586, 'initial_lr': 1.5024194229727217e-05, 'max_lr': 0.03478385377355163, 'criterion': 'BCEWithLogitsLoss', 'pos_weight': 5}. Best is trial 11 with value: 0.14835309576025285.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Fold: 1, Train: (7981, 28), Test: (1149, 28)\n",
      "Fold: 2, Train: (7859, 28), Test: (1149, 28)\n",
      "Fold: 3, Train: (7906, 28), Test: (1148, 28)\n",
      "Fold: 4, Train: (7942, 28), Test: (1148, 28)\n",
      "Fold: 5, Train: (7958, 28), Test: (1148, 28)\n",
      "Fold 1:\n",
      "Early stopping triggered at epoch 33, best val loss: 1.4309Loss: 1.8715\n",
      "Accuracy: 0.7198, precision: 0.0187, recall: 0.0345, f1: 0.0242, auc: 0.4156\n",
      "Fold 2:\n",
      "Early stopping triggered at epoch 32, best val loss: 1.3323Loss: 1.8678\n",
      "Accuracy: 0.6884, precision: 0.0236, recall: 0.0517, f1: 0.0324, auc: 0.4058\n",
      "Fold 3:\n",
      "Early stopping triggered at epoch 33, best val loss: 1.4193Loss: 1.8300\n",
      "Accuracy: 0.6420, precision: 0.0227, recall: 0.0603, f1: 0.0329, auc: 0.3839\n",
      "Fold 4:\n",
      "Early stopping triggered at epoch 33, best val loss: 1.3220Loss: 1.9658\n",
      "Accuracy: 0.6803, precision: 0.0192, recall: 0.0431, f1: 0.0265, auc: 0.3975\n",
      "Fold 5:\n",
      "Early stopping triggered at epoch 32, best val loss: 1.3634Loss: 1.9707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-14 04:59:33,908] Trial 16 finished with value: 0.028121212777743664 and parameters: {'n_neighbours': 5, 'normalisation_method': 'MinMaxScaler', 'hidden_dim': 180, 'dropout': 0.48803187213634547, 'initial_lr': 5.914844581315371e-05, 'max_lr': 0.014135993655046175, 'criterion': 'BCEWithLogitsLoss', 'pos_weight': 10}. Best is trial 11 with value: 0.14835309576025285.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7221, precision: 0.0190, recall: 0.0345, f1: 0.0245, auc: 0.4170\n",
      "Using device: cuda\n",
      "Fold: 1, Train: (8026, 28), Test: (1149, 28)\n",
      "Fold: 2, Train: (7936, 28), Test: (1149, 28)\n",
      "Fold: 3, Train: (7947, 28), Test: (1148, 28)\n",
      "Fold: 4, Train: (7981, 28), Test: (1148, 28)\n",
      "Fold: 5, Train: (7995, 28), Test: (1148, 28)\n",
      "Fold 1:\n",
      "Early stopping triggered at epoch 54, best val loss: 1.4352Loss: 2.5825\n",
      "Accuracy: 0.2559, precision: 0.0738, recall: 0.5517, f1: 0.1302, auc: 0.3872\n",
      "Fold 2:\n",
      "Early stopping triggered at epoch 49, best val loss: 1.4154Loss: 2.4864\n",
      "Accuracy: 0.2811, precision: 0.0660, recall: 0.4655, f1: 0.1156, auc: 0.3630\n",
      "Fold 3:\n",
      "Early stopping triggered at epoch 40, best val loss: 1.2922Loss: 2.9035\n",
      "Accuracy: 0.2753, precision: 0.0728, recall: 0.5259, f1: 0.1279, auc: 0.3865\n",
      "Fold 4:\n",
      "Early stopping triggered at epoch 31, best val loss: 1.2282Loss: 2.2932\n",
      "Accuracy: 0.3554, precision: 0.0749, recall: 0.4741, f1: 0.1294, auc: 0.4081\n",
      "Fold 5:\n",
      "Epoch: 30    training loss:0.5846 best_val_loss:1.2168 Val Loss: 2.5831\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-14 04:59:56,740] Trial 17 finished with value: 0.12626896317602368 and parameters: {'n_neighbours': 9, 'normalisation_method': 'MinMaxScaler', 'hidden_dim': 103, 'dropout': 0.14852048664175577, 'initial_lr': 2.1812389847318616e-05, 'max_lr': 0.058270614538022625, 'criterion': 'BCEWithLogitsLoss', 'pos_weight': 7}. Best is trial 11 with value: 0.14835309576025285.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at epoch 31, best val loss: 1.2168\n",
      "Accuracy: 0.3484, precision: 0.0741, recall: 0.4741, f1: 0.1282, auc: 0.4042\n",
      "Using device: cuda\n",
      "Fold: 1, Train: (8026, 28), Test: (1149, 28)\n",
      "Fold: 2, Train: (7936, 28), Test: (1149, 28)\n",
      "Fold: 3, Train: (7947, 28), Test: (1148, 28)\n",
      "Fold: 4, Train: (7981, 28), Test: (1148, 28)\n",
      "Fold: 5, Train: (7995, 28), Test: (1148, 28)\n",
      "Fold 1:\n",
      "Early stopping triggered at epoch 112, best val loss: 1.3724oss: 1.8632\n",
      "Accuracy: 0.3064, precision: 0.0728, recall: 0.5000, f1: 0.1271, auc: 0.3923\n",
      "Fold 2:\n",
      "Early stopping triggered at epoch 32, best val loss: 0.9399Loss: 1.3740\n",
      "Accuracy: 0.4735, precision: 0.0413, recall: 0.1897, f1: 0.0678, auc: 0.3475\n",
      "Fold 3:\n",
      "Early stopping triggered at epoch 31, best val loss: 0.9370Loss: 1.5388\n",
      "Accuracy: 0.4756, precision: 0.0598, recall: 0.2845, f1: 0.0988, auc: 0.3908\n",
      "Fold 4:\n",
      "Early stopping triggered at epoch 31, best val loss: 1.2097Loss: 1.5591\n",
      "Accuracy: 0.4800, precision: 0.0603, recall: 0.2845, f1: 0.0995, auc: 0.3932\n",
      "Fold 5:\n",
      "Epoch: 30    training loss:0.8315 best_val_loss:1.1288 Val Loss: 1.5836\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-14 05:00:23,783] Trial 18 finished with value: 0.09206285597467301 and parameters: {'n_neighbours': 9, 'normalisation_method': 'MinMaxScaler', 'hidden_dim': 172, 'dropout': 0.2693747877021697, 'initial_lr': 5.370116947293522e-05, 'max_lr': 0.0182041248160145, 'criterion': 'BCEWithLogitsLoss', 'pos_weight': 5}. Best is trial 11 with value: 0.14835309576025285.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at epoch 31, best val loss: 1.1288\n",
      "Accuracy: 0.5157, precision: 0.0417, recall: 0.1724, f1: 0.0671, auc: 0.3633\n",
      "Using device: cuda\n",
      "Fold: 1, Train: (7910, 28), Test: (1149, 28)\n",
      "Fold: 2, Train: (7926, 28), Test: (1149, 28)\n",
      "Fold: 3, Train: (7964, 28), Test: (1148, 28)\n",
      "Fold: 4, Train: (7982, 28), Test: (1148, 28)\n",
      "Fold: 5, Train: (7889, 28), Test: (1148, 28)\n",
      "Fold 1:\n",
      "Early stopping triggered at epoch 33, best val loss: 1.2183Loss: 2.0616\n",
      "Accuracy: 0.7111, precision: 0.0385, recall: 0.0776, f1: 0.0514, auc: 0.4299\n",
      "Fold 2:\n",
      "Early stopping triggered at epoch 33, best val loss: 1.3084Loss: 1.9952\n",
      "Accuracy: 0.6066, precision: 0.0359, recall: 0.1121, f1: 0.0544, auc: 0.3871\n",
      "Fold 3:\n",
      "Early stopping triggered at epoch 33, best val loss: 1.2843Loss: 2.1159\n",
      "Accuracy: 0.5976, precision: 0.0349, recall: 0.1121, f1: 0.0533, auc: 0.3821\n",
      "Fold 4:\n",
      "Early stopping triggered at epoch 33, best val loss: 1.3482Loss: 2.2041\n",
      "Accuracy: 0.6211, precision: 0.0430, recall: 0.1293, f1: 0.0645, auc: 0.4028\n",
      "Fold 5:\n",
      "Early stopping triggered at epoch 33, best val loss: 1.3342Loss: 2.3445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-14 05:00:43,571] Trial 19 finished with value: 0.05678364039248773 and parameters: {'n_neighbours': 7, 'normalisation_method': 'MinMaxScaler', 'hidden_dim': 218, 'dropout': 0.21107482805502975, 'initial_lr': 1.925736147995007e-05, 'max_lr': 0.006412842928355811, 'criterion': 'BCEWithLogitsLoss', 'pos_weight': 10}. Best is trial 11 with value: 0.14835309576025285.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6742, precision: 0.0426, recall: 0.1034, f1: 0.0603, auc: 0.4209\n",
      "Using device: cuda\n",
      "Fold: 1, Train: (7910, 28), Test: (1149, 28)\n",
      "Fold: 2, Train: (7926, 28), Test: (1149, 28)\n",
      "Fold: 3, Train: (7964, 28), Test: (1148, 28)\n",
      "Fold: 4, Train: (7982, 28), Test: (1148, 28)\n",
      "Fold: 5, Train: (7889, 28), Test: (1148, 28)\n",
      "Fold 1:\n",
      "Early stopping triggered at epoch 51, best val loss: 1.6013Loss: 4.3789\n",
      "Accuracy: 0.2324, precision: 0.0800, recall: 0.6293, f1: 0.1420, auc: 0.4086\n",
      "Fold 2:\n",
      "Early stopping triggered at epoch 43, best val loss: 1.6111Loss: 3.6165\n",
      "Accuracy: 0.2280, precision: 0.0805, recall: 0.6379, f1: 0.1430, auc: 0.4100\n",
      "Fold 3:\n",
      "Early stopping triggered at epoch 37, best val loss: 1.6117Loss: 3.7892\n",
      "Accuracy: 0.2169, precision: 0.0804, recall: 0.6466, f1: 0.1430, auc: 0.4076\n",
      "Fold 4:\n",
      "Early stopping triggered at epoch 36, best val loss: 1.6268Loss: 4.0763\n",
      "Accuracy: 0.2517, precision: 0.0886, recall: 0.6897, f1: 0.1570, auc: 0.4461\n",
      "Fold 5:\n",
      "Epoch: 38    training loss:0.2732 best_val_loss:1.8827 Val Loss: 4.6987\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-14 05:01:05,833] Trial 20 finished with value: 0.1495982976698472 and parameters: {'n_neighbours': 7, 'normalisation_method': 'MinMaxScaler', 'hidden_dim': 255, 'dropout': 0.13453206643934615, 'initial_lr': 3.405906311970348e-05, 'max_lr': 0.05323481728278594, 'criterion': 'BCEWithLogitsLoss', 'pos_weight': 8}. Best is trial 20 with value: 0.1495982976698472.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at epoch 40, best val loss: 1.8827Loss: 4.2114\n",
      "Accuracy: 0.2125, precision: 0.0913, recall: 0.7586, f1: 0.1630, auc: 0.4549\n",
      "Using device: cuda\n",
      "Fold: 1, Train: (7996, 28), Test: (1149, 28)\n",
      "Fold: 2, Train: (7899, 28), Test: (1149, 28)\n",
      "Fold: 3, Train: (7902, 28), Test: (1148, 28)\n",
      "Fold: 4, Train: (7943, 28), Test: (1148, 28)\n",
      "Fold: 5, Train: (7959, 28), Test: (1148, 28)\n",
      "Fold 1:\n",
      "Early stopping triggered at epoch 42, best val loss: 1.6037Loss: 3.2709\n",
      "Accuracy: 0.2211, precision: 0.0825, recall: 0.6638, f1: 0.1468, auc: 0.4176\n",
      "Fold 2:\n",
      "Early stopping triggered at epoch 43, best val loss: 1.5229Loss: 3.9194\n",
      "Accuracy: 0.2245, precision: 0.0802, recall: 0.6379, f1: 0.1424, auc: 0.4080\n",
      "Fold 3:\n",
      "Early stopping triggered at epoch 38, best val loss: 1.7151Loss: 4.2804\n",
      "Accuracy: 0.2256, precision: 0.0822, recall: 0.6552, f1: 0.1460, auc: 0.4162\n",
      "Fold 4:\n",
      "Early stopping triggered at epoch 37, best val loss: 1.7135Loss: 4.3526\n",
      "Accuracy: 0.2570, precision: 0.0827, recall: 0.6293, f1: 0.1461, auc: 0.4222\n",
      "Fold 5:\n",
      "Early stopping triggered at epoch 41, best val loss: 1.7423Loss: 5.1463\n",
      "Accuracy: 0.2422, precision: 0.0875, recall: 0.6897, f1: 0.1553, auc: 0.4408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-14 05:01:28,907] Trial 21 finished with value: 0.1473501082535933 and parameters: {'n_neighbours': 10, 'normalisation_method': 'MinMaxScaler', 'hidden_dim': 256, 'dropout': 0.13511552290006554, 'initial_lr': 3.276291903718801e-05, 'max_lr': 0.05475142219393207, 'criterion': 'BCEWithLogitsLoss', 'pos_weight': 8}. Best is trial 20 with value: 0.1495982976698472.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Fold: 1, Train: (7910, 28), Test: (1149, 28)\n",
      "Fold: 2, Train: (7926, 28), Test: (1149, 28)\n",
      "Fold: 3, Train: (7964, 28), Test: (1148, 28)\n",
      "Fold: 4, Train: (7982, 28), Test: (1148, 28)\n",
      "Fold: 5, Train: (7889, 28), Test: (1148, 28)\n",
      "Fold 1:\n",
      "Early stopping triggered at epoch 47, best val loss: 1.5533Loss: 3.1143\n",
      "Accuracy: 0.2889, precision: 0.0772, recall: 0.5517, f1: 0.1354, auc: 0.4056\n",
      "Fold 2:\n",
      "Early stopping triggered at epoch 31, best val loss: 1.2407Loss: 2.9174\n",
      "Accuracy: 0.3438, precision: 0.0701, recall: 0.4483, f1: 0.1212, auc: 0.3902\n",
      "Fold 3:\n",
      "Early stopping triggered at epoch 31, best val loss: 1.4104Loss: 2.9452\n",
      "Accuracy: 0.3014, precision: 0.0691, recall: 0.4741, f1: 0.1206, auc: 0.3781\n",
      "Fold 4:\n",
      "Early stopping triggered at epoch 31, best val loss: 1.2842Loss: 3.0433\n",
      "Accuracy: 0.3118, precision: 0.0777, recall: 0.5345, f1: 0.1357, auc: 0.4107\n",
      "Fold 5:\n",
      "Early stopping triggered at epoch 31, best val loss: 1.3253Loss: 3.2895\n",
      "Accuracy: 0.3345, precision: 0.0803, recall: 0.5345, f1: 0.1396, auc: 0.4232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-14 05:01:47,858] Trial 22 finished with value: 0.13051658549009695 and parameters: {'n_neighbours': 7, 'normalisation_method': 'MinMaxScaler', 'hidden_dim': 224, 'dropout': 0.10053482534188388, 'initial_lr': 5.656947469883495e-05, 'max_lr': 0.023327168245503786, 'criterion': 'BCEWithLogitsLoss', 'pos_weight': 9}. Best is trial 20 with value: 0.1495982976698472.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Fold: 1, Train: (8026, 28), Test: (1149, 28)\n",
      "Fold: 2, Train: (7936, 28), Test: (1149, 28)\n",
      "Fold: 3, Train: (7947, 28), Test: (1148, 28)\n",
      "Fold: 4, Train: (7981, 28), Test: (1148, 28)\n",
      "Fold: 5, Train: (7995, 28), Test: (1148, 28)\n",
      "Fold 1:\n",
      "Early stopping triggered at epoch 45, best val loss: 1.6961Loss: 3.3357\n",
      "Accuracy: 0.2332, precision: 0.0811, recall: 0.6379, f1: 0.1438, auc: 0.4129\n",
      "Fold 2:\n",
      "Early stopping triggered at epoch 42, best val loss: 1.6802Loss: 4.7787\n",
      "Accuracy: 0.2350, precision: 0.0840, recall: 0.6638, f1: 0.1491, auc: 0.4253\n",
      "Fold 3:\n",
      "Early stopping triggered at epoch 37, best val loss: 1.7536Loss: 4.2314\n",
      "Accuracy: 0.2282, precision: 0.0769, recall: 0.6034, f1: 0.1365, auc: 0.3947\n",
      "Fold 4:\n",
      "Early stopping triggered at epoch 38, best val loss: 1.8233Loss: 4.7047\n",
      "Accuracy: 0.2622, precision: 0.0916, recall: 0.7069, f1: 0.1622, auc: 0.4596\n",
      "Fold 5:\n",
      "Early stopping triggered at epoch 40, best val loss: 1.9567Loss: 5.7551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-14 05:02:10,771] Trial 23 finished with value: 0.1474416492845141 and parameters: {'n_neighbours': 9, 'normalisation_method': 'MinMaxScaler', 'hidden_dim': 250, 'dropout': 0.13951214317638774, 'initial_lr': 1.0736287410411255e-05, 'max_lr': 0.05372493452858314, 'criterion': 'BCEWithLogitsLoss', 'pos_weight': 9}. Best is trial 20 with value: 0.1495982976698472.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2334, precision: 0.0821, recall: 0.6466, f1: 0.1456, auc: 0.4168\n",
      "Using device: cuda\n",
      "Fold: 1, Train: (7981, 28), Test: (1149, 28)\n",
      "Fold: 2, Train: (7859, 28), Test: (1149, 28)\n",
      "Fold: 3, Train: (7906, 28), Test: (1148, 28)\n",
      "Fold: 4, Train: (7942, 28), Test: (1148, 28)\n",
      "Fold: 5, Train: (7958, 28), Test: (1148, 28)\n",
      "Fold 1:\n",
      "Early stopping triggered at epoch 33, best val loss: 1.1507Loss: 1.7159\n",
      "Accuracy: 0.6327, precision: 0.0335, recall: 0.0948, f1: 0.0495, auc: 0.3940\n",
      "Fold 2:\n",
      "Early stopping triggered at epoch 34, best val loss: 1.1902Loss: 1.6814\n",
      "Accuracy: 0.5927, precision: 0.0269, recall: 0.0862, f1: 0.0410, auc: 0.3679\n",
      "Fold 3:\n",
      "Early stopping triggered at epoch 32, best val loss: 1.1639Loss: 1.7226\n",
      "Accuracy: 0.5723, precision: 0.0370, recall: 0.1293, f1: 0.0576, auc: 0.3757\n",
      "Fold 4:\n",
      "Early stopping triggered at epoch 33, best val loss: 1.0856Loss: 1.7791\n",
      "Accuracy: 0.5923, precision: 0.0464, recall: 0.1552, f1: 0.0714, auc: 0.3983\n",
      "Fold 5:\n",
      "Epoch: 32    training loss:1.0933 best_val_loss:0.9972 Val Loss: 1.9209\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-14 05:02:29,620] Trial 24 finished with value: 0.051277081339001815 and parameters: {'n_neighbours': 5, 'normalisation_method': 'MinMaxScaler', 'hidden_dim': 172, 'dropout': 0.19930915803441052, 'initial_lr': 0.00017254309335327638, 'max_lr': 0.007021009955732747, 'criterion': 'BCEWithLogitsLoss', 'pos_weight': 7}. Best is trial 20 with value: 0.1495982976698472.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at epoch 33, best val loss: 0.9972\n",
      "Accuracy: 0.6812, precision: 0.0265, recall: 0.0603, f1: 0.0368, auc: 0.4057\n",
      "Using device: cuda\n",
      "Fold: 1, Train: (8000, 28), Test: (1149, 28)\n",
      "Fold: 2, Train: (7948, 28), Test: (1149, 28)\n",
      "Fold: 3, Train: (7979, 28), Test: (1148, 28)\n",
      "Fold: 4, Train: (7918, 28), Test: (1148, 28)\n",
      "Fold: 5, Train: (7960, 28), Test: (1148, 28)\n",
      "Fold 1:\n",
      "Early stopping triggered at epoch 43, best val loss: 1.7427Loss: 3.7496\n",
      "Accuracy: 0.2489, precision: 0.0882, recall: 0.6897, f1: 0.1564, auc: 0.4445\n",
      "Fold 2:\n",
      "Early stopping triggered at epoch 45, best val loss: 1.8536Loss: 4.3723\n",
      "Accuracy: 0.2646, precision: 0.0806, recall: 0.6034, f1: 0.1421, auc: 0.4150\n",
      "Fold 3:\n",
      "Early stopping triggered at epoch 39, best val loss: 1.9467Loss: 4.5143\n",
      "Accuracy: 0.2291, precision: 0.0704, recall: 0.5431, f1: 0.1246, auc: 0.3685\n",
      "Fold 4:\n",
      "Early stopping triggered at epoch 39, best val loss: 1.9012Loss: 5.0574\n",
      "Accuracy: 0.2866, precision: 0.0820, recall: 0.5948, f1: 0.1442, auc: 0.4234\n",
      "Fold 5:\n",
      "Epoch: 39    training loss:0.3354 best_val_loss:1.9316 Val Loss: 4.7127\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-14 05:02:52,877] Trial 25 finished with value: 0.14412121482319346 and parameters: {'n_neighbours': 8, 'normalisation_method': 'MinMaxScaler', 'hidden_dim': 229, 'dropout': 0.16470242185613077, 'initial_lr': 2.3721557488317163e-05, 'max_lr': 0.06229630042743155, 'criterion': 'BCEWithLogitsLoss', 'pos_weight': 10}. Best is trial 20 with value: 0.1495982976698472.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at epoch 41, best val loss: 1.9316Loss: 4.6061\n",
      "Accuracy: 0.2491, precision: 0.0865, recall: 0.6724, f1: 0.1532, auc: 0.4370\n",
      "Using device: cuda\n",
      "Fold: 1, Train: (8026, 28), Test: (1149, 28)\n",
      "Fold: 2, Train: (7936, 28), Test: (1149, 28)\n",
      "Fold: 3, Train: (7947, 28), Test: (1148, 28)\n",
      "Fold: 4, Train: (7981, 28), Test: (1148, 28)\n",
      "Fold: 5, Train: (7995, 28), Test: (1148, 28)\n",
      "Fold 1:\n",
      "Early stopping triggered at epoch 31, best val loss: 1.1711Loss: 1.7725\n",
      "Accuracy: 0.3882, precision: 0.0586, recall: 0.3362, f1: 0.0999, auc: 0.3651\n",
      "Fold 2:\n",
      "Early stopping triggered at epoch 37, best val loss: 1.3007Loss: 2.4094\n",
      "Accuracy: 0.3003, precision: 0.0668, recall: 0.4569, f1: 0.1165, auc: 0.3698\n",
      "Fold 3:\n",
      "Early stopping triggered at epoch 31, best val loss: 1.2431Loss: 2.3020\n",
      "Accuracy: 0.3624, precision: 0.0650, recall: 0.3966, f1: 0.1117, auc: 0.3775\n",
      "Fold 4:\n",
      "Early stopping triggered at epoch 31, best val loss: 1.1748Loss: 2.3539\n",
      "Accuracy: 0.3510, precision: 0.0812, recall: 0.5259, f1: 0.1407, auc: 0.4286\n",
      "Fold 5:\n",
      "Early stopping triggered at epoch 31, best val loss: 1.3104Loss: 2.4423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-14 05:03:11,240] Trial 26 finished with value: 0.11955066571701109 and parameters: {'n_neighbours': 9, 'normalisation_method': 'MinMaxScaler', 'hidden_dim': 119, 'dropout': 0.12390806974123683, 'initial_lr': 7.743648040199094e-05, 'max_lr': 0.034495846382039765, 'criterion': 'BCEWithLogitsLoss', 'pos_weight': 8}. Best is trial 20 with value: 0.1495982976698472.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3885, precision: 0.0754, recall: 0.4483, f1: 0.1290, auc: 0.4150\n",
      "Using device: cuda\n",
      "Fold: 1, Train: (7901, 28), Test: (1149, 28)\n",
      "Fold: 2, Train: (7913, 28), Test: (1149, 28)\n",
      "Fold: 3, Train: (7954, 28), Test: (1148, 28)\n",
      "Fold: 4, Train: (7844, 28), Test: (1148, 28)\n",
      "Fold: 5, Train: (7879, 28), Test: (1148, 28)\n",
      "Fold 1:\n",
      "Early stopping triggered at epoch 58, best val loss: 1.3004Loss: 2.1545\n",
      "Accuracy: 0.2402, precision: 0.0827, recall: 0.6466, f1: 0.1466, auc: 0.4206\n",
      "Fold 2:\n",
      "Early stopping triggered at epoch 45, best val loss: 1.2188Loss: 2.1774\n",
      "Accuracy: 0.2437, precision: 0.0707, recall: 0.5345, f1: 0.1249, auc: 0.3728\n",
      "Fold 3:\n",
      "Early stopping triggered at epoch 42, best val loss: 1.4808Loss: 3.0455\n",
      "Accuracy: 0.2483, precision: 0.0682, recall: 0.5086, f1: 0.1203, auc: 0.3638\n",
      "Fold 4:\n",
      "Early stopping triggered at epoch 43, best val loss: 1.4874Loss: 2.5877\n",
      "Accuracy: 0.2787, precision: 0.0772, recall: 0.5603, f1: 0.1357, auc: 0.4037\n",
      "Fold 5:\n",
      "Epoch: 43    training loss:0.3796 best_val_loss:1.5077 Val Loss: 3.2561\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-14 05:03:35,518] Trial 27 finished with value: 0.13447113936777857 and parameters: {'n_neighbours': 4, 'normalisation_method': 'MinMaxScaler', 'hidden_dim': 207, 'dropout': 0.27627790298213867, 'initial_lr': 4.310369298216038e-05, 'max_lr': 0.07490037883914082, 'criterion': 'BCEWithLogitsLoss', 'pos_weight': 6}. Best is trial 20 with value: 0.1495982976698472.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at epoch 44, best val loss: 1.5077\n",
      "Accuracy: 0.2596, precision: 0.0820, recall: 0.6207, f1: 0.1449, auc: 0.4198\n",
      "Using device: cuda\n",
      "Fold: 1, Train: (7996, 28), Test: (1149, 28)\n",
      "Fold: 2, Train: (7899, 28), Test: (1149, 28)\n",
      "Fold: 3, Train: (7902, 28), Test: (1148, 28)\n",
      "Fold: 4, Train: (7943, 28), Test: (1148, 28)\n",
      "Fold: 5, Train: (7959, 28), Test: (1148, 28)\n",
      "Fold 1:\n",
      "Early stopping triggered at epoch 52, best val loss: 1.7014Loss: 3.7282\n",
      "Accuracy: 0.3211, precision: 0.0754, recall: 0.5086, f1: 0.1314, auc: 0.4044\n",
      "Fold 2:\n",
      "Early stopping triggered at epoch 53, best val loss: 1.6575Loss: 3.3699\n",
      "Accuracy: 0.2620, precision: 0.0674, recall: 0.4914, f1: 0.1185, auc: 0.3638\n",
      "Fold 3:\n",
      "Early stopping triggered at epoch 40, best val loss: 1.8091Loss: 4.0491\n",
      "Accuracy: 0.2544, precision: 0.0718, recall: 0.5345, f1: 0.1265, auc: 0.3787\n",
      "Fold 4:\n",
      "Early stopping triggered at epoch 41, best val loss: 1.6945Loss: 3.4600\n",
      "Accuracy: 0.3101, precision: 0.0848, recall: 0.5948, f1: 0.1484, auc: 0.4365\n",
      "Fold 5:\n",
      "Epoch: 37    training loss:0.4700 best_val_loss:1.5768 Val Loss: 3.2194\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-14 05:03:59,435] Trial 28 finished with value: 0.1337258510593625 and parameters: {'n_neighbours': 10, 'normalisation_method': 'MinMaxScaler', 'hidden_dim': 186, 'dropout': 0.16287020580855993, 'initial_lr': 1.7530985619836235e-05, 'max_lr': 0.04495246417279645, 'criterion': 'BCEWithLogitsLoss', 'pos_weight': 9}. Best is trial 20 with value: 0.1495982976698472.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at epoch 38, best val loss: 1.5768\n",
      "Accuracy: 0.3258, precision: 0.0825, recall: 0.5603, f1: 0.1438, auc: 0.4299\n",
      "Using device: cuda\n",
      "Fold: 1, Train: (7910, 28), Test: (1149, 28)\n",
      "Fold: 2, Train: (7926, 28), Test: (1149, 28)\n",
      "Fold: 3, Train: (7964, 28), Test: (1148, 28)\n",
      "Fold: 4, Train: (7982, 28), Test: (1148, 28)\n",
      "Fold: 5, Train: (7889, 28), Test: (1148, 28)\n",
      "Fold 1:\n",
      "Early stopping triggered at epoch 31, best val loss: 1.4642Loss: 2.3446\n",
      "Accuracy: 0.3586, precision: 0.0682, recall: 0.4224, f1: 0.1174, auc: 0.3869\n",
      "Fold 2:\n",
      "Early stopping triggered at epoch 38, best val loss: 1.5198Loss: 2.5624\n",
      "Accuracy: 0.3238, precision: 0.0680, recall: 0.4483, f1: 0.1180, auc: 0.3790\n",
      "Fold 3:\n",
      "Early stopping triggered at epoch 42, best val loss: 1.8439Loss: 3.8868\n",
      "Accuracy: 0.2726, precision: 0.0674, recall: 0.4828, f1: 0.1183, auc: 0.3659\n",
      "Fold 4:\n",
      "Early stopping triggered at epoch 31, best val loss: 1.3322Loss: 2.8804\n",
      "Accuracy: 0.3641, precision: 0.0724, recall: 0.4483, f1: 0.1247, auc: 0.4015\n",
      "Fold 5:\n",
      "Epoch: 29    training loss:0.6192 best_val_loss:1.5540 Val Loss: 3.0060\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-14 05:04:19,252] Trial 29 finished with value: 0.11815993968773683 and parameters: {'n_neighbours': 7, 'normalisation_method': 'MinMaxScaler', 'hidden_dim': 238, 'dropout': 0.12949676651213293, 'initial_lr': 2.83434635779415e-05, 'max_lr': 0.021982953055555348, 'criterion': 'BCEWithLogitsLoss', 'pos_weight': 10}. Best is trial 20 with value: 0.1495982976698472.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at epoch 31, best val loss: 1.5540Loss: 2.9379\n",
      "Accuracy: 0.4085, precision: 0.0663, recall: 0.3707, f1: 0.1124, auc: 0.3917\n",
      "Best trial:\n",
      "  Combined score: 0.1495982976698472\n",
      "  Best hyperparameters:\n",
      "    n_neighbours: 7\n",
      "    normalisation_method: MinMaxScaler\n",
      "    hidden_dim: 255\n",
      "    dropout: 0.13453206643934615\n",
      "    initial_lr: 3.405906311970348e-05\n",
      "    max_lr: 0.05323481728278594\n",
      "    criterion: BCEWithLogitsLoss\n",
      "    pos_weight: 8\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import optuna\n",
    "from optuna_dashboard import run_server\n",
    "!fuser -k 8080/tcp\n",
    "\n",
    "# Define your persistent storage\n",
    "storage = \"sqlite:///optuna_study3.db\"\n",
    "\n",
    "# Create or load your study\n",
    "study_name = \"my_cursed_study\"\n",
    "try:\n",
    "    study = optuna.load_study(study_name=study_name, storage=storage)\n",
    "except KeyError:\n",
    "    study = optuna.create_study(study_name=study_name, direction=\"maximize\", storage=storage)\n",
    "\n",
    "# Start Optuna Dashboard in a separate thread\n",
    "dashboard_thread = threading.Thread(target=lambda: run_server(storage), daemon=True)\n",
    "dashboard_thread.start()\n",
    "\n",
    "# Run optimization\n",
    "study.optimize(maximise_combined_score, n_trials=30)\n",
    "\n",
    "# Print results\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(f\"  Combined score: {trial.value}\")\n",
    "print(\"  Best hyperparameters:\")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cb2751",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
