{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "556439f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in d:\\adl\\adl\\venv\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in d:\\adl\\adl\\venv\\lib\\site-packages (from pandas) (2.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\adl\\adl\\venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\adl\\adl\\venv\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\adl\\adl\\venv\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in d:\\adl\\adl\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: optuna in d:\\adl\\adl\\venv\\lib\\site-packages (4.3.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in d:\\adl\\adl\\venv\\lib\\site-packages (from optuna) (1.15.2)\n",
      "Requirement already satisfied: colorlog in d:\\adl\\adl\\venv\\lib\\site-packages (from optuna) (6.9.0)\n",
      "Requirement already satisfied: numpy in d:\\adl\\adl\\venv\\lib\\site-packages (from optuna) (2.2.4)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\adl\\adl\\venv\\lib\\site-packages (from optuna) (24.2)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in d:\\adl\\adl\\venv\\lib\\site-packages (from optuna) (2.0.40)\n",
      "Requirement already satisfied: tqdm in d:\\adl\\adl\\venv\\lib\\site-packages (from optuna) (4.67.1)\n",
      "Requirement already satisfied: PyYAML in d:\\adl\\adl\\venv\\lib\\site-packages (from optuna) (6.0.2)\n",
      "Requirement already satisfied: Mako in d:\\adl\\adl\\venv\\lib\\site-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
      "Requirement already satisfied: typing-extensions>=4.12 in d:\\adl\\adl\\venv\\lib\\site-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
      "Requirement already satisfied: greenlet>=1 in d:\\adl\\adl\\venv\\lib\\site-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
      "Requirement already satisfied: colorama in d:\\adl\\adl\\venv\\lib\\site-packages (from colorlog->optuna) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in d:\\adl\\adl\\venv\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
      "Requirement already satisfied: optuna-dashboard in d:\\adl\\adl\\venv\\lib\\site-packages (0.18.0)\n",
      "Requirement already satisfied: bottle>=0.13.0 in d:\\adl\\adl\\venv\\lib\\site-packages (from optuna-dashboard) (0.13.2)\n",
      "Requirement already satisfied: optuna>=3.1.0 in d:\\adl\\adl\\venv\\lib\\site-packages (from optuna-dashboard) (4.3.0)\n",
      "Requirement already satisfied: packaging in d:\\adl\\adl\\venv\\lib\\site-packages (from optuna-dashboard) (24.2)\n",
      "Requirement already satisfied: scikit-learn in d:\\adl\\adl\\venv\\lib\\site-packages (from optuna-dashboard) (1.6.1)\n",
      "Requirement already satisfied: alembic>=1.5.0 in d:\\adl\\adl\\venv\\lib\\site-packages (from optuna>=3.1.0->optuna-dashboard) (1.15.2)\n",
      "Requirement already satisfied: colorlog in d:\\adl\\adl\\venv\\lib\\site-packages (from optuna>=3.1.0->optuna-dashboard) (6.9.0)\n",
      "Requirement already satisfied: numpy in d:\\adl\\adl\\venv\\lib\\site-packages (from optuna>=3.1.0->optuna-dashboard) (2.2.4)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in d:\\adl\\adl\\venv\\lib\\site-packages (from optuna>=3.1.0->optuna-dashboard) (2.0.40)\n",
      "Requirement already satisfied: tqdm in d:\\adl\\adl\\venv\\lib\\site-packages (from optuna>=3.1.0->optuna-dashboard) (4.67.1)\n",
      "Requirement already satisfied: PyYAML in d:\\adl\\adl\\venv\\lib\\site-packages (from optuna>=3.1.0->optuna-dashboard) (6.0.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in d:\\adl\\adl\\venv\\lib\\site-packages (from scikit-learn->optuna-dashboard) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in d:\\adl\\adl\\venv\\lib\\site-packages (from scikit-learn->optuna-dashboard) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in d:\\adl\\adl\\venv\\lib\\site-packages (from scikit-learn->optuna-dashboard) (3.6.0)\n",
      "Requirement already satisfied: Mako in d:\\adl\\adl\\venv\\lib\\site-packages (from alembic>=1.5.0->optuna>=3.1.0->optuna-dashboard) (1.3.10)\n",
      "Requirement already satisfied: typing-extensions>=4.12 in d:\\adl\\adl\\venv\\lib\\site-packages (from alembic>=1.5.0->optuna>=3.1.0->optuna-dashboard) (4.12.2)\n",
      "Requirement already satisfied: greenlet>=1 in d:\\adl\\adl\\venv\\lib\\site-packages (from sqlalchemy>=1.4.2->optuna>=3.1.0->optuna-dashboard) (3.1.1)\n",
      "Requirement already satisfied: colorama in d:\\adl\\adl\\venv\\lib\\site-packages (from colorlog->optuna>=3.1.0->optuna-dashboard) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in d:\\adl\\adl\\venv\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna>=3.1.0->optuna-dashboard) (3.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement scikit (from versions: none)\n",
      "ERROR: No matching distribution found for scikit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in d:\\adl\\adl\\venv\\lib\\site-packages (0.13.0)\n",
      "Requirement already satisfied: numpy<3,>=1.24.3 in d:\\adl\\adl\\venv\\lib\\site-packages (from imbalanced-learn) (2.2.4)\n",
      "Requirement already satisfied: scipy<2,>=1.10.1 in d:\\adl\\adl\\venv\\lib\\site-packages (from imbalanced-learn) (1.15.2)\n",
      "Requirement already satisfied: scikit-learn<2,>=1.3.2 in d:\\adl\\adl\\venv\\lib\\site-packages (from imbalanced-learn) (1.6.1)\n",
      "Requirement already satisfied: sklearn-compat<1,>=0.1 in d:\\adl\\adl\\venv\\lib\\site-packages (from imbalanced-learn) (0.1.3)\n",
      "Requirement already satisfied: joblib<2,>=1.1.1 in d:\\adl\\adl\\venv\\lib\\site-packages (from imbalanced-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in d:\\adl\\adl\\venv\\lib\\site-packages (from imbalanced-learn) (3.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install optuna\n",
    "!pip install optuna-dashboard\n",
    "!pip install scikit\n",
    "!pip install imbalanced-learn\n",
    "from sklearn.preprocessing import (\n",
    "    MaxAbsScaler,\n",
    "    MinMaxScaler,\n",
    "    Normalizer,\n",
    "    PowerTransformer,\n",
    "    QuantileTransformer,\n",
    "    RobustScaler,\n",
    "    StandardScaler,\n",
    "    minmax_scale,\n",
    ")\n",
    "from sklearn.metrics import recall_score, accuracy_score,f1_score, precision_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import warnings\n",
    "import optuna\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "625cfb3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using\", device)\n",
    "def init_weights(model): #tested already\n",
    "    if isinstance(model, nn.Linear):  # Apply only to linear layers\n",
    "        nn.init.xavier_uniform_(model.weight)\n",
    "        if model.bias is not None:\n",
    "            nn.init.zeros_(model.bias)\n",
    "            \n",
    "def fold_to_dataloader_tensor(train_x, test_x, train_y, test_y, batch_size=64, device=device):\n",
    "    train_dataset = TensorDataset(\n",
    "        torch.tensor(train_x.values,dtype=torch.float32).to(device), \n",
    "        torch.tensor(train_y.values,dtype=torch.float32).to(device))\n",
    "    val_dataset = TensorDataset(\n",
    "        torch.tensor(test_x.values,dtype=torch.float32).to(device), \n",
    "        torch.tensor(test_y.values,dtype=torch.float32).to(device))\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=len(val_dataset), shuffle=False, drop_last=True)\n",
    "    return train_loader, val_loader \n",
    "\n",
    "def get_feature_count(loader):\n",
    "    \"\"\"returns the number of features in the dataset\"\"\"\n",
    "    return next(iter(loader))[0].shape[1]\n",
    "\n",
    "from Criterion_Models import *\n",
    "def criterion_mapping(criterion_choice:str, pos_weight:float=None, alpha:float=None, gamma:float=None):\n",
    "    \"\"\"\n",
    "    Feel free to add any custom loss functions here.\n",
    "    returns function for criterion\n",
    "    \"\"\"\n",
    "    if criterion_choice == \"FocalLoss\":\n",
    "        return FocalLoss(alpha =alpha, gamma=gamma)\n",
    "    elif criterion_choice == \"DiceLoss\":\n",
    "        return DiceLoss()\n",
    "    elif criterion_choice == \"BCEWithLogitsLoss\":\n",
    "        return nn.BCEWithLogitsLoss(pos_weight=torch.tensor([pos_weight])) if pos_weight else nn.BCEWithLogitsLoss()\n",
    "    return nn.BCEWithLogitsLoss() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "646878a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42\n",
    "raw_dataset = pd.read_csv(\"./data/processed_data.csv\") #data has X and Y\n",
    "X = raw_dataset.drop(columns=[\"DR\"])\n",
    "Y = pd.DataFrame(raw_dataset[\"DR\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "40c058ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop cols here\n",
    "# numeric_columns = ['Age', 'UAlb', 'Ucr', 'UACR', 'TC', 'TG', 'TCTG', 'LDLC', 'HDLC', 'Scr', 'BUN', 'FPG', 'HbA1c', 'Height', 'Weight', 'BMI', 'Duration']\n",
    "# binary_columns = ['Gender', 'DR', 'Community_baihe', 'Community_chonggu', 'Community_huaxin', 'Community_jinze', 'Community_liantang', 'Community_xianghuaqiao', 'Community_xujin', 'Community_yingpu', 'Community_zhaoxian', 'Community_zhujiajiao']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "d4c9b002",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_FOR_FOLDS, X_FINAL_TEST, Y_FOR_FOLDS, Y_FINAL_TEST = train_test_split(X, Y, test_size=0.1, random_state=random_state, stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "7f4dd31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data_in_place(X, X_test, Y=None, normalisation_method=MinMaxScaler(), robust_scaler=RobustScaler(), noise=None):\n",
    "    \"\"\"\n",
    "    Apply preprocessing transformations to data in this order:\n",
    "    1. Optional log transformation for numerical features\n",
    "    2. RobustScaler to handle outliers\n",
    "    3. MinMaxScaler to normalize to [0,1] range\n",
    "    4. Optional noise addition to negative class samples\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : DataFrame\n",
    "        Training features\n",
    "    X_test : DataFrame\n",
    "        Test features\n",
    "    Y : DataFrame or Series, optional\n",
    "        Target variable (needed if adding noise selectively)\n",
    "    normalisation_method : sklearn scaler, default=MinMaxScaler()\n",
    "        Final normalization method\n",
    "    robust_scaler : sklearn scaler, default=RobustScaler()\n",
    "        Initial scaling method to handle outliers\n",
    "    noise : float, optional\n",
    "        Standard deviation of Gaussian noise to add to negative class samples\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    X_transformed, X_test_transformed : DataFrames\n",
    "        Transformed training and test data\n",
    "    \"\"\"\n",
    "    # Create copies to avoid modifying original data\n",
    "    X_transformed = X.copy()\n",
    "    X_test_transformed = X_test.copy()\n",
    "    \n",
    "    # Identify numerical columns (exclude binary ones)\n",
    "    all_numerical_columns = ['Age', 'UAlb', 'Ucr', 'UACR', 'TC', 'TG', 'TCTG', 'LDLC', \n",
    "                           'HDLC', 'Scr', 'BUN', 'FPG', 'HbA1c', 'Height', 'Weight', \n",
    "                           'BMI', 'Duration']\n",
    "    binary_columns = ['Gender', 'DR', 'Community_baihe', 'Community_chonggu', \n",
    "                    'Community_huaxin', 'Community_jinze', 'Community_liantang', \n",
    "                    'Community_xianghuaqiao', 'Community_xujin', 'Community_yingpu', \n",
    "                    'Community_zhaoxian', 'Community_zhujiajiao']\n",
    "    \n",
    "    # Find which numerical columns actually exist in the data\n",
    "    numeric_cols = [col for col in all_numerical_columns if col in X.columns and col in X_test.columns]\n",
    "    \n",
    "    if not numeric_cols:\n",
    "        print(\"No matching numerical columns found for transformation.\")\n",
    "        # Apply standard normalization to all data if no specific columns matched\n",
    "        X_normalized = pd.DataFrame(normalisation_method.fit_transform(X), columns=X.columns, index=X.index)\n",
    "        X_test_normalized = pd.DataFrame(normalisation_method.transform(X_test), columns=X_test.columns, index=X_test.index)\n",
    "        return X_normalized, X_test_normalized\n",
    "    \n",
    "    # 1. Apply log transformation to numeric columns (handling zeros/negatives with log1p)\n",
    "    # Skip log transform for any columns that have negative values\n",
    "    for col in numeric_cols:\n",
    "        if (X_transformed[col].min() >= 0) and (X_test_transformed[col].min() >= 0):\n",
    "            X_transformed[col] = np.log1p(X_transformed[col])\n",
    "            X_test_transformed[col] = np.log1p(X_test_transformed[col])\n",
    "    \n",
    "    # 2. Apply RobustScaler to handle outliers (only to numeric columns)\n",
    "    if robust_scaler:\n",
    "        robust_scaled_train = robust_scaler.fit_transform(X_transformed[numeric_cols])\n",
    "        robust_scaled_test = robust_scaler.transform(X_test_transformed[numeric_cols])\n",
    "        \n",
    "        X_transformed[numeric_cols] = robust_scaled_train\n",
    "        X_test_transformed[numeric_cols] = robust_scaled_test\n",
    "    \n",
    "    # 3. Apply final normalization method (to all columns)\n",
    "    X_normalized = normalisation_method.fit_transform(X_transformed)\n",
    "    X_test_normalized = normalisation_method.transform(X_test_transformed)\n",
    "    \n",
    "    # Convert back to DataFrame with original column names\n",
    "    X_normalized = pd.DataFrame(X_normalized, columns=X.columns, index=X.index)\n",
    "    X_test_normalized = pd.DataFrame(X_test_normalized, columns=X_test.columns, index=X_test.index)\n",
    "    \n",
    "    # 4. Add noise ONLY to negatives (class 0) if Y is provided and noise is set\n",
    "    if noise is not None and noise > 0 and Y is not None:\n",
    "        # Identify negative class indices (class 0)\n",
    "        if isinstance(Y, pd.DataFrame):\n",
    "            negative_indices = Y[Y.iloc[:, 0] == 0].index\n",
    "        else:  # Handle Series case\n",
    "            negative_indices = Y[Y == 0].index\n",
    "            \n",
    "        # Add noise only to negative samples and only to numerical columns\n",
    "        if len(negative_indices) > 0:\n",
    "            noise_matrix = np.random.normal(0, noise, (len(negative_indices), len(numeric_cols)))\n",
    "            X_normalized.loc[negative_indices, numeric_cols] += noise_matrix\n",
    "            \n",
    "            # Ensure values stay within [0,1] range after noise addition\n",
    "            X_normalized.loc[negative_indices, numeric_cols] = np.clip(\n",
    "                X_normalized.loc[negative_indices, numeric_cols], 0, 1)\n",
    "    \n",
    "    return X_normalized, X_test_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "8f98c91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iso_forest(X_train, Y_train, contamination=None, random_state=42):\n",
    "    # Create copies of input data\n",
    "    X_train_cleaned, Y_train_cleaned = X_train.copy(), Y_train.copy()\n",
    "    \n",
    "    # Handle Y_train whether it's a DataFrame or Series\n",
    "    if isinstance(Y_train, pd.DataFrame):\n",
    "        class_values = Y_train.iloc[:, 0]\n",
    "    else:  # It's a Series\n",
    "        class_values = Y_train\n",
    "    \n",
    "    # Split data by class\n",
    "    X_train_zeros = X_train[class_values == 0]\n",
    "    X_train_ones = X_train[class_values == 1]\n",
    "    Y_train_zeros = Y_train[class_values == 0]\n",
    "    Y_train_ones = Y_train[class_values == 1]\n",
    "    \n",
    "    # Print debug info\n",
    "    print(f\"Class distribution - Zeros: {len(X_train_zeros)}, Ones: {len(X_train_ones)}\")\n",
    "    \n",
    "    # Check if we have enough samples to apply Isolation Forest\n",
    "    if len(X_train_zeros) <= 1:\n",
    "        print(\"Not enough majority class samples for Isolation Forest. Skipping.\")\n",
    "        return X_train, Y_train\n",
    "    \n",
    "    # Apply Isolation Forest to majority class only\n",
    "    if X_train_zeros.isna().any().any():\n",
    "        print(\"Warning: NaN values in the training set\")\n",
    "    \n",
    "    # Apply Isolation Forest to majority class only\n",
    "    iso_forest = IsolationForest(contamination=contamination, random_state=random_state)\n",
    "    try:\n",
    "        outliers = iso_forest.fit_predict(X_train_zeros)\n",
    "    except Exception as e:\n",
    "        print(f\"Error during IsolationForest fitting: {e}\")\n",
    "        return X_train, Y_train  # Return original data if it fails\n",
    "    \n",
    "    # Keep only non-outlier majority samples\n",
    "    X_train_zeros = X_train_zeros[outliers == 1]\n",
    "    Y_train_zeros = Y_train_zeros[outliers == 1]\n",
    "    \n",
    "    print(f\"After Isolation Forest - Kept {len(X_train_zeros)} out of {len(outliers)} majority samples\")\n",
    "    \n",
    "    # Combine the cleaned majority class with the untouched minority class\n",
    "    X_train_cleaned = pd.concat([X_train_zeros, X_train_ones])\n",
    "    Y_train_cleaned = pd.concat([Y_train_zeros, Y_train_ones])\n",
    "    \n",
    "    return X_train_cleaned, Y_train_cleaned\n",
    "\n",
    "def FOLDS_GENERATOR(X, Y, normalisation_method=MinMaxScaler(), n_splits=5, random_state=None, oversampler=None, contamination=0.05, noise=None):\n",
    "    \"\"\"\n",
    "    Generates stratified folds with specified normalization.\n",
    "    \"\"\"\n",
    "    kF = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    kFolds_list = []\n",
    "\n",
    "    robust_scaler = RobustScaler()\n",
    "    \n",
    "    # Convert column names to strings to ensure compatibility\n",
    "    X = X.copy()\n",
    "    X.columns = [str(col) for col in X.columns]\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(kF.split(X, Y)):\n",
    "        # Split the data into training and testing sets for this fold\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        Y_train, Y_test = Y.iloc[train_idx], Y.iloc[test_idx]\n",
    "        \n",
    "        # Initialize cleaned data with original data\n",
    "        X_train_cleaned, Y_train_cleaned = X_train.copy(), Y_train.copy()\n",
    "        \n",
    "        # Apply isolation forest if contamination is specified\n",
    "        if contamination is not None and contamination > 0:\n",
    "            X_train_cleaned, Y_train_cleaned = iso_forest(X_train, Y_train, contamination=contamination, random_state=random_state)\n",
    "        \n",
    "        # Data augmentation on cleaned data\n",
    "        X_train_scaled, X_test_scaled = augment_data_in_place(X_train_cleaned, X_test, Y_train_cleaned, \n",
    "                                                             normalisation_method=normalisation_method, \n",
    "                                                             robust_scaler=robust_scaler, \n",
    "                                                             noise=noise)\n",
    "        \n",
    "        # Handle oversampling if needed\n",
    "        print(\"Before oversampling class distribution:\")\n",
    "        print(Y_train_cleaned.value_counts())\n",
    "        if oversampler:\n",
    "            X_train_scaled, Y_train_cleaned = oversampler.fit_resample(X_train_scaled, Y_train_cleaned)\n",
    "        print(\"\\nAfter oversampling class distribution:\")\n",
    "        print(Y_train_cleaned.value_counts())\n",
    "        \n",
    "\n",
    "        # Handle community columns with safeguards\n",
    "        # First check if columns are string type\n",
    "        community_cols = []\n",
    "        for col in X_train_scaled.columns:\n",
    "            col_str = str(col)  # Convert to string if not already\n",
    "            if isinstance(col_str, str) and col_str.startswith('Community'):\n",
    "                community_cols.append(col)\n",
    "\n",
    "        if community_cols:\n",
    "            try:\n",
    "                X_train_scaled[community_cols] = X_train_scaled[community_cols].apply(\n",
    "                    lambda row: pd.Series(np.eye(len(row))[row.argmax()], index=community_cols), axis=1\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Error processing community columns: {e}. Skipping one-hot encoding.\")\n",
    "\n",
    "        # Ensure 'Gender' is still binary (0 or 1) if it exists\n",
    "        if 'Gender' in X_train_scaled.columns:\n",
    "            X_train_scaled['Gender'] = (X_train_scaled['Gender'] > 0.5).astype(int)\n",
    "            X_test_scaled['Gender'] = (X_test_scaled['Gender'] > 0.5).astype(int)\n",
    "\n",
    "        # Append the processed fold to the list\n",
    "        kFolds_list.append((X_train_scaled, X_test_scaled, Y_train_cleaned, Y_test))\n",
    "\n",
    "        print(f\"Fold: {fold+1}, Train: {X_train_scaled.shape}, Test: {X_test_scaled.shape}\")\n",
    "\n",
    "    return kFolds_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "67a2c06b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution - Zeros: 4129, Ones: 464\n",
      "After Isolation Forest - Kept 3922 out of 4129 majority samples\n",
      "Before oversampling class distribution:\n",
      "DR \n",
      "0.0    3922\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "\n",
      "After oversampling class distribution:\n",
      "DR \n",
      "1.0    3979\n",
      "0.0    3922\n",
      "Name: count, dtype: int64\n",
      "Fold: 1, Train: (7901, 28), Test: (1149, 28)\n",
      "Class distribution - Zeros: 4129, Ones: 464\n",
      "After Isolation Forest - Kept 3922 out of 4129 majority samples\n",
      "Before oversampling class distribution:\n",
      "DR \n",
      "0.0    3922\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "\n",
      "After oversampling class distribution:\n",
      "DR \n",
      "1.0    3960\n",
      "0.0    3922\n",
      "Name: count, dtype: int64\n",
      "Fold: 2, Train: (7882, 28), Test: (1149, 28)\n",
      "Class distribution - Zeros: 4130, Ones: 464\n",
      "After Isolation Forest - Kept 3923 out of 4130 majority samples\n",
      "Before oversampling class distribution:\n",
      "DR \n",
      "0.0    3923\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "\n",
      "After oversampling class distribution:\n",
      "DR \n",
      "1.0    3963\n",
      "0.0    3923\n",
      "Name: count, dtype: int64\n",
      "Fold: 3, Train: (7886, 28), Test: (1148, 28)\n",
      "Class distribution - Zeros: 4130, Ones: 464\n",
      "After Isolation Forest - Kept 3923 out of 4130 majority samples\n",
      "Before oversampling class distribution:\n",
      "DR \n",
      "0.0    3923\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "\n",
      "After oversampling class distribution:\n",
      "DR \n",
      "1.0    3958\n",
      "0.0    3923\n",
      "Name: count, dtype: int64\n",
      "Fold: 4, Train: (7881, 28), Test: (1148, 28)\n",
      "Class distribution - Zeros: 4130, Ones: 464\n",
      "After Isolation Forest - Kept 3923 out of 4130 majority samples\n",
      "Before oversampling class distribution:\n",
      "DR \n",
      "0.0    3923\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "\n",
      "After oversampling class distribution:\n",
      "DR \n",
      "1.0    3956\n",
      "0.0    3923\n",
      "Name: count, dtype: int64\n",
      "Fold: 5, Train: (7879, 28), Test: (1148, 28)\n",
      "\n",
      "Training Data Feature Scaling - Fold: 1\n",
      "Min values:\n",
      " Age                       0.0\n",
      "Gender                    0.0\n",
      "UAlb                      0.0\n",
      "Ucr                       0.0\n",
      "UACR                      0.0\n",
      "TC                        0.0\n",
      "TG                        0.0\n",
      "TCTG                      0.0\n",
      "LDLC                      0.0\n",
      "HDLC                      0.0\n",
      "Scr                       0.0\n",
      "BUN                       0.0\n",
      "FPG                       0.0\n",
      "HbA1c                     0.0\n",
      "Height                    0.0\n",
      "Weight                    0.0\n",
      "BMI                       0.0\n",
      "Duration                  0.0\n",
      "Community_baihe           0.0\n",
      "Community_chonggu         0.0\n",
      "Community_huaxin          0.0\n",
      "Community_jinze           0.0\n",
      "Community_liantang        0.0\n",
      "Community_xianghuaqiao    0.0\n",
      "Community_xujin           0.0\n",
      "Community_yingpu          0.0\n",
      "Community_zhaoxian        0.0\n",
      "Community_zhujiajiao      0.0\n",
      "dtype: float64\n",
      "Max values:\n",
      " Age                       1.0\n",
      "Gender                    1.0\n",
      "UAlb                      1.0\n",
      "Ucr                       1.0\n",
      "UACR                      1.0\n",
      "TC                        1.0\n",
      "TG                        1.0\n",
      "TCTG                      1.0\n",
      "LDLC                      1.0\n",
      "HDLC                      1.0\n",
      "Scr                       1.0\n",
      "BUN                       1.0\n",
      "FPG                       1.0\n",
      "HbA1c                     1.0\n",
      "Height                    1.0\n",
      "Weight                    1.0\n",
      "BMI                       1.0\n",
      "Duration                  1.0\n",
      "Community_baihe           1.0\n",
      "Community_chonggu         1.0\n",
      "Community_huaxin          1.0\n",
      "Community_jinze           1.0\n",
      "Community_liantang        1.0\n",
      "Community_xianghuaqiao    1.0\n",
      "Community_xujin           1.0\n",
      "Community_yingpu          1.0\n",
      "Community_zhaoxian        1.0\n",
      "Community_zhujiajiao      1.0\n",
      "dtype: float64\n",
      "\n",
      "Testing Data Feature Scaling - Fold: 1\n",
      "Min values:\n",
      " Age                       0.000000\n",
      "Gender                    0.000000\n",
      "UAlb                      0.000000\n",
      "Ucr                      -0.074277\n",
      "UACR                      0.000000\n",
      "TC                        0.095015\n",
      "TG                        0.029534\n",
      "TCTG                      0.000000\n",
      "LDLC                      0.062928\n",
      "HDLC                      0.068840\n",
      "Scr                       0.016370\n",
      "BUN                       0.189464\n",
      "FPG                       0.000000\n",
      "HbA1c                    -0.018471\n",
      "Height                    0.617826\n",
      "Weight                    0.072993\n",
      "BMI                      -0.020522\n",
      "Duration                  0.025360\n",
      "Community_baihe           0.000000\n",
      "Community_chonggu         0.000000\n",
      "Community_huaxin          0.000000\n",
      "Community_jinze           0.000000\n",
      "Community_liantang        0.000000\n",
      "Community_xianghuaqiao    0.000000\n",
      "Community_xujin           0.000000\n",
      "Community_yingpu          0.000000\n",
      "Community_zhaoxian        0.000000\n",
      "Community_zhujiajiao      0.000000\n",
      "dtype: float64\n",
      "Max values:\n",
      " Age                       0.927642\n",
      "Gender                    1.000000\n",
      "UAlb                      0.996363\n",
      "Ucr                       1.000672\n",
      "UACR                      0.995117\n",
      "TC                        0.899566\n",
      "TG                        0.664370\n",
      "TCTG                      0.973333\n",
      "LDLC                      1.038626\n",
      "HDLC                      1.023293\n",
      "Scr                       0.908064\n",
      "BUN                       1.002110\n",
      "FPG                       0.899621\n",
      "HbA1c                     0.981029\n",
      "Height                    0.960796\n",
      "Weight                    1.938269\n",
      "BMI                       1.751699\n",
      "Duration                  0.963520\n",
      "Community_baihe           1.000000\n",
      "Community_chonggu         1.000000\n",
      "Community_huaxin          1.000000\n",
      "Community_jinze           1.000000\n",
      "Community_liantang        1.000000\n",
      "Community_xianghuaqiao    1.000000\n",
      "Community_xujin           1.000000\n",
      "Community_yingpu          1.000000\n",
      "Community_zhaoxian        1.000000\n",
      "Community_zhujiajiao      1.000000\n",
      "dtype: float64\n",
      "\n",
      "'Gender' column in Training Data - Fold: 1\n",
      "[1 0]\n",
      "\n",
      "'Gender' column in Testing Data - Fold: 1\n",
      "[1 0]\n",
      "\n",
      "'Community' columns in Training Data - Fold: 1\n",
      "Community_baihe: [0. 1.]\n",
      "Community_chonggu: [0. 1.]\n",
      "Community_huaxin: [0. 1.]\n",
      "Community_jinze: [0. 1.]\n",
      "Community_liantang: [0. 1.]\n",
      "Community_xianghuaqiao: [0. 1.]\n",
      "Community_xujin: [0. 1.]\n",
      "Community_yingpu: [0. 1.]\n",
      "Community_zhaoxian: [1. 0.]\n",
      "Community_zhujiajiao: [0. 1.]\n",
      "\n",
      "'Community' columns in Testing Data - Fold: 1\n",
      "Community_baihe: [0. 1.]\n",
      "Community_chonggu: [1. 0.]\n",
      "Community_huaxin: [0. 1.]\n",
      "Community_jinze: [0. 1.]\n",
      "Community_liantang: [0. 1.]\n",
      "Community_xianghuaqiao: [0. 1.]\n",
      "Community_xujin: [0. 1.]\n",
      "Community_yingpu: [0. 1.]\n",
      "Community_zhaoxian: [0. 1.]\n",
      "Community_zhujiajiao: [0. 1.]\n",
      "\n",
      "Training Data Feature Scaling - Fold: 2\n",
      "Min values:\n",
      " Age                       0.0\n",
      "Gender                    0.0\n",
      "UAlb                      0.0\n",
      "Ucr                       0.0\n",
      "UACR                      0.0\n",
      "TC                        0.0\n",
      "TG                        0.0\n",
      "TCTG                      0.0\n",
      "LDLC                      0.0\n",
      "HDLC                      0.0\n",
      "Scr                       0.0\n",
      "BUN                       0.0\n",
      "FPG                       0.0\n",
      "HbA1c                     0.0\n",
      "Height                    0.0\n",
      "Weight                    0.0\n",
      "BMI                       0.0\n",
      "Duration                  0.0\n",
      "Community_baihe           0.0\n",
      "Community_chonggu         0.0\n",
      "Community_huaxin          0.0\n",
      "Community_jinze           0.0\n",
      "Community_liantang        0.0\n",
      "Community_xianghuaqiao    0.0\n",
      "Community_xujin           0.0\n",
      "Community_yingpu          0.0\n",
      "Community_zhaoxian        0.0\n",
      "Community_zhujiajiao      0.0\n",
      "dtype: float64\n",
      "Max values:\n",
      " Age                       1.0\n",
      "Gender                    1.0\n",
      "UAlb                      1.0\n",
      "Ucr                       1.0\n",
      "UACR                      1.0\n",
      "TC                        1.0\n",
      "TG                        1.0\n",
      "TCTG                      1.0\n",
      "LDLC                      1.0\n",
      "HDLC                      1.0\n",
      "Scr                       1.0\n",
      "BUN                       1.0\n",
      "FPG                       1.0\n",
      "HbA1c                     1.0\n",
      "Height                    1.0\n",
      "Weight                    1.0\n",
      "BMI                       1.0\n",
      "Duration                  1.0\n",
      "Community_baihe           1.0\n",
      "Community_chonggu         1.0\n",
      "Community_huaxin          1.0\n",
      "Community_jinze           1.0\n",
      "Community_liantang        1.0\n",
      "Community_xianghuaqiao    1.0\n",
      "Community_xujin           1.0\n",
      "Community_yingpu          1.0\n",
      "Community_zhaoxian        1.0\n",
      "Community_zhujiajiao      1.0\n",
      "dtype: float64\n",
      "\n",
      "Testing Data Feature Scaling - Fold: 2\n",
      "Min values:\n",
      " Age                       0.057117\n",
      "Gender                    0.000000\n",
      "UAlb                      0.000000\n",
      "Ucr                       0.069098\n",
      "UACR                      0.000000\n",
      "TC                        0.054044\n",
      "TG                       -0.028278\n",
      "TCTG                      0.000000\n",
      "LDLC                     -0.119022\n",
      "HDLC                      0.012936\n",
      "Scr                      -0.016642\n",
      "BUN                       0.176953\n",
      "FPG                       0.000000\n",
      "HbA1c                    -0.181744\n",
      "Height                   -0.023125\n",
      "Weight                    0.074783\n",
      "BMI                       0.079979\n",
      "Duration                  0.070288\n",
      "Community_baihe           0.000000\n",
      "Community_chonggu         0.000000\n",
      "Community_huaxin          0.000000\n",
      "Community_jinze           0.000000\n",
      "Community_liantang        0.000000\n",
      "Community_xianghuaqiao    0.000000\n",
      "Community_xujin           0.000000\n",
      "Community_yingpu          0.000000\n",
      "Community_zhaoxian        0.000000\n",
      "Community_zhujiajiao      0.000000\n",
      "dtype: float64\n",
      "Max values:\n",
      " Age                       0.964424\n",
      "Gender                    1.000000\n",
      "UAlb                      0.996491\n",
      "Ucr                       0.999375\n",
      "UACR                      1.082868\n",
      "TC                        0.810170\n",
      "TG                        0.656584\n",
      "TCTG                      1.069850\n",
      "LDLC                      0.962811\n",
      "HDLC                      0.886958\n",
      "Scr                       1.019782\n",
      "BUN                       0.886401\n",
      "FPG                       0.866536\n",
      "HbA1c                     0.981373\n",
      "Height                    0.897420\n",
      "Weight                    1.024531\n",
      "BMI                       1.022913\n",
      "Duration                  0.963520\n",
      "Community_baihe           1.000000\n",
      "Community_chonggu         1.000000\n",
      "Community_huaxin          1.000000\n",
      "Community_jinze           1.000000\n",
      "Community_liantang        1.000000\n",
      "Community_xianghuaqiao    1.000000\n",
      "Community_xujin           1.000000\n",
      "Community_yingpu          1.000000\n",
      "Community_zhaoxian        1.000000\n",
      "Community_zhujiajiao      1.000000\n",
      "dtype: float64\n",
      "\n",
      "'Gender' column in Training Data - Fold: 2\n",
      "[1 0]\n",
      "\n",
      "'Gender' column in Testing Data - Fold: 2\n",
      "[1 0]\n",
      "\n",
      "'Community' columns in Training Data - Fold: 2\n",
      "Community_baihe: [0. 1.]\n",
      "Community_chonggu: [0. 1.]\n",
      "Community_huaxin: [0. 1.]\n",
      "Community_jinze: [1. 0.]\n",
      "Community_liantang: [0. 1.]\n",
      "Community_xianghuaqiao: [0. 1.]\n",
      "Community_xujin: [0. 1.]\n",
      "Community_yingpu: [0. 1.]\n",
      "Community_zhaoxian: [0. 1.]\n",
      "Community_zhujiajiao: [0. 1.]\n",
      "\n",
      "'Community' columns in Testing Data - Fold: 2\n",
      "Community_baihe: [0. 1.]\n",
      "Community_chonggu: [0. 1.]\n",
      "Community_huaxin: [0. 1.]\n",
      "Community_jinze: [0. 1.]\n",
      "Community_liantang: [0. 1.]\n",
      "Community_xianghuaqiao: [0. 1.]\n",
      "Community_xujin: [0. 1.]\n",
      "Community_yingpu: [0. 1.]\n",
      "Community_zhaoxian: [1. 0.]\n",
      "Community_zhujiajiao: [0. 1.]\n",
      "\n",
      "Training Data Feature Scaling - Fold: 3\n",
      "Min values:\n",
      " Age                       0.0\n",
      "Gender                    0.0\n",
      "UAlb                      0.0\n",
      "Ucr                       0.0\n",
      "UACR                      0.0\n",
      "TC                        0.0\n",
      "TG                        0.0\n",
      "TCTG                      0.0\n",
      "LDLC                      0.0\n",
      "HDLC                      0.0\n",
      "Scr                       0.0\n",
      "BUN                       0.0\n",
      "FPG                       0.0\n",
      "HbA1c                     0.0\n",
      "Height                    0.0\n",
      "Weight                    0.0\n",
      "BMI                       0.0\n",
      "Duration                  0.0\n",
      "Community_baihe           0.0\n",
      "Community_chonggu         0.0\n",
      "Community_huaxin          0.0\n",
      "Community_jinze           0.0\n",
      "Community_liantang        0.0\n",
      "Community_xianghuaqiao    0.0\n",
      "Community_xujin           0.0\n",
      "Community_yingpu          0.0\n",
      "Community_zhaoxian        0.0\n",
      "Community_zhujiajiao      0.0\n",
      "dtype: float64\n",
      "Max values:\n",
      " Age                       1.0\n",
      "Gender                    1.0\n",
      "UAlb                      1.0\n",
      "Ucr                       1.0\n",
      "UACR                      1.0\n",
      "TC                        1.0\n",
      "TG                        1.0\n",
      "TCTG                      1.0\n",
      "LDLC                      1.0\n",
      "HDLC                      1.0\n",
      "Scr                       1.0\n",
      "BUN                       1.0\n",
      "FPG                       1.0\n",
      "HbA1c                     1.0\n",
      "Height                    1.0\n",
      "Weight                    1.0\n",
      "BMI                       1.0\n",
      "Duration                  1.0\n",
      "Community_baihe           1.0\n",
      "Community_chonggu         1.0\n",
      "Community_huaxin          1.0\n",
      "Community_jinze           1.0\n",
      "Community_liantang        1.0\n",
      "Community_xianghuaqiao    1.0\n",
      "Community_xujin           1.0\n",
      "Community_yingpu          1.0\n",
      "Community_zhaoxian        1.0\n",
      "Community_zhujiajiao      1.0\n",
      "dtype: float64\n",
      "\n",
      "Testing Data Feature Scaling - Fold: 3\n",
      "Min values:\n",
      " Age                       0.029278\n",
      "Gender                    0.000000\n",
      "UAlb                      0.000000\n",
      "Ucr                       0.069098\n",
      "UACR                      0.000000\n",
      "TC                        0.118751\n",
      "TG                        0.031375\n",
      "TCTG                      0.002227\n",
      "LDLC                      0.070955\n",
      "HDLC                      0.006914\n",
      "Scr                       0.062185\n",
      "BUN                       0.096820\n",
      "FPG                       0.010853\n",
      "HbA1c                     0.053364\n",
      "Height                   -1.699041\n",
      "Weight                    0.056795\n",
      "BMI                       0.053225\n",
      "Duration                 -0.026020\n",
      "Community_baihe           0.000000\n",
      "Community_chonggu         0.000000\n",
      "Community_huaxin          0.000000\n",
      "Community_jinze           0.000000\n",
      "Community_liantang        0.000000\n",
      "Community_xianghuaqiao    0.000000\n",
      "Community_xujin           0.000000\n",
      "Community_yingpu          0.000000\n",
      "Community_zhaoxian        0.000000\n",
      "Community_zhujiajiao      0.000000\n",
      "dtype: float64\n",
      "Max values:\n",
      " Age                       1.011869\n",
      "Gender                    1.000000\n",
      "UAlb                      0.996804\n",
      "Ucr                       0.999820\n",
      "UACR                      0.917217\n",
      "TC                        1.326725\n",
      "TG                        0.897859\n",
      "TCTG                      0.959505\n",
      "LDLC                      0.948977\n",
      "HDLC                      1.065615\n",
      "Scr                       1.019458\n",
      "BUN                       1.034406\n",
      "FPG                       0.767961\n",
      "HbA1c                     0.923103\n",
      "Height                    1.036653\n",
      "Weight                    0.932062\n",
      "BMI                       1.295892\n",
      "Duration                  0.991073\n",
      "Community_baihe           1.000000\n",
      "Community_chonggu         1.000000\n",
      "Community_huaxin          1.000000\n",
      "Community_jinze           1.000000\n",
      "Community_liantang        1.000000\n",
      "Community_xianghuaqiao    1.000000\n",
      "Community_xujin           1.000000\n",
      "Community_yingpu          1.000000\n",
      "Community_zhaoxian        1.000000\n",
      "Community_zhujiajiao      1.000000\n",
      "dtype: float64\n",
      "\n",
      "'Gender' column in Training Data - Fold: 3\n",
      "[1 0]\n",
      "\n",
      "'Gender' column in Testing Data - Fold: 3\n",
      "[0 1]\n",
      "\n",
      "'Community' columns in Training Data - Fold: 3\n",
      "Community_baihe: [0. 1.]\n",
      "Community_chonggu: [0. 1.]\n",
      "Community_huaxin: [0. 1.]\n",
      "Community_jinze: [0. 1.]\n",
      "Community_liantang: [0. 1.]\n",
      "Community_xianghuaqiao: [0. 1.]\n",
      "Community_xujin: [0. 1.]\n",
      "Community_yingpu: [0. 1.]\n",
      "Community_zhaoxian: [1. 0.]\n",
      "Community_zhujiajiao: [0. 1.]\n",
      "\n",
      "'Community' columns in Testing Data - Fold: 3\n",
      "Community_baihe: [0. 1.]\n",
      "Community_chonggu: [0. 1.]\n",
      "Community_huaxin: [0. 1.]\n",
      "Community_jinze: [0. 1.]\n",
      "Community_liantang: [0. 1.]\n",
      "Community_xianghuaqiao: [0. 1.]\n",
      "Community_xujin: [0. 1.]\n",
      "Community_yingpu: [1. 0.]\n",
      "Community_zhaoxian: [0. 1.]\n",
      "Community_zhujiajiao: [0. 1.]\n",
      "\n",
      "Training Data Feature Scaling - Fold: 4\n",
      "Min values:\n",
      " Age                       0.0\n",
      "Gender                    0.0\n",
      "UAlb                      0.0\n",
      "Ucr                       0.0\n",
      "UACR                      0.0\n",
      "TC                        0.0\n",
      "TG                        0.0\n",
      "TCTG                      0.0\n",
      "LDLC                      0.0\n",
      "HDLC                      0.0\n",
      "Scr                       0.0\n",
      "BUN                       0.0\n",
      "FPG                       0.0\n",
      "HbA1c                     0.0\n",
      "Height                    0.0\n",
      "Weight                    0.0\n",
      "BMI                       0.0\n",
      "Duration                  0.0\n",
      "Community_baihe           0.0\n",
      "Community_chonggu         0.0\n",
      "Community_huaxin          0.0\n",
      "Community_jinze           0.0\n",
      "Community_liantang        0.0\n",
      "Community_xianghuaqiao    0.0\n",
      "Community_xujin           0.0\n",
      "Community_yingpu          0.0\n",
      "Community_zhaoxian        0.0\n",
      "Community_zhujiajiao      0.0\n",
      "dtype: float64\n",
      "Max values:\n",
      " Age                       1.0\n",
      "Gender                    1.0\n",
      "UAlb                      1.0\n",
      "Ucr                       1.0\n",
      "UACR                      1.0\n",
      "TC                        1.0\n",
      "TG                        1.0\n",
      "TCTG                      1.0\n",
      "LDLC                      1.0\n",
      "HDLC                      1.0\n",
      "Scr                       1.0\n",
      "BUN                       1.0\n",
      "FPG                       1.0\n",
      "HbA1c                     1.0\n",
      "Height                    1.0\n",
      "Weight                    1.0\n",
      "BMI                       1.0\n",
      "Duration                  1.0\n",
      "Community_baihe           1.0\n",
      "Community_chonggu         1.0\n",
      "Community_huaxin          1.0\n",
      "Community_jinze           1.0\n",
      "Community_liantang        1.0\n",
      "Community_xianghuaqiao    1.0\n",
      "Community_xujin           1.0\n",
      "Community_yingpu          1.0\n",
      "Community_zhaoxian        1.0\n",
      "Community_zhujiajiao      1.0\n",
      "dtype: float64\n",
      "\n",
      "Testing Data Feature Scaling - Fold: 4\n",
      "Min values:\n",
      " Age                       0.000000\n",
      "Gender                    0.000000\n",
      "UAlb                      0.000000\n",
      "Ucr                       0.069098\n",
      "UACR                      0.000000\n",
      "TC                        0.063107\n",
      "TG                        0.036811\n",
      "TCTG                      0.000000\n",
      "LDLC                      0.077529\n",
      "HDLC                     -0.006962\n",
      "Scr                       0.035422\n",
      "BUN                      -0.107200\n",
      "FPG                       0.035938\n",
      "HbA1c                     0.137629\n",
      "Height                    0.023785\n",
      "Weight                   -0.068682\n",
      "BMI                       0.025476\n",
      "Duration                  0.025360\n",
      "Community_baihe           0.000000\n",
      "Community_chonggu         0.000000\n",
      "Community_huaxin          0.000000\n",
      "Community_jinze           0.000000\n",
      "Community_liantang        0.000000\n",
      "Community_xianghuaqiao    0.000000\n",
      "Community_xujin           0.000000\n",
      "Community_yingpu          0.000000\n",
      "Community_zhaoxian        0.000000\n",
      "Community_zhujiajiao      0.000000\n",
      "dtype: float64\n",
      "Max values:\n",
      " Age                       0.988270\n",
      "Gender                    1.000000\n",
      "UAlb                      1.002079\n",
      "Ucr                       0.994616\n",
      "UACR                      1.010021\n",
      "TC                        0.779801\n",
      "TG                        0.775050\n",
      "TCTG                      0.894557\n",
      "LDLC                      0.875759\n",
      "HDLC                      0.950717\n",
      "Scr                       1.546202\n",
      "BUN                       1.059256\n",
      "FPG                       1.125316\n",
      "HbA1c                     0.987297\n",
      "Height                    1.052329\n",
      "Weight                    1.000000\n",
      "BMI                       1.000000\n",
      "Duration                  0.982331\n",
      "Community_baihe           1.000000\n",
      "Community_chonggu         1.000000\n",
      "Community_huaxin          1.000000\n",
      "Community_jinze           1.000000\n",
      "Community_liantang        1.000000\n",
      "Community_xianghuaqiao    1.000000\n",
      "Community_xujin           1.000000\n",
      "Community_yingpu          1.000000\n",
      "Community_zhaoxian        1.000000\n",
      "Community_zhujiajiao      1.000000\n",
      "dtype: float64\n",
      "\n",
      "'Gender' column in Training Data - Fold: 4\n",
      "[1 0]\n",
      "\n",
      "'Gender' column in Testing Data - Fold: 4\n",
      "[0 1]\n",
      "\n",
      "'Community' columns in Training Data - Fold: 4\n",
      "Community_baihe: [0. 1.]\n",
      "Community_chonggu: [0. 1.]\n",
      "Community_huaxin: [0. 1.]\n",
      "Community_jinze: [0. 1.]\n",
      "Community_liantang: [0. 1.]\n",
      "Community_xianghuaqiao: [0. 1.]\n",
      "Community_xujin: [0. 1.]\n",
      "Community_yingpu: [0. 1.]\n",
      "Community_zhaoxian: [1. 0.]\n",
      "Community_zhujiajiao: [0. 1.]\n",
      "\n",
      "'Community' columns in Testing Data - Fold: 4\n",
      "Community_baihe: [0. 1.]\n",
      "Community_chonggu: [1. 0.]\n",
      "Community_huaxin: [0. 1.]\n",
      "Community_jinze: [0. 1.]\n",
      "Community_liantang: [0. 1.]\n",
      "Community_xianghuaqiao: [0. 1.]\n",
      "Community_xujin: [0. 1.]\n",
      "Community_yingpu: [0. 1.]\n",
      "Community_zhaoxian: [0. 1.]\n",
      "Community_zhujiajiao: [0. 1.]\n",
      "\n",
      "Training Data Feature Scaling - Fold: 5\n",
      "Min values:\n",
      " Age                       0.0\n",
      "Gender                    0.0\n",
      "UAlb                      0.0\n",
      "Ucr                       0.0\n",
      "UACR                      0.0\n",
      "TC                        0.0\n",
      "TG                        0.0\n",
      "TCTG                      0.0\n",
      "LDLC                      0.0\n",
      "HDLC                      0.0\n",
      "Scr                       0.0\n",
      "BUN                       0.0\n",
      "FPG                       0.0\n",
      "HbA1c                     0.0\n",
      "Height                    0.0\n",
      "Weight                    0.0\n",
      "BMI                       0.0\n",
      "Duration                  0.0\n",
      "Community_baihe           0.0\n",
      "Community_chonggu         0.0\n",
      "Community_huaxin          0.0\n",
      "Community_jinze           0.0\n",
      "Community_liantang        0.0\n",
      "Community_xianghuaqiao    0.0\n",
      "Community_xujin           0.0\n",
      "Community_yingpu          0.0\n",
      "Community_zhaoxian        0.0\n",
      "Community_zhujiajiao      0.0\n",
      "dtype: float64\n",
      "Max values:\n",
      " Age                       1.0\n",
      "Gender                    1.0\n",
      "UAlb                      1.0\n",
      "Ucr                       1.0\n",
      "UACR                      1.0\n",
      "TC                        1.0\n",
      "TG                        1.0\n",
      "TCTG                      1.0\n",
      "LDLC                      1.0\n",
      "HDLC                      1.0\n",
      "Scr                       1.0\n",
      "BUN                       1.0\n",
      "FPG                       1.0\n",
      "HbA1c                     1.0\n",
      "Height                    1.0\n",
      "Weight                    1.0\n",
      "BMI                       1.0\n",
      "Duration                  1.0\n",
      "Community_baihe           1.0\n",
      "Community_chonggu         1.0\n",
      "Community_huaxin          1.0\n",
      "Community_jinze           1.0\n",
      "Community_liantang        1.0\n",
      "Community_xianghuaqiao    1.0\n",
      "Community_xujin           1.0\n",
      "Community_yingpu          1.0\n",
      "Community_zhaoxian        1.0\n",
      "Community_zhujiajiao      1.0\n",
      "dtype: float64\n",
      "\n",
      "Testing Data Feature Scaling - Fold: 5\n",
      "Min values:\n",
      " Age                      -0.060292\n",
      "Gender                    0.000000\n",
      "UAlb                      0.000000\n",
      "Ucr                       0.000000\n",
      "UACR                      0.000000\n",
      "TC                       -0.075445\n",
      "TG                       -0.003146\n",
      "TCTG                      0.000000\n",
      "LDLC                      0.115268\n",
      "HDLC                      0.025713\n",
      "Scr                       0.062185\n",
      "BUN                       0.138606\n",
      "FPG                       0.021496\n",
      "HbA1c                     0.231302\n",
      "Height                    0.626600\n",
      "Weight                    0.065845\n",
      "BMI                       0.045475\n",
      "Duration                  0.025583\n",
      "Community_baihe           0.000000\n",
      "Community_chonggu         0.000000\n",
      "Community_huaxin          0.000000\n",
      "Community_jinze           0.000000\n",
      "Community_liantang        0.000000\n",
      "Community_xianghuaqiao    0.000000\n",
      "Community_xujin           0.000000\n",
      "Community_yingpu          0.000000\n",
      "Community_zhaoxian        0.000000\n",
      "Community_zhujiajiao      0.000000\n",
      "dtype: float64\n",
      "Max values:\n",
      " Age                       0.927642\n",
      "Gender                    1.000000\n",
      "UAlb                      1.003521\n",
      "Ucr                       0.999785\n",
      "UACR                      1.437579\n",
      "TC                        1.358458\n",
      "TG                        1.501439\n",
      "TCTG                      0.934711\n",
      "LDLC                      0.956428\n",
      "HDLC                      0.847337\n",
      "Scr                       0.908064\n",
      "BUN                       0.847288\n",
      "FPG                       0.888639\n",
      "HbA1c                     1.016015\n",
      "Height                    0.967419\n",
      "Weight                    0.964207\n",
      "BMI                       0.771669\n",
      "Duration                  1.008777\n",
      "Community_baihe           1.000000\n",
      "Community_chonggu         1.000000\n",
      "Community_huaxin          1.000000\n",
      "Community_jinze           1.000000\n",
      "Community_liantang        1.000000\n",
      "Community_xianghuaqiao    1.000000\n",
      "Community_xujin           1.000000\n",
      "Community_yingpu          1.000000\n",
      "Community_zhaoxian        1.000000\n",
      "Community_zhujiajiao      1.000000\n",
      "dtype: float64\n",
      "\n",
      "'Gender' column in Training Data - Fold: 5\n",
      "[1 0]\n",
      "\n",
      "'Gender' column in Testing Data - Fold: 5\n",
      "[1 0]\n",
      "\n",
      "'Community' columns in Training Data - Fold: 5\n",
      "Community_baihe: [0. 1.]\n",
      "Community_chonggu: [0. 1.]\n",
      "Community_huaxin: [0. 1.]\n",
      "Community_jinze: [0. 1.]\n",
      "Community_liantang: [0. 1.]\n",
      "Community_xianghuaqiao: [0. 1.]\n",
      "Community_xujin: [0. 1.]\n",
      "Community_yingpu: [0. 1.]\n",
      "Community_zhaoxian: [1. 0.]\n",
      "Community_zhujiajiao: [0. 1.]\n",
      "\n",
      "'Community' columns in Testing Data - Fold: 5\n",
      "Community_baihe: [0. 1.]\n",
      "Community_chonggu: [0. 1.]\n",
      "Community_huaxin: [0. 1.]\n",
      "Community_jinze: [1. 0.]\n",
      "Community_liantang: [0. 1.]\n",
      "Community_xianghuaqiao: [0. 1.]\n",
      "Community_xujin: [0. 1.]\n",
      "Community_yingpu: [0. 1.]\n",
      "Community_zhaoxian: [0. 1.]\n",
      "Community_zhujiajiao: [0. 1.]\n"
     ]
    }
   ],
   "source": [
    "scaling_pipeline = Pipeline([\n",
    "    ('robust', RobustScaler()),\n",
    "    ('minmax', MinMaxScaler())\n",
    "])\n",
    "\n",
    "oversampler = ADASYN(sampling_strategy='minority', n_neighbors=5, random_state=42)\n",
    "contamination = 0.05\n",
    "\n",
    "# 1. Sanity checks\n",
    "# print(\"Features Data Shape:\", X_FOR_FOLDS.shape)\n",
    "# print(\"Labels Data Shape:\", Y_FOR_FOLDS.shape)\n",
    "if X_FOR_FOLDS.shape[0] == 0 or Y_FOR_FOLDS.shape[0] == 0:\n",
    "    raise ValueError(\"Input data is empty. Please check your data preprocessing.\")\n",
    "\n",
    "# 2. Convert NumPy arrays to pandas DataFrames if needed\n",
    "if not isinstance(X_FOR_FOLDS, pd.DataFrame):\n",
    "    # print(\"Converting X_FOR_FOLDS from NumPy array to DataFrame\")\n",
    "    column_names = ['age', 'image1', 'DR1', 'CSME1', 'HBPRP1', 'image2', 'DR2', 'CSME2', 'HBPRP2', 'WorseDR', 'DR', 'UACR', 'TCTG', 'TC', 'LDLC', 'TG', 'HDLC', 'Scr', 'Ucr', 'BUN', 'UAlb', 'FPG', 'HbA1c', 'Height', 'Weight', 'BMI', 'Duration', 'Gender_2', 'Community_chonggu', 'Community_huaxin', 'Community_jinze', 'Community_liantang', 'Community_xianghuaqiao', 'Community_xujin', 'Community_yingpu', 'Community_zhaoxian', 'Community_zhujiajiao']\n",
    "    # Create with basic column names if needed\n",
    "    X_FOR_FOLDS = pd.DataFrame(X_FOR_FOLDS, columns=column_names)\n",
    "\n",
    "    X_FOR_FOLDS.rename(columns={'age': 'Age',\n",
    "                           'ualb': 'UAlb',\n",
    "                           'ucr': 'Ucr',\n",
    "                           'uacr': 'UACR',\n",
    "                           'tc': 'TC',\n",
    "                           'tg': 'TG',\n",
    "                           'tctg': 'TCTG',\n",
    "                           'ldlc': 'LDLC',\n",
    "                           'hdlc': 'HDLC',\n",
    "                           'scr': 'Scr',\n",
    "                           'bun': 'BUN',\n",
    "                           'fpg': 'FPG',\n",
    "                           'hba1c': 'HbA1c',\n",
    "                           'height': 'Height',\n",
    "                           'weight': 'Weight',\n",
    "                           'bmi': 'BMI',\n",
    "                           'duration': 'Duration',\n",
    "                           'Gender_2': 'Gender'}, inplace=True)\n",
    "\n",
    "if not isinstance(Y_FOR_FOLDS, (pd.DataFrame, pd.Series)):\n",
    "    # print(\"Converting Y_FOR_FOLDS from NumPy array to Series\")\n",
    "    Y_FOR_FOLDS = pd.Series(Y_FOR_FOLDS)\n",
    "\n",
    "# # 3. Inspect NaNs\n",
    "# # print(\"NaNs in features:\\n\", X_FOR_FOLDS.isna().sum())\n",
    "# # print(\"NaNs in labels:\\n\", Y_FOR_FOLDS.isna().sum())\n",
    "\n",
    "# # 4. Find non-numeric columns - but first check data types\n",
    "# # print(\"Data types in X_FOR_FOLDS:\")\n",
    "# # print(X_FOR_FOLDS.dtypes)\n",
    "\n",
    "# Skip string processing if no object columns exist\n",
    "string_cols = X_FOR_FOLDS.select_dtypes(include=['object']).columns\n",
    "if len(string_cols) > 0:\n",
    "    # print(f\"Found {len(string_cols)} object columns: {list(string_cols)}\")\n",
    "    for col in string_cols:\n",
    "        # Only apply string operations if the column contains strings\n",
    "        if pd.api.types.is_string_dtype(X_FOR_FOLDS[col]):\n",
    "            X_FOR_FOLDS[col] = X_FOR_FOLDS[col].str.replace(',', '', regex=False)\n",
    "        X_FOR_FOLDS[col] = pd.to_numeric(X_FOR_FOLDS[col], errors='coerce')\n",
    "else:\n",
    "    # print(\"No string columns found - skipping string processing\")\n",
    "    pass\n",
    "\n",
    "# 5. Check if any columns are still non-numeric\n",
    "still_obj = X_FOR_FOLDS.select_dtypes(include=['object']).columns\n",
    "if len(still_obj) > 0:\n",
    "    # print(f\"Dropping nonnumeric columns: {list(still_obj)}\")\n",
    "    X_FOR_FOLDS = X_FOR_FOLDS.drop(columns=still_obj)  # Use assignment instead of inplace\n",
    "\n",
    "# 6. Fill NaNs (from original missing or failed coercion)\n",
    "X_FOR_FOLDS = X_FOR_FOLDS.fillna(0)  # Use assignment instead of inplace\n",
    "\n",
    "# 7. Now call your fold generator\n",
    "# print(\"Ready to generate folds. X shape:\", X_FOR_FOLDS.shape, \"Y shape:\", Y_FOR_FOLDS.shape)\n",
    "kFolds = FOLDS_GENERATOR(\n",
    "    X_FOR_FOLDS,\n",
    "    Y_FOR_FOLDS,\n",
    "    normalisation_method=MinMaxScaler(),\n",
    "    n_splits=5,\n",
    "    oversampler=oversampler,\n",
    "    random_state=42,\n",
    "    contamination=contamination,\n",
    "    noise=None\n",
    ")\n",
    "# print(f\"\\nNumber of folds generated: {len(kFolds)}\")\n",
    "\n",
    "for fold_idx, (X_train_scaled, X_test_scaled, Y_train_cleaned, Y_test) in enumerate(kFolds):\n",
    "    # print(f\"\\n--- Fold {fold_idx + 1} ---\")\n",
    "\n",
    "    # print(\"\\nColumn names in X_train_scaled:\", X_train_scaled.columns.tolist())\n",
    "    # print(\"Column names in X_test_scaled:\", X_test_scaled.columns.tolist())\n",
    "\n",
    "    # Check feature scaling (0 to 1) for training data\n",
    "    print(\"\\nTraining Data Feature Scaling - Fold:\", fold_idx + 1)\n",
    "    print(\"Min values:\\n\", X_train_scaled.min())\n",
    "    print(\"Max values:\\n\", X_train_scaled.max())\n",
    "\n",
    "    # Check feature scaling (0 to 1) for testing data\n",
    "    print(\"\\nTesting Data Feature Scaling - Fold:\", fold_idx + 1)\n",
    "    print(\"Min values:\\n\", X_test_scaled.min())\n",
    "    print(\"Max values:\\n\", X_test_scaled.max())\n",
    "\n",
    "    # Check if 'Gender' column is binary in training data\n",
    "    if 'Gender' in X_train_scaled.columns:\n",
    "        print(\"\\n'Gender' column in Training Data - Fold:\", fold_idx + 1)\n",
    "        print(X_train_scaled['Gender'].unique())\n",
    "\n",
    "    # Check if 'Gender' column is binary in testing data\n",
    "    if 'Gender' in X_test_scaled.columns:\n",
    "        print(\"\\n'Gender' column in Testing Data - Fold:\", fold_idx + 1)\n",
    "        print(X_test_scaled['Gender'].unique())\n",
    "\n",
    "    # Check if 'Community' columns are binary in training data\n",
    "    community_cols_train = [col for col in X_train_scaled.columns if col.startswith('Community')]\n",
    "    if community_cols_train:\n",
    "        print(\"\\n'Community' columns in Training Data - Fold:\", fold_idx + 1)\n",
    "        for col in community_cols_train:\n",
    "            print(f\"{col}: {X_train_scaled[col].unique()}\")\n",
    "\n",
    "    # Check if 'Community' columns are binary in testing data\n",
    "    community_cols_test = [col for col in X_test_scaled.columns if col.startswith('Community')]\n",
    "    if community_cols_test:\n",
    "        print(\"\\n'Community' columns in Testing Data - Fold:\", fold_idx + 1)\n",
    "        for col in community_cols_test:\n",
    "            print(f\"{col}: {X_test_scaled[col].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "14cf28b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7901, 28) (1149, 28) (7901, 1) (1149, 1)\n",
      "               Age       Gender         UAlb          Ucr         UACR  \\\n",
      "count  7901.000000  7901.000000  7901.000000  7901.000000  7901.000000   \n",
      "mean      0.594660     0.537780     0.389796     0.465419     0.356018   \n",
      "std       0.122816     0.498602     0.191754     0.373218     0.165705   \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "25%       0.524505     0.000000     0.260280     0.134245     0.245180   \n",
      "50%       0.609557     1.000000     0.361727     0.200581     0.330989   \n",
      "75%       0.676143     1.000000     0.501705     0.882666     0.445693   \n",
      "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
      "\n",
      "                TC           TG         TCTG         LDLC         HDLC  ...  \\\n",
      "count  7901.000000  7901.000000  7901.000000  7901.000000  7901.000000  ...   \n",
      "mean      0.435022     0.185039     0.434814     0.562047     0.424684  ...   \n",
      "std       0.097940     0.082591     0.155653     0.119372     0.135046  ...   \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
      "25%       0.372252     0.128549     0.330813     0.488008     0.330208  ...   \n",
      "50%       0.436436     0.170170     0.433936     0.574145     0.417008  ...   \n",
      "75%       0.500955     0.225500     0.543564     0.645381     0.511798  ...   \n",
      "max       1.000000     1.000000     1.000000     1.000000     1.000000  ...   \n",
      "\n",
      "       Community_baihe  Community_chonggu  Community_huaxin  Community_jinze  \\\n",
      "count      7901.000000        7901.000000       7901.000000      7901.000000   \n",
      "mean          0.146817           0.067713          0.124035         0.084546   \n",
      "std           0.353946           0.251269          0.329642         0.278223   \n",
      "min           0.000000           0.000000          0.000000         0.000000   \n",
      "25%           0.000000           0.000000          0.000000         0.000000   \n",
      "50%           0.000000           0.000000          0.000000         0.000000   \n",
      "75%           0.000000           0.000000          0.000000         0.000000   \n",
      "max           1.000000           1.000000          1.000000         1.000000   \n",
      "\n",
      "       Community_liantang  Community_xianghuaqiao  Community_xujin  \\\n",
      "count         7901.000000             7901.000000      7901.000000   \n",
      "mean             0.112771                0.087837         0.088976   \n",
      "std              0.316332                0.283076         0.284727   \n",
      "min              0.000000                0.000000         0.000000   \n",
      "25%              0.000000                0.000000         0.000000   \n",
      "50%              0.000000                0.000000         0.000000   \n",
      "75%              0.000000                0.000000         0.000000   \n",
      "max              1.000000                1.000000         1.000000   \n",
      "\n",
      "       Community_yingpu  Community_zhaoxian  Community_zhujiajiao  \n",
      "count       7901.000000         7901.000000           7901.000000  \n",
      "mean           0.079484            0.112264              0.095558  \n",
      "std            0.270509            0.315711              0.294002  \n",
      "min            0.000000            0.000000              0.000000  \n",
      "25%            0.000000            0.000000              0.000000  \n",
      "50%            0.000000            0.000000              0.000000  \n",
      "75%            0.000000            0.000000              0.000000  \n",
      "max            1.000000            1.000000              1.000000  \n",
      "\n",
      "[8 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "for list in kFolds:\n",
    "    print(list[0].shape, list[1].shape, list[2].shape, list[3].shape)\n",
    "    print(list[0].describe())\n",
    "    a = list[0]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "5c2bca64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution - Zeros: 4129, Ones: 464\n",
      "After Isolation Forest - Kept 3922 out of 4129 majority samples\n",
      "Before oversampling class distribution:\n",
      "DR \n",
      "0.0    3922\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "\n",
      "After oversampling class distribution:\n",
      "DR \n",
      "1.0    4001\n",
      "0.0    3922\n",
      "Name: count, dtype: int64\n",
      "Fold: 1, Train: (7923, 28), Test: (1149, 28)\n",
      "Class distribution - Zeros: 4129, Ones: 464\n",
      "After Isolation Forest - Kept 3922 out of 4129 majority samples\n",
      "Before oversampling class distribution:\n",
      "DR \n",
      "0.0    3922\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "\n",
      "After oversampling class distribution:\n",
      "DR \n",
      "1.0    3973\n",
      "0.0    3922\n",
      "Name: count, dtype: int64\n",
      "Fold: 2, Train: (7895, 28), Test: (1149, 28)\n",
      "Class distribution - Zeros: 4130, Ones: 464\n",
      "After Isolation Forest - Kept 3923 out of 4130 majority samples\n",
      "Before oversampling class distribution:\n",
      "DR \n",
      "0.0    3923\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "\n",
      "After oversampling class distribution:\n",
      "DR \n",
      "0.0    3923\n",
      "1.0    3894\n",
      "Name: count, dtype: int64\n",
      "Fold: 3, Train: (7817, 28), Test: (1148, 28)\n",
      "Class distribution - Zeros: 4130, Ones: 464\n",
      "After Isolation Forest - Kept 3923 out of 4130 majority samples\n",
      "Before oversampling class distribution:\n",
      "DR \n",
      "0.0    3923\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "\n",
      "After oversampling class distribution:\n",
      "DR \n",
      "0.0    3923\n",
      "1.0    3877\n",
      "Name: count, dtype: int64\n",
      "Fold: 4, Train: (7800, 28), Test: (1148, 28)\n",
      "Class distribution - Zeros: 4130, Ones: 464\n",
      "After Isolation Forest - Kept 3923 out of 4130 majority samples\n",
      "Before oversampling class distribution:\n",
      "DR \n",
      "0.0    3923\n",
      "1.0     464\n",
      "Name: count, dtype: int64\n",
      "\n",
      "After oversampling class distribution:\n",
      "DR \n",
      "0.0    3923\n",
      "1.0    3865\n",
      "Name: count, dtype: int64\n",
      "Fold: 5, Train: (7788, 28), Test: (1148, 28)\n"
     ]
    }
   ],
   "source": [
    "oversampler = ADASYN(sampling_strategy='minority', n_neighbors=5, random_state=42)\n",
    "contamination = 0.05\n",
    "normalisation_method = MinMaxScaler()\n",
    "kFolds2 = FOLDS_GENERATOR(X_FOR_FOLDS, Y_FOR_FOLDS, \n",
    "                         normalisation_method = normalisation_method, \n",
    "                         n_splits=5, \n",
    "                         oversampler = oversampler, random_state=42, contamination=contamination, noise = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "933d76a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7923, 28) (1149, 28) (7923, 1) (1149, 1)\n",
      "               Age       Gender         UAlb          Ucr         UACR  \\\n",
      "count  7923.000000  7923.000000  7923.000000  7923.000000  7923.000000   \n",
      "mean      0.596533     0.545122     0.413025     0.493828     0.377046   \n",
      "std       0.182528     0.497991     0.235354     0.373827     0.217835   \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "25%       0.492103     0.000000     0.244837     0.134245     0.226818   \n",
      "50%       0.606012     1.000000     0.392682     0.408707     0.361061   \n",
      "75%       0.705448     1.000000     0.571080     0.883003     0.515149   \n",
      "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
      "\n",
      "                TC           TG         TCTG         LDLC         HDLC  ...  \\\n",
      "count  7923.000000  7923.000000  7923.000000  7923.000000  7923.000000  ...   \n",
      "mean      0.437548     0.201240     0.432193     0.558524     0.424255  ...   \n",
      "std       0.171568     0.145735     0.205710     0.184080     0.191496  ...   \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
      "25%       0.340936     0.111504     0.300073     0.449507     0.302431  ...   \n",
      "50%       0.439069     0.173483     0.435450     0.570589     0.418382  ...   \n",
      "75%       0.528946     0.270590     0.567003     0.665726     0.541685  ...   \n",
      "max       1.000000     1.000000     1.000000     1.000000     1.000000  ...   \n",
      "\n",
      "       Community_baihe  Community_chonggu  Community_huaxin  Community_jinze  \\\n",
      "count      7923.000000        7923.000000       7923.000000      7923.000000   \n",
      "mean          0.095797           0.079768          0.122302         0.102739   \n",
      "std           0.294331           0.270950          0.327655         0.303637   \n",
      "min           0.000000           0.000000          0.000000         0.000000   \n",
      "25%           0.000000           0.000000          0.000000         0.000000   \n",
      "50%           0.000000           0.000000          0.000000         0.000000   \n",
      "75%           0.000000           0.000000          0.000000         0.000000   \n",
      "max           1.000000           1.000000          1.000000         1.000000   \n",
      "\n",
      "       Community_liantang  Community_xianghuaqiao  Community_xujin  \\\n",
      "count         7923.000000             7923.000000      7923.000000   \n",
      "mean             0.117506                0.072447         0.103496   \n",
      "std              0.322043                0.259243         0.304625   \n",
      "min              0.000000                0.000000         0.000000   \n",
      "25%              0.000000                0.000000         0.000000   \n",
      "50%              0.000000                0.000000         0.000000   \n",
      "75%              0.000000                0.000000         0.000000   \n",
      "max              1.000000                1.000000         1.000000   \n",
      "\n",
      "       Community_yingpu  Community_zhaoxian  Community_zhujiajiao  \n",
      "count       7923.000000         7923.000000           7923.000000  \n",
      "mean           0.104127            0.100341              0.101477  \n",
      "std            0.305445            0.300473              0.301978  \n",
      "min            0.000000            0.000000              0.000000  \n",
      "25%            0.000000            0.000000              0.000000  \n",
      "50%            0.000000            0.000000              0.000000  \n",
      "75%            0.000000            0.000000              0.000000  \n",
      "max            1.000000            1.000000              1.000000  \n",
      "\n",
      "[8 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "for list in kFolds2:\n",
    "    print(list[0].shape, list[1].shape, list[2].shape, list[3].shape)\n",
    "    print(list[0].describe())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4504db28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
