{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasetSplitter import datasetSplitterStratKFold, datasetFoldMaker\n",
    "import pandas as pd\n",
    "\n",
    "datasett = pd.read_csv(\"data\\processed_data.csv\")\n",
    "\n",
    "train_x, test_x, train_y, test_y = datasetSplitterStratKFold(dataFrame=datasett)\n",
    "\n",
    "kFolds = datasetFoldMaker(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasicModel(\n",
      "  (block): Sequential(\n",
      "    (0): Linear(in_features=28, out_features=512, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): LeakyReLU(negative_slope=0.01)\n",
      "    (4): Linear(in_features=256, out_features=32, bias=True)\n",
      "    (5): LeakyReLU(negative_slope=0.01)\n",
      "    (6): Linear(in_features=32, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "Parameter containing:\n",
      "tensor([[ 0.0462,  0.0186,  0.0191,  ...,  0.0204, -0.1267,  0.0306],\n",
      "        [-0.0874, -0.0839,  0.0043,  ...,  0.0715, -0.1137, -0.0141],\n",
      "        [-0.0037,  0.0596, -0.1428,  ...,  0.0464, -0.0860,  0.1586],\n",
      "        ...,\n",
      "        [-0.1269,  0.0466, -0.0769,  ..., -0.0946,  0.1886,  0.1820],\n",
      "        [-0.0163,  0.0278, -0.1288,  ..., -0.0549, -0.1546, -0.1839],\n",
      "        [ 0.1009, -0.0454, -0.0144,  ...,  0.1664, -0.0035,  0.0378]],\n",
      "       requires_grad=True) Parameter containing:\n",
      "tensor([-0.0666,  0.0077,  0.1085, -0.0874, -0.0532,  0.0539,  0.0925, -0.0980,\n",
      "         0.1683,  0.0759,  0.0926, -0.0670,  0.0089,  0.0457,  0.1287, -0.0358,\n",
      "        -0.1196,  0.0391, -0.1667,  0.0941, -0.1606, -0.1061,  0.1408, -0.1360,\n",
      "        -0.1858, -0.1700, -0.1131, -0.1079,  0.0335,  0.1143, -0.1645, -0.1292,\n",
      "        -0.1759,  0.0890,  0.1753, -0.0408, -0.0777,  0.0643, -0.1115,  0.0083,\n",
      "         0.1390,  0.1123, -0.0339,  0.1701, -0.0550,  0.0207, -0.1088,  0.1177,\n",
      "        -0.0985,  0.1250,  0.0602, -0.0826, -0.1674, -0.0456,  0.1573, -0.0557,\n",
      "         0.1618, -0.0087, -0.0885, -0.1360,  0.0453, -0.1384, -0.0228,  0.1311,\n",
      "        -0.0625,  0.1719,  0.0338, -0.0116, -0.0521, -0.1502,  0.0178, -0.0995,\n",
      "        -0.0869,  0.1450, -0.0514,  0.0379, -0.1023,  0.1750,  0.0134,  0.1279,\n",
      "        -0.1443, -0.0964,  0.0782, -0.1461, -0.1494,  0.1629, -0.0705,  0.0611,\n",
      "        -0.0179, -0.1160,  0.0260, -0.0939,  0.1405,  0.0378, -0.1018, -0.0122,\n",
      "         0.0571, -0.1461, -0.0883,  0.0147,  0.0556,  0.0632, -0.0299, -0.1548,\n",
      "        -0.0143,  0.1294, -0.1570,  0.1576,  0.1813, -0.1310,  0.0469,  0.1074,\n",
      "        -0.1168, -0.0312,  0.0990, -0.0220,  0.0098,  0.0905,  0.1060, -0.1741,\n",
      "         0.1313, -0.1005,  0.0794, -0.0119,  0.1255,  0.1805, -0.0032,  0.0222,\n",
      "        -0.0717, -0.1839,  0.1666,  0.0375,  0.0829,  0.1175, -0.0256,  0.0688,\n",
      "        -0.1302,  0.1088, -0.0094,  0.0150,  0.1366,  0.0071, -0.0670,  0.0531,\n",
      "         0.0990,  0.1393, -0.0379,  0.0689, -0.1614,  0.0064, -0.1424, -0.0466,\n",
      "        -0.0774, -0.1164, -0.0954,  0.1503,  0.0034, -0.1369,  0.1146, -0.0915,\n",
      "         0.1258, -0.1428,  0.0326, -0.1125, -0.0292, -0.0076, -0.0779,  0.1190,\n",
      "        -0.1645,  0.1723,  0.0826,  0.1383, -0.1841,  0.0663, -0.1550, -0.0984,\n",
      "        -0.1508, -0.1832, -0.0642, -0.0480, -0.1587,  0.0982, -0.1554,  0.0688,\n",
      "        -0.1554, -0.0868,  0.1662,  0.0008,  0.1622, -0.1514,  0.1370, -0.0967,\n",
      "         0.0360,  0.0984, -0.0929,  0.1352,  0.0818, -0.1651, -0.0776, -0.0911,\n",
      "         0.1490,  0.1770,  0.0924, -0.0580, -0.0526, -0.0251, -0.0017, -0.1870,\n",
      "         0.0883, -0.1260, -0.0443,  0.0138,  0.0179,  0.1402, -0.1106,  0.0476,\n",
      "        -0.0383, -0.1381,  0.0978, -0.0884, -0.0771,  0.0393, -0.0632, -0.0218,\n",
      "         0.0695,  0.0974, -0.1140, -0.0102,  0.0070, -0.1525,  0.1167, -0.0914,\n",
      "         0.1737, -0.0288, -0.0431,  0.0811, -0.0987, -0.1221,  0.1608, -0.0491,\n",
      "         0.1367, -0.1418, -0.0720, -0.0975,  0.0751, -0.1216, -0.0893, -0.1075,\n",
      "        -0.1291, -0.1636, -0.1328, -0.0546, -0.0414, -0.0542, -0.0795,  0.1304,\n",
      "         0.0002, -0.1668, -0.0251,  0.1185, -0.1187,  0.1784, -0.0562, -0.0128,\n",
      "         0.1618, -0.0581, -0.0907,  0.1866, -0.0457, -0.1505,  0.0363, -0.1607,\n",
      "         0.1241,  0.0227, -0.0801, -0.0958,  0.1422,  0.1367, -0.1106, -0.1790,\n",
      "        -0.1003,  0.0478, -0.1291, -0.0212,  0.1394, -0.0756, -0.0606,  0.1639,\n",
      "        -0.0866, -0.0787, -0.0343, -0.1657, -0.0132,  0.1206, -0.0661,  0.0372,\n",
      "        -0.1803,  0.0128,  0.1552, -0.1315, -0.1193, -0.1390, -0.1012,  0.0369,\n",
      "         0.1578, -0.0650, -0.1195, -0.1687,  0.1152, -0.1419,  0.0040,  0.0657,\n",
      "         0.0095, -0.1622,  0.1636,  0.0860, -0.0075, -0.0293,  0.0910,  0.0019,\n",
      "        -0.0991,  0.0610, -0.0651, -0.1070, -0.0486, -0.1167,  0.1041,  0.0616,\n",
      "         0.0017, -0.0744, -0.0505,  0.1400,  0.0150,  0.1522,  0.0911, -0.1119,\n",
      "         0.1695,  0.0727,  0.0694, -0.0569, -0.1342, -0.0924, -0.1833, -0.0500,\n",
      "        -0.1029,  0.0674, -0.1284,  0.1470, -0.1335, -0.0012,  0.0998, -0.1005,\n",
      "        -0.0618,  0.0156, -0.1728,  0.0288,  0.1301,  0.1704,  0.1523, -0.0710,\n",
      "         0.0585, -0.0105,  0.1575,  0.0285,  0.1070, -0.0638,  0.1480,  0.1562,\n",
      "        -0.0766, -0.1686,  0.0788,  0.0795, -0.0156, -0.0376, -0.0457, -0.1541,\n",
      "        -0.1502, -0.1042, -0.1780,  0.0956,  0.0841,  0.1012,  0.1492,  0.1410,\n",
      "         0.1045, -0.0670, -0.0589, -0.0363,  0.1885,  0.1052,  0.1170,  0.0592,\n",
      "         0.1309, -0.1045, -0.0173, -0.1139,  0.1025,  0.1533,  0.1813,  0.0109,\n",
      "         0.0813,  0.1791, -0.0824,  0.0674, -0.1506, -0.1656, -0.1798, -0.0263,\n",
      "        -0.0200,  0.1862,  0.1678,  0.1438,  0.0189, -0.1207, -0.1888,  0.1797,\n",
      "         0.0987,  0.0696,  0.1118, -0.1116, -0.0517, -0.1847, -0.1554, -0.1571,\n",
      "        -0.1867,  0.1659,  0.0364,  0.1872,  0.0550,  0.0082, -0.1136,  0.0736,\n",
      "         0.0361,  0.1034,  0.1098, -0.1422, -0.0150, -0.0544, -0.0551, -0.1522,\n",
      "        -0.1020, -0.1794, -0.0656, -0.0945, -0.1407,  0.0482,  0.0667,  0.1468,\n",
      "        -0.0228, -0.0559,  0.0333,  0.1312,  0.1396,  0.1482,  0.1579,  0.1194,\n",
      "         0.1668, -0.0101,  0.0664, -0.0795, -0.0453,  0.1802,  0.1752,  0.0374,\n",
      "        -0.0085,  0.0361, -0.1824, -0.0782,  0.0936,  0.0163, -0.0397, -0.1332,\n",
      "        -0.0372,  0.0119, -0.0890,  0.0742, -0.0472,  0.1593,  0.0691,  0.0499,\n",
      "        -0.1163,  0.1415,  0.1736, -0.1501, -0.1624,  0.0184,  0.1411, -0.0470,\n",
      "        -0.1789, -0.0343,  0.0121, -0.0588, -0.1858, -0.0731, -0.0180, -0.0498,\n",
      "         0.0284,  0.0836,  0.1391,  0.0976,  0.0692,  0.0129, -0.0769,  0.1603,\n",
      "         0.1759,  0.0195,  0.0271, -0.1748, -0.1223,  0.1874, -0.1100, -0.1846],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-3.9147e-02,  1.7989e-02,  1.2973e-02,  ...,  2.3863e-02,\n",
      "          2.0902e-02,  8.5732e-03],\n",
      "        [ 5.4478e-03,  4.1825e-02,  4.3236e-02,  ..., -2.5887e-02,\n",
      "         -3.6006e-02, -2.8278e-02],\n",
      "        [-4.2027e-02, -4.2033e-02,  3.0647e-02,  ..., -1.9724e-02,\n",
      "          3.8556e-02,  8.3651e-05],\n",
      "        ...,\n",
      "        [-3.9609e-02,  2.5312e-03,  1.2329e-02,  ..., -3.5588e-02,\n",
      "         -3.6365e-02, -4.0101e-02],\n",
      "        [-3.1118e-02, -1.2601e-03, -4.0711e-02,  ..., -8.2837e-04,\n",
      "         -2.1176e-02,  1.7770e-04],\n",
      "        [ 3.4798e-02, -1.7697e-02,  3.1849e-02,  ..., -3.8908e-02,\n",
      "          2.2561e-02,  3.0920e-02]], requires_grad=True) Parameter containing:\n",
      "tensor([ 0.0180,  0.0284,  0.0365, -0.0157, -0.0391,  0.0046, -0.0338,  0.0194,\n",
      "        -0.0183, -0.0047, -0.0142, -0.0249, -0.0075, -0.0099,  0.0157,  0.0069,\n",
      "        -0.0425, -0.0179,  0.0134, -0.0151,  0.0434,  0.0052,  0.0023, -0.0155,\n",
      "        -0.0102, -0.0432, -0.0158, -0.0196, -0.0072, -0.0087,  0.0019,  0.0248,\n",
      "         0.0368, -0.0144, -0.0399, -0.0132,  0.0101,  0.0065, -0.0223, -0.0224,\n",
      "        -0.0202,  0.0186, -0.0256, -0.0373, -0.0144, -0.0153, -0.0266, -0.0280,\n",
      "        -0.0292,  0.0211, -0.0234,  0.0094,  0.0336, -0.0412,  0.0354,  0.0387,\n",
      "         0.0111, -0.0003, -0.0237,  0.0158,  0.0347,  0.0240, -0.0164, -0.0236,\n",
      "         0.0283,  0.0168,  0.0420, -0.0158,  0.0189, -0.0208, -0.0369,  0.0352,\n",
      "         0.0411, -0.0314, -0.0382,  0.0101, -0.0258, -0.0203, -0.0354,  0.0083,\n",
      "        -0.0417, -0.0404,  0.0093, -0.0234, -0.0013,  0.0071,  0.0261, -0.0126,\n",
      "        -0.0072, -0.0362,  0.0040, -0.0184,  0.0130,  0.0129, -0.0256, -0.0225,\n",
      "        -0.0302, -0.0217, -0.0136,  0.0272, -0.0273,  0.0262, -0.0358,  0.0260,\n",
      "        -0.0438,  0.0297, -0.0225,  0.0147, -0.0222, -0.0151, -0.0002, -0.0382,\n",
      "         0.0084, -0.0357,  0.0355, -0.0411, -0.0010,  0.0154, -0.0114, -0.0399,\n",
      "         0.0366,  0.0251, -0.0248,  0.0182,  0.0169,  0.0284, -0.0102,  0.0130,\n",
      "         0.0056,  0.0196,  0.0048,  0.0386, -0.0298, -0.0233,  0.0389, -0.0406,\n",
      "        -0.0143, -0.0141,  0.0343, -0.0225, -0.0136, -0.0395,  0.0052,  0.0055,\n",
      "         0.0097,  0.0063,  0.0023,  0.0283, -0.0202, -0.0129, -0.0051, -0.0209,\n",
      "        -0.0337, -0.0203, -0.0322, -0.0102,  0.0133, -0.0257, -0.0356,  0.0035,\n",
      "         0.0344,  0.0160,  0.0292, -0.0043,  0.0124, -0.0038, -0.0435,  0.0336,\n",
      "        -0.0360, -0.0202,  0.0128,  0.0118,  0.0145, -0.0392,  0.0003, -0.0173,\n",
      "        -0.0403, -0.0173,  0.0260,  0.0286,  0.0246, -0.0245, -0.0440,  0.0064,\n",
      "        -0.0317,  0.0111,  0.0032, -0.0318,  0.0309,  0.0292, -0.0351,  0.0042,\n",
      "         0.0344, -0.0367, -0.0117, -0.0200, -0.0035, -0.0404,  0.0095, -0.0123,\n",
      "        -0.0363,  0.0108,  0.0343,  0.0269,  0.0121, -0.0388, -0.0306, -0.0370,\n",
      "        -0.0092,  0.0091, -0.0031,  0.0306,  0.0205, -0.0265,  0.0247, -0.0299,\n",
      "        -0.0322,  0.0105, -0.0342, -0.0126, -0.0117,  0.0425, -0.0290, -0.0027,\n",
      "         0.0216,  0.0258,  0.0322, -0.0393, -0.0225, -0.0358,  0.0248,  0.0254,\n",
      "         0.0307,  0.0024, -0.0254,  0.0203,  0.0440,  0.0063, -0.0112, -0.0089,\n",
      "        -0.0138, -0.0420, -0.0318, -0.0269,  0.0055,  0.0202,  0.0381, -0.0076,\n",
      "         0.0143, -0.0235,  0.0234,  0.0269,  0.0062, -0.0265, -0.0030,  0.0214],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0144,  0.0289, -0.0106,  ..., -0.0107,  0.0425,  0.0172],\n",
      "        [ 0.0555,  0.0365,  0.0190,  ...,  0.0047, -0.0473,  0.0349],\n",
      "        [ 0.0599, -0.0159, -0.0157,  ...,  0.0237,  0.0264,  0.0219],\n",
      "        ...,\n",
      "        [ 0.0580, -0.0459, -0.0552,  ..., -0.0501,  0.0105, -0.0218],\n",
      "        [ 0.0491,  0.0625,  0.0020,  ...,  0.0253,  0.0550, -0.0053],\n",
      "        [-0.0450, -0.0474, -0.0590,  ..., -0.0024,  0.0105,  0.0347]],\n",
      "       requires_grad=True) Parameter containing:\n",
      "tensor([-0.0353,  0.0436, -0.0572, -0.0561, -0.0006, -0.0483, -0.0029,  0.0580,\n",
      "        -0.0228, -0.0280, -0.0438, -0.0171,  0.0213,  0.0088,  0.0038,  0.0238,\n",
      "         0.0539,  0.0480,  0.0190, -0.0489, -0.0371,  0.0193, -0.0226,  0.0381,\n",
      "         0.0565,  0.0429,  0.0285,  0.0260, -0.0308, -0.0613,  0.0372, -0.0220],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.1163, -0.1197,  0.0123, -0.1646,  0.0468,  0.0852,  0.1246,  0.0618,\n",
      "          0.0843,  0.1289, -0.1149, -0.0701, -0.0605, -0.0663,  0.0328,  0.0771,\n",
      "          0.0798, -0.1472,  0.1581, -0.1348, -0.0771, -0.1383,  0.0965, -0.0298,\n",
      "         -0.0511, -0.1165, -0.1752, -0.1549,  0.1542, -0.0010,  0.0629,  0.0706]],\n",
      "       requires_grad=True) Parameter containing:\n",
      "tensor([0.0308], requires_grad=True)\n",
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "# import torch.nn.init as init\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "class BasicModel(nn.Module):\n",
    "    def __init__(self,inFeatures,hiddens,classes,activations:list):\n",
    "        super().__init__()\n",
    "        if isinstance(activations,list):\n",
    "            assert len(activations) <= len(hiddens)\n",
    "        linearList = []\n",
    "        start = inFeatures\n",
    "        for size in hiddens:\n",
    "            linearList.append(nn.Linear(start,size))\n",
    "            start = size\n",
    "\n",
    "        layerList = []\n",
    "        for idx in range(len(linearList)):\n",
    "            layerList.append(linearList[idx])\n",
    "            if isinstance(activations,list):\n",
    "                if idx < len(activations):\n",
    "                    layerList.append(activations[idx])\n",
    "                else:\n",
    "                    layerList.append(activations[-1])\n",
    "            else:\n",
    "                layerList.append(activations)\n",
    "        layerList.append(nn.Linear(size,classes))\n",
    "        # layerList.append(nn.Sigmoid())\n",
    "        self.block = nn.Sequential(\n",
    "            *layerList,\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "        \n",
    "model = BasicModel(28,[512,256,32],1,\n",
    "                   [nn.Tanh(),nn.LeakyReLU()])\n",
    "print(model)\n",
    "\n",
    "for layer in model.modules():\n",
    "    if isinstance(layer, (nn.Linear, nn.Conv2d)):  # Check if the layer has weights\n",
    "#         init.xavier_normal_(layer.weight,gain=0.1)  # Initialize weights using Xavier Normal\n",
    "#         if layer.bias is not None:\n",
    "#             init.normal_(layer.bias, mean=0, std=0.05)  \n",
    "        print(layer.weight,layer.bias)\n",
    "\n",
    "device = \"cpu\" #torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([2.0]))\n",
    "optimiser = optim.Adagrad(model.parameters(),lr=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1\n",
      "Labels tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.]])\n",
      "Outputs tensor([[-0.1264],\n",
      "        [-0.1141],\n",
      "        [-0.1453],\n",
      "        [-0.1242],\n",
      "        [-0.1171],\n",
      "        [-0.1363],\n",
      "        [-0.1448],\n",
      "        [-0.1286],\n",
      "        [-0.1503],\n",
      "        [-0.1301],\n",
      "        [-0.1347],\n",
      "        [-0.1181],\n",
      "        [-0.1489],\n",
      "        [-0.1499],\n",
      "        [-0.1289],\n",
      "        [-0.1253],\n",
      "        [-0.1474],\n",
      "        [-0.1377],\n",
      "        [-0.1410],\n",
      "        [-0.1293],\n",
      "        [-0.1339],\n",
      "        [-0.1410],\n",
      "        [-0.1238],\n",
      "        [-0.1368],\n",
      "        [-0.1399],\n",
      "        [-0.1384],\n",
      "        [-0.1377],\n",
      "        [-0.1439],\n",
      "        [-0.1296],\n",
      "        [-0.1219],\n",
      "        [-0.1260],\n",
      "        [-0.1279],\n",
      "        [-0.1463],\n",
      "        [-0.1521],\n",
      "        [-0.1502],\n",
      "        [-0.1411],\n",
      "        [-0.1215],\n",
      "        [-0.1411],\n",
      "        [-0.1300],\n",
      "        [-0.1201],\n",
      "        [-0.1489],\n",
      "        [-0.1277],\n",
      "        [-0.1408],\n",
      "        [-0.1274],\n",
      "        [-0.1103],\n",
      "        [-0.1104],\n",
      "        [-0.1266],\n",
      "        [-0.1340],\n",
      "        [-0.1244],\n",
      "        [-0.1562],\n",
      "        [-0.1466],\n",
      "        [-0.1353],\n",
      "        [-0.1441],\n",
      "        [-0.1262],\n",
      "        [-0.1212],\n",
      "        [-0.1448],\n",
      "        [-0.1499],\n",
      "        [-0.1321],\n",
      "        [-0.1342],\n",
      "        [-0.1268],\n",
      "        [-0.1352],\n",
      "        [-0.1125],\n",
      "        [-0.1352],\n",
      "        [-0.1331]], grad_fn=<AddmmBackward0>)\n",
      "Preds tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]])\n",
      " Epoch: 1___ Batch: 72    Loss: 0.0079     AccuracyScore: 0.88  RecallScore: 0.00    f1Score: 0.00       \n",
      " Epoch: 1    Loss: 0.5022     Train Accuracy: 89.90%                                                          \n",
      " Epoch: 2___ Batch: 61    Loss: 0.0072     AccuracyScore: 0.94  RecallScore: 0.00    f1Score: 0.00       \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ivanw\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 2___ Batch: 72    Loss: 0.0073     AccuracyScore: 0.96  RecallScore: 0.00    f1Score: 0.00       \n",
      " Epoch: 2    Loss: 0.4668     Train Accuracy: 89.77%                                                          \n",
      " Epoch: 3___ Batch: 72    Loss: 0.0071     AccuracyScore: 0.82  RecallScore: 0.00    f1Score: 0.00       \n",
      " Epoch: 3    Loss: 0.4545     Train Accuracy: 88.74%                                                          \n",
      " Epoch: 4___ Batch: 72    Loss: 0.0070     AccuracyScore: 0.90  RecallScore: 0.00    f1Score: 0.00       \n",
      " Epoch: 4    Loss: 0.4481     Train Accuracy: 89.20%                                                          \n",
      " Epoch: 5___ Batch: 72    Loss: 0.0070     AccuracyScore: 1.00  RecallScore: 1.00    f1Score: 0.00       \n",
      " Epoch: 5    Loss: 0.4466     Train Accuracy: 88.77%                                                          \n",
      " Epoch: 6___ Batch: 33    Loss: 0.0069     AccuracyScore: 0.92  RecallScore: 0.17    f1Score: 0.29       \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ivanw\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 6___ Batch: 72    Loss: 0.0070     AccuracyScore: 0.90  RecallScore: 0.00    f1Score: 0.00       \n",
      " Epoch: 6    Loss: 0.4468     Train Accuracy: 89.33%                                                          \n",
      " Epoch: 7___ Batch: 72    Loss: 0.0070     AccuracyScore: 0.92  RecallScore: 0.00    f1Score: 0.00       \n",
      " Epoch: 7    Loss: 0.4434     Train Accuracy: 89.20%                                                          \n",
      " Epoch: 8___ Batch: 72    Loss: 0.0070     AccuracyScore: 0.90  RecallScore: 0.50    f1Score: 0.55       \n",
      " Epoch: 8    Loss: 0.4436     Train Accuracy: 89.16%                                                          \n",
      " Epoch: 9___ Batch: 72    Loss: 0.0069     AccuracyScore: 0.90  RecallScore: 0.00    f1Score: 0.00       \n",
      " Epoch: 9    Loss: 0.4419     Train Accuracy: 89.22%                                                          \n",
      " Epoch: 10__ Batch: 72    Loss: 0.0069     AccuracyScore: 0.88  RecallScore: 0.29    f1Score: 0.40       \n",
      " Epoch: 10   Loss: 0.4414     Train Accuracy: 89.22%                                                          \n",
      " Epoch: 11__ Batch: 72    Loss: 0.0069     AccuracyScore: 0.96  RecallScore: 0.33    f1Score: 0.50       \n",
      " Epoch: 11   Loss: 0.4400     Train Accuracy: 89.09%                                                          \n",
      " Epoch: 12__ Batch: 72    Loss: 0.0068     AccuracyScore: 0.98  RecallScore: 0.00    f1Score: 0.00       \n",
      " Epoch: 12   Loss: 0.4367     Train Accuracy: 89.01%                                                          \n",
      " Epoch: 13__ Batch: 72    Loss: 0.0069     AccuracyScore: 0.90  RecallScore: 0.25    f1Score: 0.29       \n",
      " Epoch: 13   Loss: 0.4377     Train Accuracy: 89.09%                                                          \n",
      " Epoch: 14__ Batch: 72    Loss: 0.0068     AccuracyScore: 0.92  RecallScore: 0.33    f1Score: 0.33       \n",
      " Epoch: 14   Loss: 0.4357     Train Accuracy: 89.24%                                                          \n",
      " Epoch: 15__ Batch: 72    Loss: 0.0068     AccuracyScore: 0.82  RecallScore: 0.00    f1Score: 0.00       \n",
      " Epoch: 15   Loss: 0.4366     Train Accuracy: 89.01%                                                          \n",
      " Epoch: 16__ Batch: 72    Loss: 0.0068     AccuracyScore: 0.90  RecallScore: 0.33    f1Score: 0.29       \n",
      " Epoch: 16   Loss: 0.4340     Train Accuracy: 89.24%                                                          \n",
      " Epoch: 17__ Batch: 72    Loss: 0.0068     AccuracyScore: 0.94  RecallScore: 0.00    f1Score: 0.00       \n",
      " Epoch: 17   Loss: 0.4337     Train Accuracy: 89.16%                                                          \n",
      " Epoch: 18__ Batch: 72    Loss: 0.0068     AccuracyScore: 0.92  RecallScore: 0.33    f1Score: 0.33       \n",
      " Epoch: 18   Loss: 0.4320     Train Accuracy: 89.24%                                                          \n",
      " Epoch: 19__ Batch: 72    Loss: 0.0068     AccuracyScore: 0.90  RecallScore: 0.17    f1Score: 0.29       \n",
      " Epoch: 19   Loss: 0.4323     Train Accuracy: 89.14%                                                          \n",
      " Epoch: 20__ Batch: 72    Loss: 0.0068     AccuracyScore: 0.90  RecallScore: 0.00    f1Score: 0.00       \n",
      " Epoch: 20   Loss: 0.4310     Train Accuracy: 89.24%                                                          \n",
      " Epoch: 21__ Batch: 72    Loss: 0.0067     AccuracyScore: 0.92  RecallScore: 0.33    f1Score: 0.50       \n",
      " Epoch: 21   Loss: 0.4304     Train Accuracy: 89.18%                                                          \n",
      " Epoch: 22__ Batch: 72    Loss: 0.0067     AccuracyScore: 0.82  RecallScore: 0.00    f1Score: 0.00       \n",
      " Epoch: 22   Loss: 0.4299     Train Accuracy: 89.27%                                                          \n",
      " Epoch: 23__ Batch: 72    Loss: 0.0067     AccuracyScore: 0.92  RecallScore: 0.00    f1Score: 0.00       \n",
      " Epoch: 23   Loss: 0.4285     Train Accuracy: 89.16%                                                          \n",
      " Epoch: 24__ Batch: 72    Loss: 0.0067     AccuracyScore: 0.84  RecallScore: 0.12    f1Score: 0.20       \n",
      " Epoch: 24   Loss: 0.4271     Train Accuracy: 89.42%                                                          \n",
      " Epoch: 25__ Batch: 72    Loss: 0.0067     AccuracyScore: 0.84  RecallScore: 0.00    f1Score: 0.00       \n",
      " Epoch: 25   Loss: 0.4276     Train Accuracy: 89.42%                                                          \n",
      " Epoch: 26__ Batch: 72    Loss: 0.0067     AccuracyScore: 0.84  RecallScore: 0.38    f1Score: 0.43       \n",
      " Epoch: 26   Loss: 0.4253     Train Accuracy: 89.24%                                                          \n",
      " Epoch: 27__ Batch: 72    Loss: 0.0067     AccuracyScore: 0.84  RecallScore: 0.25    f1Score: 0.33       \n",
      " Epoch: 27   Loss: 0.4251     Train Accuracy: 89.33%                                                          \n",
      " Epoch: 28__ Batch: 72    Loss: 0.0066     AccuracyScore: 0.90  RecallScore: 0.33    f1Score: 0.44       \n",
      " Epoch: 28   Loss: 0.4240     Train Accuracy: 89.42%                                                          \n",
      " Epoch: 29__ Batch: 72    Loss: 0.0066     AccuracyScore: 0.78  RecallScore: 0.18    f1Score: 0.27       \n",
      " Epoch: 29   Loss: 0.4241     Train Accuracy: 89.66%                                                          \n",
      " Epoch: 30__ Batch: 72    Loss: 0.0066     AccuracyScore: 0.80  RecallScore: 0.20    f1Score: 0.29       \n",
      " Epoch: 30   Loss: 0.4234     Train Accuracy: 89.55%                                                          \n",
      " Epoch: 31__ Batch: 72    Loss: 0.0066     AccuracyScore: 0.84  RecallScore: 0.25    f1Score: 0.33       \n",
      " Epoch: 31   Loss: 0.4217     Train Accuracy: 89.38%                                                          \n",
      " Epoch: 32__ Batch: 72    Loss: 0.0066     AccuracyScore: 0.94  RecallScore: 0.40    f1Score: 0.57       \n",
      " Epoch: 32   Loss: 0.4206     Train Accuracy: 89.59%                                                          \n",
      " Epoch: 33__ Batch: 72    Loss: 0.0066     AccuracyScore: 0.92  RecallScore: 0.50    f1Score: 0.50       \n",
      " Epoch: 33   Loss: 0.4185     Train Accuracy: 89.61%                                                          \n",
      " Epoch: 34__ Batch: 72    Loss: 0.0065     AccuracyScore: 0.94  RecallScore: 0.40    f1Score: 0.57       \n",
      " Epoch: 34   Loss: 0.4163     Train Accuracy: 89.79%                                                          \n",
      " Epoch: 35__ Batch: 72    Loss: 0.0065     AccuracyScore: 0.96  RecallScore: 0.75    f1Score: 0.75       \n",
      " Epoch: 35   Loss: 0.4165     Train Accuracy: 89.59%                                                          \n",
      " Epoch: 36__ Batch: 72    Loss: 0.0065     AccuracyScore: 0.90  RecallScore: 0.29    f1Score: 0.44       \n",
      " Epoch: 36   Loss: 0.4162     Train Accuracy: 89.64%                                                          \n",
      " Epoch: 37__ Batch: 72    Loss: 0.0065     AccuracyScore: 0.94  RecallScore: 0.25    f1Score: 0.40       \n",
      " Epoch: 37   Loss: 0.4147     Train Accuracy: 89.96%                                                          \n",
      " Epoch: 38__ Batch: 72    Loss: 0.0065     AccuracyScore: 0.94  RecallScore: 0.50    f1Score: 0.57       \n",
      " Epoch: 38   Loss: 0.4133     Train Accuracy: 89.70%                                                          \n",
      " Epoch: 39__ Batch: 72    Loss: 0.0065     AccuracyScore: 0.90  RecallScore: 0.20    f1Score: 0.29       \n",
      " Epoch: 39   Loss: 0.4134     Train Accuracy: 89.53%                                                          \n",
      " Epoch: 40__ Batch: 72    Loss: 0.0064     AccuracyScore: 0.84  RecallScore: 0.29    f1Score: 0.33       \n",
      " Epoch: 40   Loss: 0.4110     Train Accuracy: 90.05%                                                          \n",
      " Epoch: 41__ Batch: 72    Loss: 0.0064     AccuracyScore: 0.86  RecallScore: 0.14    f1Score: 0.22       \n",
      " Epoch: 41   Loss: 0.4108     Train Accuracy: 89.88%                                                          \n",
      " Epoch: 42__ Batch: 12    Loss: 0.0059     AccuracyScore: 0.91  RecallScore: 0.17    f1Score: 0.25       \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ivanw\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 42__ Batch: 72    Loss: 0.0064     AccuracyScore: 0.84  RecallScore: 0.00    f1Score: 0.00       \n",
      " Epoch: 42   Loss: 0.4072     Train Accuracy: 89.81%                                                          \n",
      " Epoch: 43__ Batch: 72    Loss: 0.0064     AccuracyScore: 0.92  RecallScore: 0.40    f1Score: 0.50       \n",
      " Epoch: 43   Loss: 0.4074     Train Accuracy: 89.64%                                                          \n",
      " Epoch: 44__ Batch: 72    Loss: 0.0064     AccuracyScore: 0.84  RecallScore: 0.00    f1Score: 0.00       \n",
      " Epoch: 44   Loss: 0.4060     Train Accuracy: 89.88%                                                          \n",
      " Epoch: 45__ Batch: 72    Loss: 0.0063     AccuracyScore: 0.90  RecallScore: 0.33    f1Score: 0.44       \n",
      " Epoch: 45   Loss: 0.4050     Train Accuracy: 90.03%                                                          \n",
      " Epoch: 46__ Batch: 72    Loss: 0.0063     AccuracyScore: 0.84  RecallScore: 0.45    f1Score: 0.56       \n",
      " Epoch: 46   Loss: 0.4035     Train Accuracy: 89.96%                                                          \n",
      " Epoch: 47__ Batch: 72    Loss: 0.0063     AccuracyScore: 0.86  RecallScore: 0.29    f1Score: 0.36       \n",
      " Epoch: 47   Loss: 0.4026     Train Accuracy: 89.88%                                                          \n",
      " Epoch: 48__ Batch: 72    Loss: 0.0063     AccuracyScore: 0.94  RecallScore: 0.33    f1Score: 0.40       \n",
      " Epoch: 48   Loss: 0.4012     Train Accuracy: 90.05%                                                          \n",
      " Epoch: 49__ Batch: 72    Loss: 0.0063     AccuracyScore: 0.84  RecallScore: 0.00    f1Score: 0.00       \n",
      " Epoch: 49   Loss: 0.4012     Train Accuracy: 89.94%                                                          \n",
      " Epoch: 50__ Batch: 72    Loss: 0.0063     AccuracyScore: 0.94  RecallScore: 0.25    f1Score: 0.40       \n",
      " Epoch: 50   Loss: 0.3994     Train Accuracy: 89.94%                                                          \n",
      " Epoch: 51__ Batch: 72    Loss: 0.0062     AccuracyScore: 0.84  RecallScore: 0.30    f1Score: 0.43       \n",
      " Epoch: 51   Loss: 0.3982     Train Accuracy: 90.20%                                                          \n",
      " Epoch: 52__ Batch: 72    Loss: 0.0062     AccuracyScore: 0.94  RecallScore: 0.50    f1Score: 0.67       \n",
      " Epoch: 52   Loss: 0.3965     Train Accuracy: 90.09%                                                          \n",
      " Epoch: 53__ Batch: 72    Loss: 0.0062     AccuracyScore: 0.96  RecallScore: 0.67    f1Score: 0.80       \n",
      " Epoch: 53   Loss: 0.3960     Train Accuracy: 90.22%                                                          \n",
      " Epoch: 54__ Batch: 72    Loss: 0.0062     AccuracyScore: 0.90  RecallScore: 0.17    f1Score: 0.29       \n",
      " Epoch: 54   Loss: 0.3941     Train Accuracy: 90.05%                                                          \n",
      " Epoch: 55__ Batch: 72    Loss: 0.0062     AccuracyScore: 0.84  RecallScore: 0.14    f1Score: 0.20       \n",
      " Epoch: 55   Loss: 0.3942     Train Accuracy: 90.12%                                                          \n",
      " Epoch: 56__ Batch: 72    Loss: 0.0062     AccuracyScore: 0.92  RecallScore: 0.00    f1Score: 0.00       \n",
      " Epoch: 56   Loss: 0.3924     Train Accuracy: 90.18%                                                          \n",
      " Epoch: 57__ Batch: 72    Loss: 0.0061     AccuracyScore: 0.94  RecallScore: 0.40    f1Score: 0.57       \n",
      " Epoch: 57   Loss: 0.3920     Train Accuracy: 90.25%                                                          \n",
      " Epoch: 58__ Batch: 72    Loss: 0.0061     AccuracyScore: 0.92  RecallScore: 0.43    f1Score: 0.60       \n",
      " Epoch: 58   Loss: 0.3906     Train Accuracy: 90.01%                                                          \n",
      " Epoch: 59__ Batch: 72    Loss: 0.0061     AccuracyScore: 0.86  RecallScore: 0.29    f1Score: 0.36       \n",
      " Epoch: 59   Loss: 0.3902     Train Accuracy: 90.38%                                                          \n",
      " Epoch: 60__ Batch: 72    Loss: 0.0061     AccuracyScore: 0.94  RecallScore: 0.75    f1Score: 0.67       \n",
      " Epoch: 60   Loss: 0.3893     Train Accuracy: 90.27%                                                          \n",
      " Epoch: 61__ Batch: 72    Loss: 0.0061     AccuracyScore: 0.92  RecallScore: 0.20    f1Score: 0.33       \n",
      " Epoch: 61   Loss: 0.3866     Train Accuracy: 90.42%                                                          \n",
      " Epoch: 62__ Batch: 72    Loss: 0.0061     AccuracyScore: 0.86  RecallScore: 0.40    f1Score: 0.36       \n",
      " Epoch: 62   Loss: 0.3888     Train Accuracy: 90.12%                                                          \n",
      " Epoch: 63__ Batch: 72    Loss: 0.0060     AccuracyScore: 0.88  RecallScore: 0.00    f1Score: 0.00       \n",
      " Epoch: 63   Loss: 0.3852     Train Accuracy: 90.40%                                                          \n",
      " Epoch: 64__ Batch: 72    Loss: 0.0060     AccuracyScore: 0.94  RecallScore: 0.67    f1Score: 0.73       \n",
      " Epoch: 64   Loss: 0.3839     Train Accuracy: 90.53%                                                          \n",
      " Epoch: 65__ Batch: 72    Loss: 0.0060     AccuracyScore: 0.90  RecallScore: 0.00    f1Score: 0.00       \n",
      " Epoch: 65   Loss: 0.3842     Train Accuracy: 90.44%                                                          \n",
      " Epoch: 66__ Batch: 72    Loss: 0.0060     AccuracyScore: 0.90  RecallScore: 0.25    f1Score: 0.29       \n",
      " Epoch: 66   Loss: 0.3820     Train Accuracy: 90.51%                                                          \n",
      " Epoch: 67__ Batch: 72    Loss: 0.0060     AccuracyScore: 0.80  RecallScore: 0.10    f1Score: 0.17       \n",
      " Epoch: 67   Loss: 0.3834     Train Accuracy: 90.55%                                                          \n",
      " Epoch: 68__ Batch: 72    Loss: 0.0060     AccuracyScore: 0.86  RecallScore: 0.20    f1Score: 0.22       \n",
      " Epoch: 68   Loss: 0.3819     Train Accuracy: 90.38%                                                          \n",
      " Epoch: 69__ Batch: 72    Loss: 0.0060     AccuracyScore: 0.92  RecallScore: 0.25    f1Score: 0.33       \n",
      " Epoch: 69   Loss: 0.3806     Train Accuracy: 90.53%                                                          \n",
      " Epoch: 70__ Batch: 72    Loss: 0.0059     AccuracyScore: 0.90  RecallScore: 0.50    f1Score: 0.55       \n",
      " Epoch: 70   Loss: 0.3786     Train Accuracy: 90.38%                                                          \n",
      " Epoch: 71__ Batch: 72    Loss: 0.0059     AccuracyScore: 0.88  RecallScore: 0.33    f1Score: 0.40       \n",
      " Epoch: 71   Loss: 0.3787     Train Accuracy: 90.83%                                                          \n",
      " Epoch: 72__ Batch: 72    Loss: 0.0060     AccuracyScore: 0.88  RecallScore: 0.00    f1Score: 0.00       \n",
      " Epoch: 72   Loss: 0.3802     Train Accuracy: 90.38%                                                          \n",
      " Epoch: 73__ Batch: 72    Loss: 0.0059     AccuracyScore: 0.88  RecallScore: 0.40    f1Score: 0.40       \n",
      " Epoch: 73   Loss: 0.3752     Train Accuracy: 90.81%                                                          \n",
      " Epoch: 74__ Batch: 72    Loss: 0.0059     AccuracyScore: 0.84  RecallScore: 0.00    f1Score: 0.00       \n",
      " Epoch: 74   Loss: 0.3750     Train Accuracy: 90.73%                                                          \n",
      " Epoch: 75__ Batch: 72    Loss: 0.0059     AccuracyScore: 0.94  RecallScore: 0.40    f1Score: 0.57       \n",
      " Epoch: 75   Loss: 0.3745     Train Accuracy: 90.57%                                                          \n",
      " Epoch: 76__ Batch: 72    Loss: 0.0059     AccuracyScore: 0.86  RecallScore: 0.60    f1Score: 0.46       \n",
      " Epoch: 76   Loss: 0.3734     Train Accuracy: 90.73%                                                          \n",
      " Epoch: 77__ Batch: 72    Loss: 0.0058     AccuracyScore: 0.94  RecallScore: 0.50    f1Score: 0.67       \n",
      " Epoch: 77   Loss: 0.3725     Train Accuracy: 90.57%                                                          \n",
      " Epoch: 78__ Batch: 72    Loss: 0.0058     AccuracyScore: 0.94  RecallScore: 0.33    f1Score: 0.40       \n",
      " Epoch: 78   Loss: 0.3714     Train Accuracy: 90.68%                                                          \n",
      " Epoch: 79__ Batch: 72    Loss: 0.0058     AccuracyScore: 0.88  RecallScore: 0.50    f1Score: 0.50       \n",
      " Epoch: 79   Loss: 0.3717     Train Accuracy: 90.79%                                                          \n",
      " Epoch: 80__ Batch: 72    Loss: 0.0058     AccuracyScore: 0.92  RecallScore: 0.20    f1Score: 0.33       \n",
      " Epoch: 80   Loss: 0.3689     Train Accuracy: 91.10%                                                          \n",
      " Epoch: 81__ Batch: 72    Loss: 0.0058     AccuracyScore: 0.98  RecallScore: 0.80    f1Score: 0.89       \n",
      " Epoch: 81   Loss: 0.3682     Train Accuracy: 90.96%                                                          \n",
      " Epoch: 82__ Batch: 72    Loss: 0.0058     AccuracyScore: 0.88  RecallScore: 0.25    f1Score: 0.25       \n",
      " Epoch: 82   Loss: 0.3689     Train Accuracy: 90.94%                                                          \n",
      " Epoch: 83__ Batch: 72    Loss: 0.0058     AccuracyScore: 0.90  RecallScore: 0.17    f1Score: 0.29       \n",
      " Epoch: 83   Loss: 0.3671     Train Accuracy: 91.10%                                                          \n",
      " Epoch: 84__ Batch: 72    Loss: 0.0057     AccuracyScore: 0.90  RecallScore: 0.75    f1Score: 0.55       \n",
      " Epoch: 84   Loss: 0.3665     Train Accuracy: 90.88%                                                          \n",
      " Epoch: 85__ Batch: 72    Loss: 0.0057     AccuracyScore: 0.92  RecallScore: 0.25    f1Score: 0.33       \n",
      " Epoch: 85   Loss: 0.3657     Train Accuracy: 90.90%                                                          \n",
      " Epoch: 86__ Batch: 72    Loss: 0.0057     AccuracyScore: 0.94  RecallScore: 0.00    f1Score: 0.00       \n",
      " Epoch: 86   Loss: 0.3643     Train Accuracy: 91.07%                                                          \n",
      " Epoch: 87__ Batch: 72    Loss: 0.0057     AccuracyScore: 0.98  RecallScore: 1.00    f1Score: 0.89       \n",
      " Epoch: 87   Loss: 0.3644     Train Accuracy: 91.16%                                                          \n",
      " Epoch: 88__ Batch: 72    Loss: 0.0057     AccuracyScore: 0.92  RecallScore: 0.25    f1Score: 0.33       \n",
      " Epoch: 88   Loss: 0.3628     Train Accuracy: 90.94%                                                          \n",
      " Epoch: 89__ Batch: 72    Loss: 0.0057     AccuracyScore: 0.84  RecallScore: 0.29    f1Score: 0.33       \n",
      " Epoch: 89   Loss: 0.3618     Train Accuracy: 91.01%                                                          \n",
      " Epoch: 90__ Batch: 72    Loss: 0.0057     AccuracyScore: 0.94  RecallScore: 0.50    f1Score: 0.67       \n",
      " Epoch: 90   Loss: 0.3606     Train Accuracy: 91.05%                                                          \n",
      " Epoch: 91__ Batch: 72    Loss: 0.0056     AccuracyScore: 0.84  RecallScore: 0.20    f1Score: 0.20       \n",
      " Epoch: 91   Loss: 0.3601     Train Accuracy: 90.94%                                                          \n",
      " Epoch: 92__ Batch: 72    Loss: 0.0056     AccuracyScore: 0.88  RecallScore: 0.17    f1Score: 0.25       \n",
      " Epoch: 92   Loss: 0.3598     Train Accuracy: 91.16%                                                          \n",
      " Epoch: 93__ Batch: 72    Loss: 0.0056     AccuracyScore: 0.94  RecallScore: 0.80    f1Score: 0.73       \n",
      " Epoch: 93   Loss: 0.3568     Train Accuracy: 91.16%                                                          \n",
      " Epoch: 94__ Batch: 72    Loss: 0.0056     AccuracyScore: 0.90  RecallScore: 0.17    f1Score: 0.29       \n",
      " Epoch: 94   Loss: 0.3582     Train Accuracy: 91.18%                                                          \n",
      " Epoch: 95__ Batch: 72    Loss: 0.0056     AccuracyScore: 0.84  RecallScore: 0.38    f1Score: 0.43       \n",
      " Epoch: 95   Loss: 0.3551     Train Accuracy: 91.31%                                                          \n",
      " Epoch: 96__ Batch: 72    Loss: 0.0056     AccuracyScore: 0.78  RecallScore: 0.11    f1Score: 0.15       \n",
      " Epoch: 96   Loss: 0.3567     Train Accuracy: 91.14%                                                          \n",
      " Epoch: 97__ Batch: 72    Loss: 0.0056     AccuracyScore: 0.90  RecallScore: 0.50    f1Score: 0.29       \n",
      " Epoch: 97   Loss: 0.3552     Train Accuracy: 91.38%                                                          \n",
      " Epoch: 98__ Batch: 72    Loss: 0.0056     AccuracyScore: 0.88  RecallScore: 0.00    f1Score: 0.00       \n",
      " Epoch: 98   Loss: 0.3545     Train Accuracy: 91.38%                                                          \n",
      " Epoch: 99__ Batch: 72    Loss: 0.0055     AccuracyScore: 0.92  RecallScore: 0.00    f1Score: 0.00       \n",
      " Epoch: 99   Loss: 0.3524     Train Accuracy: 91.44%                                                          \n",
      " Epoch: 100_ Batch: 72    Loss: 0.0055     AccuracyScore: 0.88  RecallScore: 0.29    f1Score: 0.40       \n",
      " Epoch: 100  Loss: 0.3526     Train Accuracy: 91.25%                                                          \n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import recall_score, accuracy_score,f1_score\n",
    "\n",
    "epochs = 100\n",
    "batchSize = 64\n",
    "\n",
    "# firstBatch = True\n",
    "\n",
    "for fold, (train_x, test_x, train_y, test_y) in enumerate(kFolds,start=1):\n",
    "\n",
    "    #? Need to convert the pd.DataFrames to torch.tensors\n",
    "    # train_x = torch.tensor(train_x.values,dtype=torch.float32)\n",
    "    # train_x_normalized = (train_x - train_x.min()) / (train_x.max() - train_x.min())\n",
    "    # train_y = torch.tensor(train_y.values,dtype=torch.float32)\n",
    "    # test_x = torch.tensor(test_x.values,dtype=torch.float32)\n",
    "    # test_x_normalized = (test_x - test_x.min()) / (test_x.max() - test_x.min())\n",
    "    # test_y = torch.tensor(test_y.values,dtype=torch.float32)\n",
    "\n",
    "    train_dataset = TensorDataset(torch.tensor(train_x.values,dtype=torch.float32), torch.tensor(train_y.values,dtype=torch.float32))\n",
    "    val_dataset = TensorDataset(torch.tensor(test_x.values,dtype=torch.float32), torch.tensor(test_y.values,dtype=torch.float32))\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batchSize, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batchSize, shuffle=False)\n",
    "\n",
    "    model.train()\n",
    "    print(f\"Fold: {fold}\")\n",
    "    for epoch in range(1,epochs+1):\n",
    "        print(f\" Epoch: {epoch}\".ljust(12), end=\"\\r\")\n",
    "        running_loss = 0.\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "\n",
    "        \n",
    "        for batch, (inputs, labels) in enumerate(train_loader,start=1):\n",
    "\n",
    "            inputs, labels = inputs.to(device), labels.float().to(device)\n",
    "            optimiser.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "           \n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            predictions = (torch.sigmoid(outputs) > 0.5).float().cpu()\n",
    "            labels = labels.cpu()\n",
    "            total_train += labels.size(0)\n",
    "            correct_train += (predictions == labels).sum().item()\n",
    "            accuracyScore = accuracy_score(labels,predictions)\n",
    "            recallScore = recall_score(labels,predictions,zero_division=1)\n",
    "            f1Score = f1_score(labels,predictions)\n",
    "\n",
    "            if epoch == 1 and batch == 1:\n",
    "                # print(\"Inputs:\",inputs)\n",
    "                print(\"Labels\",labels)\n",
    "                print(\"Outputs\",outputs)\n",
    "                print(\"Preds\", predictions)\n",
    "\n",
    "            print(f\" Epoch: {epoch}\".ljust(12,\"_\"),\n",
    "                  f\"Batch: {batch}\".ljust(12),\n",
    "                  f\"Loss: {(running_loss/total_train):.4f}\".ljust(16),\n",
    "                  f\"AccuracyScore: {(accuracyScore):.2f}\".ljust(20),\n",
    "                  f\"RecallScore: {(recallScore):.2f}\".ljust(20),\n",
    "                  f\"f1Score: {(f1Score):.2f}\".ljust(20),  \n",
    "                  end=\"\\r\")\n",
    "            # break\n",
    "        print()\n",
    "\n",
    "        train_accuracy = (correct_train / total_train)*100\n",
    "        avg_loss = running_loss / (len(train_loader))\n",
    "\n",
    "        print(f\" Epoch: {epoch}\".ljust(12),\n",
    "              f\"Loss: {avg_loss:.4f}\".ljust(16),\n",
    "              f\"Train Accuracy: {train_accuracy:.2f}%\".ljust(80),\n",
    "            #   end=\"\\r\",\n",
    "              )\n",
    "        # if epoch > 10:\n",
    "        #     break\n",
    "    # break\n",
    "    print()\n",
    "\n",
    "    model.eval()\n",
    "    print(f\"Validation\".center(20,\"-\"))\n",
    "    \n",
    "    running_loss = 0.\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    with torch.no_grad():\n",
    "        for batch, (inputs, labels) in enumerate(val_loader,start=1):\n",
    "\n",
    "            inputs, labels = inputs.to(device), labels.squeeze().float().to(device)\n",
    "            outputs = model(inputs).squeeze()\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            predictions = (outputs > 0.5).float().cpu()\n",
    "            labels2 = labels.cpu()\n",
    "            total_val += labels2.size(0)\n",
    "            correct_val += (predictions == labels2).sum().item()\n",
    "            accuracy = (predictions == labels2).float().mean()\n",
    "            accuracyScore = accuracy_score(labels2,predictions)\n",
    "            recallScore = recall_score(labels2,predictions,zero_division=0.0)\n",
    "\n",
    "            # print(f\"  Batch: {batch+1}\",\n",
    "            #         f\"Loss: {(running_loss/total_train):.4f}\",\n",
    "            #         f\"AccuracyScore: {(accuracy):.2f}\",\n",
    "            #         f\"RecallScore: {(recallScore):.2f}\", \n",
    "            #         end=\"\\r\")\n",
    "            # break\n",
    "        # print()\n",
    "        print(correct_val,total_val)\n",
    "\n",
    "        val_accuracy = (correct_val / total_val)*100\n",
    "        avg_loss = running_loss / (len(train_loader))\n",
    "\n",
    "        print(f\"  Loss: {avg_loss:.4f}\".ljust(12),\n",
    "                f\"Val Accuracy: {val_accuracy:.2f}%\".ljust(50),\n",
    "                )\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs tensor([[-1.0172],\n",
      "        [ 0.4554],\n",
      "        [ 1.1342],\n",
      "        [-0.0122],\n",
      "        [ 1.1775],\n",
      "        [-2.6526],\n",
      "        [ 1.4175],\n",
      "        [ 0.1274],\n",
      "        [-0.0921],\n",
      "        [-0.9861],\n",
      "        [ 0.4210],\n",
      "        [ 0.9787],\n",
      "        [-0.4351],\n",
      "        [ 0.9333],\n",
      "        [-2.1001],\n",
      "        [-2.6380],\n",
      "        [-2.0313],\n",
      "        [-0.9810],\n",
      "        [-2.0490],\n",
      "        [ 0.4956],\n",
      "        [-0.6565],\n",
      "        [-0.5936],\n",
      "        [ 0.6807],\n",
      "        [-0.5846],\n",
      "        [-0.7008],\n",
      "        [-0.6991],\n",
      "        [-1.6942],\n",
      "        [-2.2613],\n",
      "        [-0.8856],\n",
      "        [ 0.1671],\n",
      "        [-1.4126],\n",
      "        [-1.1002],\n",
      "        [ 0.0649],\n",
      "        [ 0.1838],\n",
      "        [-0.2642],\n",
      "        [-0.6062],\n",
      "        [ 0.8984],\n",
      "        [-0.8644],\n",
      "        [ 1.8708],\n",
      "        [-1.0555],\n",
      "        [ 0.3642],\n",
      "        [-1.0209],\n",
      "        [-1.0453],\n",
      "        [-0.7794],\n",
      "        [-1.7509],\n",
      "        [-0.1454],\n",
      "        [ 1.9349],\n",
      "        [-0.0929],\n",
      "        [ 0.9393],\n",
      "        [ 1.8216],\n",
      "        [-0.0266],\n",
      "        [ 0.7406],\n",
      "        [-2.7596],\n",
      "        [-2.6206],\n",
      "        [-1.4725],\n",
      "        [-3.2560],\n",
      "        [-0.9285],\n",
      "        [-0.0616],\n",
      "        [-0.1727],\n",
      "        [ 0.3689],\n",
      "        [ 0.4482]])\n",
      "Preds tensor([[0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.]])\n",
      "Labels tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Outputs\",outputs)\n",
    "print(\"Preds\", predicted)\n",
    "print(\"Labels\",labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 4593\n",
      "Test: 1149\n",
      " Epoch: [1/50]  \n",
      "Inputs: tensor([[0.4828, 1.0000, 0.0044,  ..., 0.0000, 1.0000, 0.0000],\n",
      "        [0.6897, 0.0000, 0.0204,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.6379, 1.0000, 0.0068,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.5345, 1.0000, 0.0068,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 1.0000, 0.0023,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.5345, 1.0000, 0.0364,  ..., 0.0000, 0.0000, 0.0000]])\n",
      "Labels tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]])\n",
      "outputs tensor([[-1.1206],\n",
      "        [-2.1631],\n",
      "        [-3.1820],\n",
      "        [-1.1607],\n",
      "        [-0.1336],\n",
      "        [ 0.2772],\n",
      "        [-2.6618],\n",
      "        [-5.2749],\n",
      "        [-1.3800],\n",
      "        [-3.9575],\n",
      "        [-0.4782],\n",
      "        [-2.5154],\n",
      "        [-2.5864],\n",
      "        [-0.4246],\n",
      "        [-5.2915],\n",
      "        [-4.4328],\n",
      "        [-1.4555],\n",
      "        [-3.7324],\n",
      "        [-3.3136],\n",
      "        [-2.7607],\n",
      "        [-4.6835],\n",
      "        [-2.2266],\n",
      "        [-2.4152],\n",
      "        [ 0.7317],\n",
      "        [-1.5702],\n",
      "        [-3.1559],\n",
      "        [-3.0967],\n",
      "        [ 1.6796],\n",
      "        [-2.5914],\n",
      "        [-2.1182],\n",
      "        [-2.8052],\n",
      "        [-2.3726],\n",
      "        [-2.3894],\n",
      "        [ 0.2933],\n",
      "        [-2.5835],\n",
      "        [ 1.3100],\n",
      "        [ 0.3621],\n",
      "        [-4.8984],\n",
      "        [-2.7900],\n",
      "        [-0.6052],\n",
      "        [-2.4970],\n",
      "        [-3.2480],\n",
      "        [-2.6278],\n",
      "        [-2.0475],\n",
      "        [-2.8218],\n",
      "        [-0.9726],\n",
      "        [-2.3291],\n",
      "        [-3.1665],\n",
      "        [-2.4306],\n",
      "        [-0.3088],\n",
      "        [-1.0050],\n",
      "        [-0.5170],\n",
      "        [-1.0664],\n",
      "        [-3.1088],\n",
      "        [-3.3383],\n",
      "        [-0.4416],\n",
      "        [-0.3878],\n",
      "        [-2.7984],\n",
      "        [-1.3981],\n",
      "        [-4.0803],\n",
      "        [-1.3920],\n",
      "        [-0.3042],\n",
      "        [-2.1761],\n",
      "        [-2.1247]], grad_fn=<AddmmBackward0>)\n",
      "Preds tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]])\n",
      "AccuracyScore: 0.91\n",
      "  Batch: 72  Loss: 0.0062     AccuracyScore: 0.86  RecallScore: 0.29    f1Score: 0.36       \n",
      "  Loss: 0.3941   Train Accuracy: 90.33%                                                          \n",
      " Epoch: [2/50]  \n",
      "  Batch: 72  Loss: 0.0062     AccuracyScore: 0.86  RecallScore: 0.29    f1Score: 0.36       \n",
      "  Loss: 0.3931   Train Accuracy: 90.29%                                                          \n",
      " Epoch: [3/50]  \n",
      "  Batch: 72  Loss: 0.0061     AccuracyScore: 0.86  RecallScore: 0.29    f1Score: 0.36       \n",
      "  Loss: 0.3920   Train Accuracy: 90.31%                                                          \n",
      " Epoch: [4/50]  \n",
      "  Batch: 72  Loss: 0.0061     AccuracyScore: 0.86  RecallScore: 0.29    f1Score: 0.36       \n",
      "  Loss: 0.3910   Train Accuracy: 90.46%                                                          \n",
      " Epoch: [5/50]  \n",
      "  Batch: 72  Loss: 0.0061     AccuracyScore: 0.86  RecallScore: 0.29    f1Score: 0.36       \n",
      "  Loss: 0.3898   Train Accuracy: 90.42%                                                          \n",
      " Epoch: [6/50]  \n",
      "  Batch: 72  Loss: 0.0061     AccuracyScore: 0.86  RecallScore: 0.29    f1Score: 0.36       \n",
      "  Loss: 0.3887   Train Accuracy: 90.49%                                                          \n",
      " Epoch: [7/50]  \n",
      "  Batch: 72  Loss: 0.0061     AccuracyScore: 0.86  RecallScore: 0.29    f1Score: 0.36       \n",
      "  Loss: 0.3877   Train Accuracy: 90.49%                                                          \n",
      " Epoch: [8/50]  \n",
      "  Batch: 72  Loss: 0.0061     AccuracyScore: 0.86  RecallScore: 0.29    f1Score: 0.36       \n",
      "  Loss: 0.3866   Train Accuracy: 90.51%                                                          \n",
      " Epoch: [9/50]  \n",
      "  Batch: 72  Loss: 0.0060     AccuracyScore: 0.86  RecallScore: 0.29    f1Score: 0.36       \n",
      "  Loss: 0.3855   Train Accuracy: 90.51%                                                          \n",
      " Epoch: [10/50] \n",
      "  Batch: 72  Loss: 0.0060     AccuracyScore: 0.86  RecallScore: 0.29    f1Score: 0.36       \n",
      "  Loss: 0.3845   Train Accuracy: 90.51%                                                          \n",
      " Epoch: [11/50] \n",
      "  Batch: 72  Loss: 0.0060     AccuracyScore: 0.86  RecallScore: 0.29    f1Score: 0.36       \n",
      "  Loss: 0.3834   Train Accuracy: 90.53%                                                          \n",
      " Epoch: [12/50] \n",
      "  Batch: 72  Loss: 0.0060     AccuracyScore: 0.86  RecallScore: 0.29    f1Score: 0.36       \n",
      "  Loss: 0.3823   Train Accuracy: 90.59%                                                          \n",
      " Epoch: [13/50] \n",
      "  Batch: 72  Loss: 0.0060     AccuracyScore: 0.86  RecallScore: 0.29    f1Score: 0.36       \n",
      "  Loss: 0.3812   Train Accuracy: 90.62%                                                          \n",
      " Epoch: [14/50] \n",
      "  Batch: 72  Loss: 0.0060     AccuracyScore: 0.86  RecallScore: 0.29    f1Score: 0.36       \n",
      "  Loss: 0.3801   Train Accuracy: 90.64%                                                          \n",
      " Epoch: [15/50] \n",
      "  Batch: 72  Loss: 0.0059     AccuracyScore: 0.86  RecallScore: 0.29    f1Score: 0.36       \n",
      "  Loss: 0.3790   Train Accuracy: 90.73%                                                          \n",
      " Epoch: [16/50] \n",
      "  Batch: 72  Loss: 0.0059     AccuracyScore: 0.86  RecallScore: 0.29    f1Score: 0.36       \n",
      "  Loss: 0.3780   Train Accuracy: 90.81%                                                          \n",
      " Epoch: [17/50] \n",
      "  Batch: 72  Loss: 0.0059     AccuracyScore: 0.86  RecallScore: 0.29    f1Score: 0.36       \n",
      "  Loss: 0.3769   Train Accuracy: 90.79%                                                          \n",
      " Epoch: [18/50] \n",
      "  Batch: 72  Loss: 0.0059     AccuracyScore: 0.86  RecallScore: 0.29    f1Score: 0.36       \n",
      "  Loss: 0.3758   Train Accuracy: 90.81%                                                          \n",
      " Epoch: [19/50] \n",
      "  Batch: 72  Loss: 0.0059     AccuracyScore: 0.86  RecallScore: 0.29    f1Score: 0.36       \n",
      "  Loss: 0.3746   Train Accuracy: 90.83%                                                          \n",
      " Epoch: [20/50] \n",
      "  Batch: 72  Loss: 0.0059     AccuracyScore: 0.84  RecallScore: 0.29    f1Score: 0.33       \n",
      "  Loss: 0.3735   Train Accuracy: 90.83%                                                          \n",
      " Epoch: [21/50] \n",
      "  Batch: 72  Loss: 0.0058     AccuracyScore: 0.84  RecallScore: 0.29    f1Score: 0.33       \n",
      "  Loss: 0.3724   Train Accuracy: 90.77%                                                          \n",
      " Epoch: [22/50] \n",
      "  Batch: 72  Loss: 0.0058     AccuracyScore: 0.84  RecallScore: 0.29    f1Score: 0.33       \n",
      "  Loss: 0.3712   Train Accuracy: 90.83%                                                          \n",
      " Epoch: [23/50] \n",
      "  Batch: 72  Loss: 0.0058     AccuracyScore: 0.84  RecallScore: 0.29    f1Score: 0.33       \n",
      "  Loss: 0.3702   Train Accuracy: 90.90%                                                          \n",
      " Epoch: [24/50] \n",
      "  Batch: 72  Loss: 0.0058     AccuracyScore: 0.84  RecallScore: 0.29    f1Score: 0.33       \n",
      "  Loss: 0.3691   Train Accuracy: 90.94%                                                          \n",
      " Epoch: [25/50] \n",
      "  Batch: 72  Loss: 0.0058     AccuracyScore: 0.84  RecallScore: 0.29    f1Score: 0.33       \n",
      "  Loss: 0.3680   Train Accuracy: 90.96%                                                          \n",
      " Epoch: [26/50] \n",
      "  Batch: 72  Loss: 0.0058     AccuracyScore: 0.84  RecallScore: 0.29    f1Score: 0.33       \n",
      "  Loss: 0.3669   Train Accuracy: 91.03%                                                          \n",
      " Epoch: [27/50] \n",
      "  Batch: 72  Loss: 0.0057     AccuracyScore: 0.84  RecallScore: 0.29    f1Score: 0.33       \n",
      "  Loss: 0.3657   Train Accuracy: 91.10%                                                          \n",
      " Epoch: [28/50] \n",
      "  Batch: 72  Loss: 0.0057     AccuracyScore: 0.84  RecallScore: 0.29    f1Score: 0.33       \n",
      "  Loss: 0.3647   Train Accuracy: 91.10%                                                          \n",
      " Epoch: [29/50] \n",
      "  Batch: 72  Loss: 0.0057     AccuracyScore: 0.84  RecallScore: 0.29    f1Score: 0.33       \n",
      "  Loss: 0.3635   Train Accuracy: 91.10%                                                          \n",
      " Epoch: [30/50] \n",
      "  Batch: 72  Loss: 0.0057     AccuracyScore: 0.84  RecallScore: 0.29    f1Score: 0.33       \n",
      "  Loss: 0.3624   Train Accuracy: 91.18%                                                          \n",
      " Epoch: [31/50] \n",
      "  Batch: 72  Loss: 0.0057     AccuracyScore: 0.84  RecallScore: 0.29    f1Score: 0.33       \n",
      "  Loss: 0.3613   Train Accuracy: 91.18%                                                          \n",
      " Epoch: [32/50] \n",
      "  Batch: 72  Loss: 0.0056     AccuracyScore: 0.84  RecallScore: 0.29    f1Score: 0.33       \n",
      "  Loss: 0.3602   Train Accuracy: 91.20%                                                          \n",
      " Epoch: [33/50] \n",
      "  Batch: 72  Loss: 0.0056     AccuracyScore: 0.84  RecallScore: 0.29    f1Score: 0.33       \n",
      "  Loss: 0.3591   Train Accuracy: 91.25%                                                          \n",
      " Epoch: [34/50] \n",
      "  Batch: 72  Loss: 0.0056     AccuracyScore: 0.84  RecallScore: 0.29    f1Score: 0.33       \n",
      "  Loss: 0.3580   Train Accuracy: 91.27%                                                          \n",
      " Epoch: [35/50] \n",
      "  Batch: 72  Loss: 0.0056     AccuracyScore: 0.84  RecallScore: 0.29    f1Score: 0.33       \n",
      "  Loss: 0.3568   Train Accuracy: 91.36%                                                          \n",
      " Epoch: [36/50] \n",
      "  Batch: 72  Loss: 0.0056     AccuracyScore: 0.84  RecallScore: 0.29    f1Score: 0.33       \n",
      "  Loss: 0.3558   Train Accuracy: 91.36%                                                          \n",
      " Epoch: [37/50] \n",
      "  Batch: 72  Loss: 0.0056     AccuracyScore: 0.84  RecallScore: 0.29    f1Score: 0.33       \n",
      "  Loss: 0.3547   Train Accuracy: 91.38%                                                          \n",
      " Epoch: [38/50] \n",
      "  Batch: 72  Loss: 0.0055     AccuracyScore: 0.86  RecallScore: 0.43    f1Score: 0.46       \n",
      "  Loss: 0.3537   Train Accuracy: 91.44%                                                          \n",
      " Epoch: [39/50] \n",
      "  Batch: 72  Loss: 0.0055     AccuracyScore: 0.86  RecallScore: 0.43    f1Score: 0.46       \n",
      "  Loss: 0.3526   Train Accuracy: 91.49%                                                          \n",
      " Epoch: [40/50] \n",
      "  Batch: 72  Loss: 0.0055     AccuracyScore: 0.86  RecallScore: 0.43    f1Score: 0.46       \n",
      "  Loss: 0.3516   Train Accuracy: 91.44%                                                          \n",
      " Epoch: [41/50] \n",
      "  Batch: 72  Loss: 0.0055     AccuracyScore: 0.86  RecallScore: 0.43    f1Score: 0.46       \n",
      "  Loss: 0.3505   Train Accuracy: 91.47%                                                          \n",
      " Epoch: [42/50] \n",
      "  Batch: 72  Loss: 0.0055     AccuracyScore: 0.86  RecallScore: 0.43    f1Score: 0.46       \n",
      "  Loss: 0.3495   Train Accuracy: 91.44%                                                          \n",
      " Epoch: [43/50] \n",
      "  Batch: 72  Loss: 0.0055     AccuracyScore: 0.86  RecallScore: 0.43    f1Score: 0.46       \n",
      "  Loss: 0.3484   Train Accuracy: 91.55%                                                          \n",
      " Epoch: [44/50] \n",
      "  Batch: 72  Loss: 0.0054     AccuracyScore: 0.86  RecallScore: 0.43    f1Score: 0.46       \n",
      "  Loss: 0.3474   Train Accuracy: 91.55%                                                          \n",
      " Epoch: [45/50] \n",
      "  Batch: 72  Loss: 0.0054     AccuracyScore: 0.86  RecallScore: 0.43    f1Score: 0.46       \n",
      "  Loss: 0.3463   Train Accuracy: 91.55%                                                          \n",
      " Epoch: [46/50] \n",
      "  Batch: 72  Loss: 0.0054     AccuracyScore: 0.86  RecallScore: 0.43    f1Score: 0.46       \n",
      "  Loss: 0.3453   Train Accuracy: 91.55%                                                          \n",
      " Epoch: [47/50] \n",
      "  Batch: 72  Loss: 0.0054     AccuracyScore: 0.86  RecallScore: 0.43    f1Score: 0.46       \n",
      "  Loss: 0.3443   Train Accuracy: 91.51%                                                          \n",
      " Epoch: [48/50] \n",
      "  Batch: 72  Loss: 0.0054     AccuracyScore: 0.86  RecallScore: 0.43    f1Score: 0.46       \n",
      "  Loss: 0.3432   Train Accuracy: 91.53%                                                          \n",
      " Epoch: [49/50] \n",
      "  Batch: 72  Loss: 0.0054     AccuracyScore: 0.86  RecallScore: 0.43    f1Score: 0.46       \n",
      "  Loss: 0.3421   Train Accuracy: 91.55%                                                          \n",
      " Epoch: [50/50] \n",
      "  Batch: 72  Loss: 0.0053     AccuracyScore: 0.86  RecallScore: 0.43    f1Score: 0.46       \n",
      "  Loss: 0.3411   Train Accuracy: 91.57%                                                          \n",
      "-----------Testing------------\n",
      " Batch: 18   Loss: 0.5160 Accuracy: 0.89%\n",
      " Test Accuracy: 86.77%   Test Loss: 0.5808\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_x_normalized = (train_x - train_x.min()) / (train_x.max() - train_x.min()) \n",
    "test_x_normalized = (test_x - test_x.min()) / (test_x.max() - test_x.min())    \n",
    "\n",
    "train_dataset = TensorDataset(torch.tensor(train_x_normalized.values,dtype=torch.float32),\n",
    "                              torch.tensor(train_y.values,dtype=torch.float32))\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "\n",
    "test_dataset = TensorDataset(torch.tensor(test_x_normalized.values,dtype=torch.float32),\n",
    "                             torch.tensor(test_y.values,dtype=torch.float32))\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "print(\"Train:\", len(train_dataset))\n",
    "print(\"Test:\", len(test_dataset))\n",
    "\n",
    "epochs = 50\n",
    "\n",
    "model.train()\n",
    "for epoch in range(1,epochs+1):\n",
    "    print(f\" Epoch: [{epoch}/{epochs}]\".ljust(16),\n",
    "        #   end=\"\\r\",\n",
    "          )\n",
    "    running_loss = 0.\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "\n",
    "    for batch, (inputs, labels) in enumerate(train_loader,start=1):\n",
    "\n",
    "        inputs, labels = inputs.to(device), labels.float().to(device)\n",
    "        optimiser.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        predictions = (torch.sigmoid(outputs) > 0.5).float().cpu()\n",
    "        labels = labels.cpu()\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predictions == labels).sum().item()\n",
    "        accuracy = (predictions == labels).float().mean()\n",
    "        accuracyScore = accuracy_score(labels,predictions)\n",
    "        recallScore = recall_score(labels,predictions,zero_division=0.0)\n",
    "        f1Score = f1_score(labels,predictions)\n",
    "\n",
    "        if epoch == 1 and batch == 1:\n",
    "            print(\"Inputs:\",inputs)\n",
    "            print(\"Labels\",labels)\n",
    "            print(\"outputs\", outputs)\n",
    "            print(\"Preds\", predictions)\n",
    "            print(f\"AccuracyScore: {(accuracy):.2f}\")\n",
    "\n",
    "\n",
    "    #     print(predictions.cpu(), labels2)\n",
    "\n",
    "        print(f\"  Batch: {batch}\".ljust(12),\n",
    "              f\"Loss: {(running_loss/total_train):.4f}\".ljust(16),\n",
    "              f\"AccuracyScore: {(accuracy):.2f}\".ljust(20),\n",
    "              f\"RecallScore: {(recallScore):.2f}\".ljust(20), \n",
    "              f\"f1Score: {(f1Score):.2f}\".ljust(20),  \n",
    "                end=\"\\r\")\n",
    "        # break\n",
    "    print()\n",
    "\n",
    "    train_accuracy = (correct_train / total_train)*100\n",
    "    avg_loss = running_loss / (len(train_loader))\n",
    "\n",
    "    print(f\"  Loss: {avg_loss:.4f}\".ljust(16),\n",
    "          f\"Train Accuracy: {train_accuracy:.2f}%\".ljust(80),\n",
    "          # end=\"\\r\",\n",
    "          )\n",
    "    # break\n",
    "\n",
    "model.eval()\n",
    "print(\"Testing\".center(30,\"-\"))\n",
    "\n",
    "t_loss = 0.\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for tBatch, (inputs, labels) in enumerate(test_loader,start=1):\n",
    "\n",
    "        inputs, labels = inputs.to(device), labels.float().to(device)\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        t_loss += loss.item()\n",
    "        predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        accuracy = accuracy_score(labels,predicted)\n",
    "    \n",
    "\n",
    "\n",
    "        print(f\" Batch: {tBatch}\".ljust(12), f\"Loss: {loss.item():.4f}\".ljust(12), f\"Accuracy: {(accuracy):.2f}%\",end=\"\\r\")\n",
    "    print()\n",
    "\n",
    "test_accuracy = (correct / total)*100\n",
    "print(f\" Test Accuracy: {test_accuracy:.2f}%\".ljust(24), f\"Test Loss: {t_loss/tBatch:.4f}\".ljust(16))\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
